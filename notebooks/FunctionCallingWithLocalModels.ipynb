{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6760b6c4-e62a-4fff-a649-3e46b6989efe",
   "metadata": {},
   "source": [
    "## Doing function calling with open source local models like llama are experimental in langchain till now.\n",
    "## https://api.python.langchain.com/en/latest/llms/langchain_experimental.llms.ollama_functions.OllamaFunctions.html#langchain_experimental.llms.ollama_functions.OllamaFunctions\n",
    "## Video to explain function calling in LLama models: https://www.youtube.com/watch?v=Ss_GdU0KqE0\n",
    "\n",
    "## Experiment with Llama and Phi3 models for function calling: https://export.arxiv.org/pdf/2404.14219"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af9345dd-e3a7-44bc-8490-2e78f9daa03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser, PydanticOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8af61e84-ceec-489a-bd33-6eb5c43be6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "acf8a462-b89f-4382-ab51-4d4882887237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a8dab9a-11f0-4222-a35b-4ee75fa38fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d43a3cd-61c2-4daa-aeec-72ebc9e6fb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2188617a-8ead-4b30-9703-3f109af9d465",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.debug=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f47e1214-7e38-4ca6-8df9-b1dfa8522c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm = ChatOllama(model=\"llama2:latest\", keep_alive=-1, temperature=0, max_new_tokens=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2223f43-186a-4a7d-8a80-4714f149a844",
   "metadata": {},
   "source": [
    "## Part1: Basic usgae of local models like llama2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03a4a371-2c0c-42db-aa65-cb9a7e29f467",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is assumed to be given by the human\n",
    "prompt = ChatPromptTemplate.from_template(\"Write me a 500 word article on {topic} from the perspective of a {profession}.\")\n",
    "chain = prompt | local_llm |  StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7a647b0-29ca-4b39-95f1-ece5c7b57630",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"topic\": \"LLMs\",\n",
      "  \"profession\": \"baker\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"topic\": \"LLMs\",\n",
      "  \"profession\": \"baker\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Write me a 500 word article on LLMs from the perspective of a baker.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [18.91s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\\nAs a baker, I can't help but think about the importance of mastering the art of bread-making. It's not just about mixing flour, water, yeast, and salt to create a delicious loaf - it's about understanding the science behind the process. And that's where LLMs come in.\\n\\nLLMs, or Large Language Models, are AI systems designed to process and generate human-like language. They have the potential to revolutionize the way we work, communicate, and create. But what does this have to do with bread-making? Well, let me tell you.\\n\\nAs a baker, I know that the key to creating the perfect loaf is not just about following a recipe, but understanding the underlying principles of bread-making. It's about knowing how yeast works, how dough develops, and how different ingredients interact with each other. And that's where LLMs come in.\\n\\nLLMs can help us understand these underlying principles by analyzing and generating text related to bread-making. They can provide insights into the chemical reactions that occur during the baking process, and even generate new recipes based on existing ones. Imagine being able to create a new loaf of bread simply by inputting a few ingredients and letting an LLM do the rest!\\n\\nBut the potential applications of LLMs in bread-making go beyond just generating new recipes. They can also help us troubleshoot problems that arise during the baking process. For example, if you're experiencing inconsistent rising times or uneven baking, an LLM could analyze your existing recipe and suggest adjustments to improve the outcome.\\n\\nAnd let's not forget about the creative possibilities of LLMs in bread-making. With the ability to generate new recipes and flavor combinations, the possibilities are endless! Imagine being able to create a unique loaf of bread that combines the flavors of your favorite childhood treats, or experimenting with different spices and herbs to create a one-of-a-kind bread.\\n\\nOf course, as with any new technology, there are also potential drawbacks to using LLMs in bread-making. For example, relying too heavily on automation could lead to a loss of touch and intuition when it comes to baking. And let's not forget the potential for errors or inconsistencies in the generated recipes - after all, no AI system is perfect!\\n\\nBut overall, I believe that LLMs have the potential to revolutionize the way we approach bread-making. By providing insights into the underlying principles of the process and generating new recipe ideas, they can help us create better loaves than ever before. And who knows - maybe one day we'll be able to create a bread-making AI that can rival even the most skilled human bakers!\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama2:latest\",\n",
      "          \"created_at\": \"2024-06-20T17:11:34.424953Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 18899417625,\n",
      "          \"load_duration\": 3585292,\n",
      "          \"prompt_eval_count\": 18,\n",
      "          \"prompt_eval_duration\": 364961000,\n",
      "          \"eval_count\": 632,\n",
      "          \"eval_duration\": 18528410000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\\nAs a baker, I can't help but think about the importance of mastering the art of bread-making. It's not just about mixing flour, water, yeast, and salt to create a delicious loaf - it's about understanding the science behind the process. And that's where LLMs come in.\\n\\nLLMs, or Large Language Models, are AI systems designed to process and generate human-like language. They have the potential to revolutionize the way we work, communicate, and create. But what does this have to do with bread-making? Well, let me tell you.\\n\\nAs a baker, I know that the key to creating the perfect loaf is not just about following a recipe, but understanding the underlying principles of bread-making. It's about knowing how yeast works, how dough develops, and how different ingredients interact with each other. And that's where LLMs come in.\\n\\nLLMs can help us understand these underlying principles by analyzing and generating text related to bread-making. They can provide insights into the chemical reactions that occur during the baking process, and even generate new recipes based on existing ones. Imagine being able to create a new loaf of bread simply by inputting a few ingredients and letting an LLM do the rest!\\n\\nBut the potential applications of LLMs in bread-making go beyond just generating new recipes. They can also help us troubleshoot problems that arise during the baking process. For example, if you're experiencing inconsistent rising times or uneven baking, an LLM could analyze your existing recipe and suggest adjustments to improve the outcome.\\n\\nAnd let's not forget about the creative possibilities of LLMs in bread-making. With the ability to generate new recipes and flavor combinations, the possibilities are endless! Imagine being able to create a unique loaf of bread that combines the flavors of your favorite childhood treats, or experimenting with different spices and herbs to create a one-of-a-kind bread.\\n\\nOf course, as with any new technology, there are also potential drawbacks to using LLMs in bread-making. For example, relying too heavily on automation could lead to a loss of touch and intuition when it comes to baking. And let's not forget the potential for errors or inconsistencies in the generated recipes - after all, no AI system is perfect!\\n\\nBut overall, I believe that LLMs have the potential to revolutionize the way we approach bread-making. By providing insights into the underlying principles of the process and generating new recipe ideas, they can help us create better loaves than ever before. And who knows - maybe one day we'll be able to create a bread-making AI that can rival even the most skilled human bakers!\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama2:latest\",\n",
      "              \"created_at\": \"2024-06-20T17:11:34.424953Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 18899417625,\n",
      "              \"load_duration\": 3585292,\n",
      "              \"prompt_eval_count\": 18,\n",
      "              \"prompt_eval_duration\": 364961000,\n",
      "              \"eval_count\": 632,\n",
      "              \"eval_duration\": 18528410000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-3c3a4a4a-18b6-44f9-864c-ba5038f6dc8c-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"\\nAs a baker, I can't help but think about the importance of mastering the art of bread-making. It's not just about mixing flour, water, yeast, and salt to create a delicious loaf - it's about understanding the science behind the process. And that's where LLMs come in.\\n\\nLLMs, or Large Language Models, are AI systems designed to process and generate human-like language. They have the potential to revolutionize the way we work, communicate, and create. But what does this have to do with bread-making? Well, let me tell you.\\n\\nAs a baker, I know that the key to creating the perfect loaf is not just about following a recipe, but understanding the underlying principles of bread-making. It's about knowing how yeast works, how dough develops, and how different ingredients interact with each other. And that's where LLMs come in.\\n\\nLLMs can help us understand these underlying principles by analyzing and generating text related to bread-making. They can provide insights into the chemical reactions that occur during the baking process, and even generate new recipes based on existing ones. Imagine being able to create a new loaf of bread simply by inputting a few ingredients and letting an LLM do the rest!\\n\\nBut the potential applications of LLMs in bread-making go beyond just generating new recipes. They can also help us troubleshoot problems that arise during the baking process. For example, if you're experiencing inconsistent rising times or uneven baking, an LLM could analyze your existing recipe and suggest adjustments to improve the outcome.\\n\\nAnd let's not forget about the creative possibilities of LLMs in bread-making. With the ability to generate new recipes and flavor combinations, the possibilities are endless! Imagine being able to create a unique loaf of bread that combines the flavors of your favorite childhood treats, or experimenting with different spices and herbs to create a one-of-a-kind bread.\\n\\nOf course, as with any new technology, there are also potential drawbacks to using LLMs in bread-making. For example, relying too heavily on automation could lead to a loss of touch and intuition when it comes to baking. And let's not forget the potential for errors or inconsistencies in the generated recipes - after all, no AI system is perfect!\\n\\nBut overall, I believe that LLMs have the potential to revolutionize the way we approach bread-making. By providing insights into the underlying principles of the process and generating new recipe ideas, they can help us create better loaves than ever before. And who knows - maybe one day we'll be able to create a bread-making AI that can rival even the most skilled human bakers!\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [18.91s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"\\nAs a baker, I can't help but think about the importance of mastering the art of bread-making. It's not just about mixing flour, water, yeast, and salt to create a delicious loaf - it's about understanding the science behind the process. And that's where LLMs come in.\\n\\nLLMs, or Large Language Models, are AI systems designed to process and generate human-like language. They have the potential to revolutionize the way we work, communicate, and create. But what does this have to do with bread-making? Well, let me tell you.\\n\\nAs a baker, I know that the key to creating the perfect loaf is not just about following a recipe, but understanding the underlying principles of bread-making. It's about knowing how yeast works, how dough develops, and how different ingredients interact with each other. And that's where LLMs come in.\\n\\nLLMs can help us understand these underlying principles by analyzing and generating text related to bread-making. They can provide insights into the chemical reactions that occur during the baking process, and even generate new recipes based on existing ones. Imagine being able to create a new loaf of bread simply by inputting a few ingredients and letting an LLM do the rest!\\n\\nBut the potential applications of LLMs in bread-making go beyond just generating new recipes. They can also help us troubleshoot problems that arise during the baking process. For example, if you're experiencing inconsistent rising times or uneven baking, an LLM could analyze your existing recipe and suggest adjustments to improve the outcome.\\n\\nAnd let's not forget about the creative possibilities of LLMs in bread-making. With the ability to generate new recipes and flavor combinations, the possibilities are endless! Imagine being able to create a unique loaf of bread that combines the flavors of your favorite childhood treats, or experimenting with different spices and herbs to create a one-of-a-kind bread.\\n\\nOf course, as with any new technology, there are also potential drawbacks to using LLMs in bread-making. For example, relying too heavily on automation could lead to a loss of touch and intuition when it comes to baking. And let's not forget the potential for errors or inconsistencies in the generated recipes - after all, no AI system is perfect!\\n\\nBut overall, I believe that LLMs have the potential to revolutionize the way we approach bread-making. By providing insights into the underlying principles of the process and generating new recipe ideas, they can help us create better loaves than ever before. And who knows - maybe one day we'll be able to create a bread-making AI that can rival even the most skilled human bakers!\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "output = chain.invoke({\"topic\": \"LLMs\", \"profession\": \"baker\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afddec07-55bf-447e-baac-52e43fdf58e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "As a baker, I can't help but think about the importance of mastering the art of bread-making. It's not just about mixing flour, water, yeast, and salt to create a delicious loaf - it's about understanding the science behind the process. And that's where LLMs come in.\n",
      "\n",
      "LLMs, or Large Language Models, are AI systems designed to process and generate human-like language. They have the potential to revolutionize the way we work, communicate, and create. But what does this have to do with bread-making? Well, let me tell you.\n",
      "\n",
      "As a baker, I know that the key to creating the perfect loaf is not just about following a recipe, but understanding the underlying principles of bread-making. It's about knowing how yeast works, how dough develops, and how different ingredients interact with each other. And that's where LLMs come in.\n",
      "\n",
      "LLMs can help us understand these underlying principles by analyzing and generating text related to bread-making. They can provide insights into the chemical reactions that occur during the baking process, and even generate new recipes based on existing ones. Imagine being able to create a new loaf of bread simply by inputting a few ingredients and letting an LLM do the rest!\n",
      "\n",
      "But the potential applications of LLMs in bread-making go beyond just generating new recipes. They can also help us troubleshoot problems that arise during the baking process. For example, if you're experiencing inconsistent rising times or uneven baking, an LLM could analyze your existing recipe and suggest adjustments to improve the outcome.\n",
      "\n",
      "And let's not forget about the creative possibilities of LLMs in bread-making. With the ability to generate new recipes and flavor combinations, the possibilities are endless! Imagine being able to create a unique loaf of bread that combines the flavors of your favorite childhood treats, or experimenting with different spices and herbs to create a one-of-a-kind bread.\n",
      "\n",
      "Of course, as with any new technology, there are also potential drawbacks to using LLMs in bread-making. For example, relying too heavily on automation could lead to a loss of touch and intuition when it comes to baking. And let's not forget the potential for errors or inconsistencies in the generated recipes - after all, no AI system is perfect!\n",
      "\n",
      "But overall, I believe that LLMs have the potential to revolutionize the way we approach bread-making. By providing insights into the underlying principles of the process and generating new recipe ideas, they can help us create better loaves than ever before. And who knows - maybe one day we'll be able to create a bread-making AI that can rival even the most skilled human bakers!\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25f78a5-ff07-4545-a92e-55857fb444da",
   "metadata": {},
   "source": [
    "## Streaming output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6298d49-8584-4d76-a762-48c39b373e9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"topic\": \"LLMs\",\n",
      "  \"profession\": \"deep sea diver\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Write me a 500 word article on LLMs from the perspective of a deep sea diver.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\n",
      "As a deep sea diver, I have had the privilege of exploring some of the most incredible and mysterious environments on Earth. From the vibrant coral reefs of the Caribbean to the icy waters of the Arctic, I have seen it all. But one thing that has always fascinated me is the world of LLMs – Large Marine Life.\n",
      "\n",
      "For those who may not be familiar, LLMs are large marine animals such as whales, dolphins, and sharks. These creatures are not only incredibly impressive in size and strength, but they also play a vital role in the health of our oceans. As a deep sea diver, I have had the opportunity to observe these magnificent creatures up close and personal, and let me tell you – it's a truly humbling experience.\n",
      "\n",
      "One of the most striking things about LLMs is their sheer size. A blue whale, for example, can grow up to 100 feet in length and weigh over 200 tons. That's bigger than a school bus, folks! And yet, despite their massive size, these creatures are incredibly graceful and agile in the water. It's like they were born to swim.\n",
      "\n",
      "But LLMs aren't just impressive for their size – they also play a crucial role in maintaining the balance of our oceans. They are apex predators, which means they sit at the top of their food chain and help regulate the populations of other marine animals. Without them, the ocean ecosystem would be vastly different and likely much less healthy.\n",
      "\n",
      "As a deep sea diver, I have had the privilege of observing LLMs in their natural habitat. And let me tell you – it's a truly magical experience. Watching a pod of dolphins play and swim together is like witnessing a symphony of movement and sound. And when you get up close and personal with a great white shark, you can't help but feel a sense of awe at the power and majesty of these creatures.\n",
      "\n",
      "But despite their incredible size and strength, LLMs are also incredibly vulnerable to threats such as overfishing, pollution, and climate change. As divers, we have seen firsthand the devastating impact that humans can have on marine ecosystems. And it's not just the LLMs themselves that are affected – their decline can have far-reaching consequences for the entire ocean ecosystem.\n",
      "\n",
      "So what can we do to help protect these incredible creatures and the oceans they call home? As divers, we can start by being mindful of our impact on the marine environment. This means avoiding areas that are known to be habitats for LLMs, and taking care not to disturb their natural habitats. We can also support organizations that work to protect these creatures and their environments, such as marine conservation groups and wildlife sanctuaries.\n",
      "\n",
      "But ultimately, the key to protecting LLMs is education and awareness. By sharing our experiences and knowledge with others, we can help raise awareness about the importance of these incredible creatures and the need to protect them. And who knows – maybe one day, we'll be able to share the oceans with these magnificent creatures once again.\n",
      "\n",
      "In conclusion, as a deep sea diver, I have had the privilege of experiencing the world of LLMs up close and personal. And let me tell you – it's a truly humbling experience. These incredible creatures are not only impressive in size and strength, but they also play a vital role in maintaining the health of our oceans. So let's do our part to protect them – for their sake, and for the sake of our planet's delicate ecosystem.\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [25.95s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\\nAs a deep sea diver, I have had the privilege of exploring some of the most incredible and mysterious environments on Earth. From the vibrant coral reefs of the Caribbean to the icy waters of the Arctic, I have seen it all. But one thing that has always fascinated me is the world of LLMs – Large Marine Life.\\n\\nFor those who may not be familiar, LLMs are large marine animals such as whales, dolphins, and sharks. These creatures are not only incredibly impressive in size and strength, but they also play a vital role in the health of our oceans. As a deep sea diver, I have had the opportunity to observe these magnificent creatures up close and personal, and let me tell you – it's a truly humbling experience.\\n\\nOne of the most striking things about LLMs is their sheer size. A blue whale, for example, can grow up to 100 feet in length and weigh over 200 tons. That's bigger than a school bus, folks! And yet, despite their massive size, these creatures are incredibly graceful and agile in the water. It's like they were born to swim.\\n\\nBut LLMs aren't just impressive for their size – they also play a crucial role in maintaining the balance of our oceans. They are apex predators, which means they sit at the top of their food chain and help regulate the populations of other marine animals. Without them, the ocean ecosystem would be vastly different and likely much less healthy.\\n\\nAs a deep sea diver, I have had the privilege of observing LLMs in their natural habitat. And let me tell you – it's a truly magical experience. Watching a pod of dolphins play and swim together is like witnessing a symphony of movement and sound. And when you get up close and personal with a great white shark, you can't help but feel a sense of awe at the power and majesty of these creatures.\\n\\nBut despite their incredible size and strength, LLMs are also incredibly vulnerable to threats such as overfishing, pollution, and climate change. As divers, we have seen firsthand the devastating impact that humans can have on marine ecosystems. And it's not just the LLMs themselves that are affected – their decline can have far-reaching consequences for the entire ocean ecosystem.\\n\\nSo what can we do to help protect these incredible creatures and the oceans they call home? As divers, we can start by being mindful of our impact on the marine environment. This means avoiding areas that are known to be habitats for LLMs, and taking care not to disturb their natural habitats. We can also support organizations that work to protect these creatures and their environments, such as marine conservation groups and wildlife sanctuaries.\\n\\nBut ultimately, the key to protecting LLMs is education and awareness. By sharing our experiences and knowledge with others, we can help raise awareness about the importance of these incredible creatures and the need to protect them. And who knows – maybe one day, we'll be able to share the oceans with these magnificent creatures once again.\\n\\nIn conclusion, as a deep sea diver, I have had the privilege of experiencing the world of LLMs up close and personal. And let me tell you – it's a truly humbling experience. These incredible creatures are not only impressive in size and strength, but they also play a vital role in maintaining the health of our oceans. So let's do our part to protect them – for their sake, and for the sake of our planet's delicate ecosystem.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama2:latest\",\n",
      "          \"created_at\": \"2024-06-20T17:25:31.068985Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 25941730250,\n",
      "          \"load_duration\": 4988000,\n",
      "          \"prompt_eval_count\": 9,\n",
      "          \"prompt_eval_duration\": 359264000,\n",
      "          \"eval_count\": 843,\n",
      "          \"eval_duration\": 25575365000\n",
      "        },\n",
      "        \"type\": \"ChatGenerationChunk\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessageChunk\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\\nAs a deep sea diver, I have had the privilege of exploring some of the most incredible and mysterious environments on Earth. From the vibrant coral reefs of the Caribbean to the icy waters of the Arctic, I have seen it all. But one thing that has always fascinated me is the world of LLMs – Large Marine Life.\\n\\nFor those who may not be familiar, LLMs are large marine animals such as whales, dolphins, and sharks. These creatures are not only incredibly impressive in size and strength, but they also play a vital role in the health of our oceans. As a deep sea diver, I have had the opportunity to observe these magnificent creatures up close and personal, and let me tell you – it's a truly humbling experience.\\n\\nOne of the most striking things about LLMs is their sheer size. A blue whale, for example, can grow up to 100 feet in length and weigh over 200 tons. That's bigger than a school bus, folks! And yet, despite their massive size, these creatures are incredibly graceful and agile in the water. It's like they were born to swim.\\n\\nBut LLMs aren't just impressive for their size – they also play a crucial role in maintaining the balance of our oceans. They are apex predators, which means they sit at the top of their food chain and help regulate the populations of other marine animals. Without them, the ocean ecosystem would be vastly different and likely much less healthy.\\n\\nAs a deep sea diver, I have had the privilege of observing LLMs in their natural habitat. And let me tell you – it's a truly magical experience. Watching a pod of dolphins play and swim together is like witnessing a symphony of movement and sound. And when you get up close and personal with a great white shark, you can't help but feel a sense of awe at the power and majesty of these creatures.\\n\\nBut despite their incredible size and strength, LLMs are also incredibly vulnerable to threats such as overfishing, pollution, and climate change. As divers, we have seen firsthand the devastating impact that humans can have on marine ecosystems. And it's not just the LLMs themselves that are affected – their decline can have far-reaching consequences for the entire ocean ecosystem.\\n\\nSo what can we do to help protect these incredible creatures and the oceans they call home? As divers, we can start by being mindful of our impact on the marine environment. This means avoiding areas that are known to be habitats for LLMs, and taking care not to disturb their natural habitats. We can also support organizations that work to protect these creatures and their environments, such as marine conservation groups and wildlife sanctuaries.\\n\\nBut ultimately, the key to protecting LLMs is education and awareness. By sharing our experiences and knowledge with others, we can help raise awareness about the importance of these incredible creatures and the need to protect them. And who knows – maybe one day, we'll be able to share the oceans with these magnificent creatures once again.\\n\\nIn conclusion, as a deep sea diver, I have had the privilege of experiencing the world of LLMs up close and personal. And let me tell you – it's a truly humbling experience. These incredible creatures are not only impressive in size and strength, but they also play a vital role in maintaining the health of our oceans. So let's do our part to protect them – for their sake, and for the sake of our planet's delicate ecosystem.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama2:latest\",\n",
      "              \"created_at\": \"2024-06-20T17:25:31.068985Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 25941730250,\n",
      "              \"load_duration\": 4988000,\n",
      "              \"prompt_eval_count\": 9,\n",
      "              \"prompt_eval_duration\": 359264000,\n",
      "              \"eval_count\": 843,\n",
      "              \"eval_duration\": 25575365000\n",
      "            },\n",
      "            \"type\": \"AIMessageChunk\",\n",
      "            \"id\": \"run-35ce968d-bc18-4e9b-acd9-c041caab0af7\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [25.60s] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"\\nAs a deep sea diver, I have had the privilege of exploring some of the most incredible and mysterious environments on Earth. From the vibrant coral reefs of the Caribbean to the icy waters of the Arctic, I have seen it all. But one thing that has always fascinated me is the world of LLMs – Large Marine Life.\\n\\nFor those who may not be familiar, LLMs are large marine animals such as whales, dolphins, and sharks. These creatures are not only incredibly impressive in size and strength, but they also play a vital role in the health of our oceans. As a deep sea diver, I have had the opportunity to observe these magnificent creatures up close and personal, and let me tell you – it's a truly humbling experience.\\n\\nOne of the most striking things about LLMs is their sheer size. A blue whale, for example, can grow up to 100 feet in length and weigh over 200 tons. That's bigger than a school bus, folks! And yet, despite their massive size, these creatures are incredibly graceful and agile in the water. It's like they were born to swim.\\n\\nBut LLMs aren't just impressive for their size – they also play a crucial role in maintaining the balance of our oceans. They are apex predators, which means they sit at the top of their food chain and help regulate the populations of other marine animals. Without them, the ocean ecosystem would be vastly different and likely much less healthy.\\n\\nAs a deep sea diver, I have had the privilege of observing LLMs in their natural habitat. And let me tell you – it's a truly magical experience. Watching a pod of dolphins play and swim together is like witnessing a symphony of movement and sound. And when you get up close and personal with a great white shark, you can't help but feel a sense of awe at the power and majesty of these creatures.\\n\\nBut despite their incredible size and strength, LLMs are also incredibly vulnerable to threats such as overfishing, pollution, and climate change. As divers, we have seen firsthand the devastating impact that humans can have on marine ecosystems. And it's not just the LLMs themselves that are affected – their decline can have far-reaching consequences for the entire ocean ecosystem.\\n\\nSo what can we do to help protect these incredible creatures and the oceans they call home? As divers, we can start by being mindful of our impact on the marine environment. This means avoiding areas that are known to be habitats for LLMs, and taking care not to disturb their natural habitats. We can also support organizations that work to protect these creatures and their environments, such as marine conservation groups and wildlife sanctuaries.\\n\\nBut ultimately, the key to protecting LLMs is education and awareness. By sharing our experiences and knowledge with others, we can help raise awareness about the importance of these incredible creatures and the need to protect them. And who knows – maybe one day, we'll be able to share the oceans with these magnificent creatures once again.\\n\\nIn conclusion, as a deep sea diver, I have had the privilege of experiencing the world of LLMs up close and personal. And let me tell you – it's a truly humbling experience. These incredible creatures are not only impressive in size and strength, but they also play a vital role in maintaining the health of our oceans. So let's do our part to protect them – for their sake, and for the sake of our planet's delicate ecosystem.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [25.98s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"\\nAs a deep sea diver, I have had the privilege of exploring some of the most incredible and mysterious environments on Earth. From the vibrant coral reefs of the Caribbean to the icy waters of the Arctic, I have seen it all. But one thing that has always fascinated me is the world of LLMs – Large Marine Life.\\n\\nFor those who may not be familiar, LLMs are large marine animals such as whales, dolphins, and sharks. These creatures are not only incredibly impressive in size and strength, but they also play a vital role in the health of our oceans. As a deep sea diver, I have had the opportunity to observe these magnificent creatures up close and personal, and let me tell you – it's a truly humbling experience.\\n\\nOne of the most striking things about LLMs is their sheer size. A blue whale, for example, can grow up to 100 feet in length and weigh over 200 tons. That's bigger than a school bus, folks! And yet, despite their massive size, these creatures are incredibly graceful and agile in the water. It's like they were born to swim.\\n\\nBut LLMs aren't just impressive for their size – they also play a crucial role in maintaining the balance of our oceans. They are apex predators, which means they sit at the top of their food chain and help regulate the populations of other marine animals. Without them, the ocean ecosystem would be vastly different and likely much less healthy.\\n\\nAs a deep sea diver, I have had the privilege of observing LLMs in their natural habitat. And let me tell you – it's a truly magical experience. Watching a pod of dolphins play and swim together is like witnessing a symphony of movement and sound. And when you get up close and personal with a great white shark, you can't help but feel a sense of awe at the power and majesty of these creatures.\\n\\nBut despite their incredible size and strength, LLMs are also incredibly vulnerable to threats such as overfishing, pollution, and climate change. As divers, we have seen firsthand the devastating impact that humans can have on marine ecosystems. And it's not just the LLMs themselves that are affected – their decline can have far-reaching consequences for the entire ocean ecosystem.\\n\\nSo what can we do to help protect these incredible creatures and the oceans they call home? As divers, we can start by being mindful of our impact on the marine environment. This means avoiding areas that are known to be habitats for LLMs, and taking care not to disturb their natural habitats. We can also support organizations that work to protect these creatures and their environments, such as marine conservation groups and wildlife sanctuaries.\\n\\nBut ultimately, the key to protecting LLMs is education and awareness. By sharing our experiences and knowledge with others, we can help raise awareness about the importance of these incredible creatures and the need to protect them. And who knows – maybe one day, we'll be able to share the oceans with these magnificent creatures once again.\\n\\nIn conclusion, as a deep sea diver, I have had the privilege of experiencing the world of LLMs up close and personal. And let me tell you – it's a truly humbling experience. These incredible creatures are not only impressive in size and strength, but they also play a vital role in maintaining the health of our oceans. So let's do our part to protect them – for their sake, and for the sake of our planet's delicate ecosystem.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for chunk in chain.stream({\"topic\": \"LLMs\", \"profession\": \"deep sea diver\"}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac4f48f-513e-47d0-915e-cac8490700e3",
   "metadata": {},
   "source": [
    "## Part2: Define json schema that the LLM output should follow.\n",
    "## Very important when creating agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e46f194-055d-4217-a7a6-9383527fab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema = {\n",
    "    \"title\": \"Person\",\n",
    "    \"description\": \"Identifying information about a person\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"name\": {\"title\": \"Name\", \"description\": \"The person's name\", \"type\": \"string\"},\n",
    "        \"age\": {\"title\": \"Age\", \"description\": \"The person's age\", \"type\": \"integer\"},\n",
    "        \"city\": {\"title\": \"City\", \"description\": \"The person's city\", \"type\": \"string\"},\n",
    "        \"fav_food\": {\n",
    "            \"title\": \"Fav Food\",\n",
    "            \"description\": \"The person's favourite food\",\n",
    "            \"type\": \"string\"\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"name\", \"age\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d7a8824-cb43-482f-b1f3-31cf6e2fe32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Keep format as json that increase the chances that the llm is outputing json. It is not guaranteed\n",
    "json_local_llm = ChatOllama(model=\"llama2:latest\", format=\"json\", keep_alive=-1, temperature=0.1, max_new_tokens=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03401525-ab24-4a4c-bc39-c0037254b7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The messages will be used to create a prompt template\n",
    "json_messages = [\n",
    "    HumanMessage(content=\"Please tell me about the person using the following JSON schema:\"),\n",
    "    HumanMessage(content=\"{schema}\"),\n",
    "    HumanMessage(content=\"Considering the above mentioned schema, tell me about a person named Oliver who lives in Toronto, aged 32 and likes Biryani\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8728a674-7d1a-4ff9-8153-030aec8f922c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=[] messages=[HumanMessage(content='Please tell me about the person using the following JSON schema:'), HumanMessage(content='{schema}'), HumanMessage(content='Considering the above mentioned schema, tell me about a person named Oliver who lives in Toronto, aged 32 and likes Biryani')]\n"
     ]
    }
   ],
   "source": [
    "json_based_prompt = ChatPromptTemplate.from_messages(json_messages)\n",
    "print(json_based_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412fa602-7718-42be-bd88-08b0b43d0e88",
   "metadata": {},
   "source": [
    "json_dumps = json.dumps(json_schema, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e21d5e08-dfbc-4ffa-9742-ba779991503c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"schema\": \"{\\n  \\\"title\\\": \\\"Person\\\",\\n  \\\"description\\\": \\\"Identifying information about a person\\\",\\n  \\\"type\\\": \\\"object\\\",\\n  \\\"properties\\\": {\\n    \\\"name\\\": {\\n      \\\"title\\\": \\\"Name\\\",\\n      \\\"description\\\": \\\"The person's name\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    },\\n    \\\"age\\\": {\\n      \\\"title\\\": \\\"Age\\\",\\n      \\\"description\\\": \\\"The person's age\\\",\\n      \\\"type\\\": \\\"integer\\\"\\n    },\\n    \\\"city\\\": {\\n      \\\"title\\\": \\\"City\\\",\\n      \\\"description\\\": \\\"The person's city\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    },\\n    \\\"fav_food\\\": {\\n      \\\"title\\\": \\\"Fav Food\\\",\\n      \\\"description\\\": \\\"The person's favourite food\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    }\\n  },\\n  \\\"required\\\": [\\n    \\\"name\\\",\\n    \\\"age\\\"\\n  ]\\n}\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"schema\": \"{\\n  \\\"title\\\": \\\"Person\\\",\\n  \\\"description\\\": \\\"Identifying information about a person\\\",\\n  \\\"type\\\": \\\"object\\\",\\n  \\\"properties\\\": {\\n    \\\"name\\\": {\\n      \\\"title\\\": \\\"Name\\\",\\n      \\\"description\\\": \\\"The person's name\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    },\\n    \\\"age\\\": {\\n      \\\"title\\\": \\\"Age\\\",\\n      \\\"description\\\": \\\"The person's age\\\",\\n      \\\"type\\\": \\\"integer\\\"\\n    },\\n    \\\"city\\\": {\\n      \\\"title\\\": \\\"City\\\",\\n      \\\"description\\\": \\\"The person's city\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    },\\n    \\\"fav_food\\\": {\\n      \\\"title\\\": \\\"Fav Food\\\",\\n      \\\"description\\\": \\\"The person's favourite food\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    }\\n  },\\n  \\\"required\\\": [\\n    \\\"name\\\",\\n    \\\"age\\\"\\n  ]\\n}\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Please tell me about the person using the following JSON schema:\\nHuman: {schema}\\nHuman: Considering the above mentioned schema, tell me about a person named Oliver who lives in Toronto, aged 32 and likes Biryani\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [4.64s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\n\\\"name\\\": \\\"Oliver\\\",\\n\\\"age\\\": 32,\\n\\\"city\\\": \\\"Toronto\\\",\\n\\\"interests\\\": [\\n\\\"Biryani\\\"\\n]\\n}\\n\\n\\n\\n\\n\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama2:latest\",\n",
      "          \"created_at\": \"2024-06-20T17:47:14.021753Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 4630326000,\n",
      "          \"load_duration\": 6908375,\n",
      "          \"prompt_eval_count\": 88,\n",
      "          \"prompt_eval_duration\": 3278411000,\n",
      "          \"eval_count\": 48,\n",
      "          \"eval_duration\": 1338015000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\n\\\"name\\\": \\\"Oliver\\\",\\n\\\"age\\\": 32,\\n\\\"city\\\": \\\"Toronto\\\",\\n\\\"interests\\\": [\\n\\\"Biryani\\\"\\n]\\n}\\n\\n\\n\\n\\n\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama2:latest\",\n",
      "              \"created_at\": \"2024-06-20T17:47:14.021753Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 4630326000,\n",
      "              \"load_duration\": 6908375,\n",
      "              \"prompt_eval_count\": 88,\n",
      "              \"prompt_eval_duration\": 3278411000,\n",
      "              \"eval_count\": 48,\n",
      "              \"eval_duration\": 1338015000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-de91f38c-f90a-46fa-bdc5-70c002d975d1-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] [2ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"name\": \"Oliver\",\n",
      "  \"age\": 32,\n",
      "  \"city\": \"Toronto\",\n",
      "  \"interests\": [\n",
      "    \"Biryani\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [4.65s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"name\": \"Oliver\",\n",
      "  \"age\": 32,\n",
      "  \"city\": \"Toronto\",\n",
      "  \"interests\": [\n",
      "    \"Biryani\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "json_chain = json_based_prompt | json_local_llm |  JsonOutputParser()\n",
    "json_response = json_chain.invoke({\"schema\": json_dumps})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "891aad09-e0ce-4585-817e-686bdfee13f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(json_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "12eed721-e4b2-4177-9681-e45c8e3f5c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Oliver', 'age': 32, 'city': 'Toronto', 'interests': ['Biryani']}\n"
     ]
    }
   ],
   "source": [
    "print(json_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e0922c-f902-452c-9b4c-e99a4abf438a",
   "metadata": {},
   "source": [
    "## Part 3: Pydantic data model that the LLM output should follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3b296bbe-5cd8-4a10-9b67-4f6d055a30b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Data model\n",
    "class Person(BaseModel):\n",
    "    name: str = Field(description=\"The person's name\", required=True)\n",
    "    age: int = Field(description=\"The person's age\", required=True)\n",
    "    city: str = Field(description=\"The person's city\", required=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7f78a474-428f-4ae4-8782-167737971a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_parser = PydanticOutputParser(pydantic_object=Person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ceab8f9c-f866-448d-9180-89595775853a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"name\": {\"title\": \"Name\", \"description\": \"The person's name\", \"required\": true, \"type\": \"string\"}, \"age\": {\"title\": \"Age\", \"description\": \"The person's age\", \"required\": true, \"type\": \"integer\"}, \"city\": {\"title\": \"City\", \"description\": \"The person's city\", \"required\": true, \"type\": \"string\"}}, \"required\": [\"name\", \"age\", \"city\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(person_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c807aa5-b872-4ca1-bc4c-342f812b543b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_model_prompt = ChatPromptTemplate.from_template(\"\"\"You are a smart assistant who takes the following context and question and returns answer in JSON\\n Context: {context} \\n Question: {question}\\n \"\"\")\n",
    "\n",
    "# data_model_prompt.invoke({\"question\": \"Extract information for person described in context\", \"context\": \"I know someone named Oliver who lives in Toronto, aged 32 and likes Biryani\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6205e1cc-e3ae-4ad1-9a7b-d5c3be0a7e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model_prompt = PromptTemplate(\n",
    "    template=\"Answer the user query with the following instructions and given context.\\n{format_instructions}\\n Context: {context} \\n Question: {question}\\n\",\n",
    "    input_variables=[\"query\", \"context\"],\n",
    "    partial_variables={\"format_instructions\": person_parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "63bd1839-68e4-4f74-b5ca-a93f4e2894fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "experimental_local_llm = OllamaFunctions(model=\"llama2:latest\", format=\"json\", temperature=0)#.with_structured_output(Joke)\n",
    "experimental_person_structured_local_llm = experimental_local_llm.with_structured_output(Person)\n",
    "experiental_chain = data_model_prompt | experimental_person_structured_local_llm |  StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "239c36b8-628b-4e4a-af81-fe7e13760a94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Extract information for person described in context\",\n",
      "  \"context\": \"I know someone named Oliver who lives in Toronto, aged 32 and likes Biryani\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Extract information for person described in context\",\n",
      "  \"context\": \"I know someone named Oliver who lives in Toronto, aged 32 and likes Biryani\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:OllamaFunctions] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Answer the user query with the following instructions and given context.\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\\\"properties\\\": {\\\"foo\\\": {\\\"title\\\": \\\"Foo\\\", \\\"description\\\": \\\"a list of strings\\\", \\\"type\\\": \\\"array\\\", \\\"items\\\": {\\\"type\\\": \\\"string\\\"}}}, \\\"required\\\": [\\\"foo\\\"]}\\nthe object {\\\"foo\\\": [\\\"bar\\\", \\\"baz\\\"]} is a well-formatted instance of the schema. The object {\\\"properties\\\": {\\\"foo\\\": [\\\"bar\\\", \\\"baz\\\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\\\"properties\\\": {\\\"name\\\": {\\\"title\\\": \\\"Name\\\", \\\"description\\\": \\\"The person's name\\\", \\\"required\\\": true, \\\"type\\\": \\\"string\\\"}, \\\"age\\\": {\\\"title\\\": \\\"Age\\\", \\\"description\\\": \\\"The person's age\\\", \\\"required\\\": true, \\\"type\\\": \\\"integer\\\"}, \\\"city\\\": {\\\"title\\\": \\\"City\\\", \\\"description\\\": \\\"The person's city\\\", \\\"required\\\": true, \\\"type\\\": \\\"string\\\"}}, \\\"required\\\": [\\\"name\\\", \\\"age\\\", \\\"city\\\"]}\\n```\\n Context: I know someone named Oliver who lives in Toronto, aged 32 and likes Biryani \\n Question: Extract information for person described in context\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:OllamaFunctions] [1.67s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-3885665e-15c9-416c-8ad7-88cb7a7e2576-0\",\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"name\": \"Person\",\n",
      "                \"args\": {\n",
      "                  \"name\": \"Oliver\",\n",
      "                  \"age\": 32,\n",
      "                  \"city\": \"Toronto\"\n",
      "                },\n",
      "                \"id\": \"call_d8fdea010fef4ed8bbbc77aa890a233a\"\n",
      "              }\n",
      "            ],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:parse_response] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:parse_response] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"{\\\"name\\\": \\\"Oliver\\\", \\\"age\\\": 32, \\\"city\\\": \\\"Toronto\\\"}\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:PydanticOutputParser] Entering Parser run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"{\\\"name\\\": \\\"Oliver\\\", \\\"age\\\": 32, \\\"city\\\": \\\"Toronto\\\"}\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:PydanticOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [1ms] Parser run errored with error:\n",
      "\u001b[0m\"ValidationError(model='Generation', errors=[{'loc': ('text',), 'msg': 'str type expected', 'type': 'type_error.str'}])Traceback (most recent call last):\\n\\n\\n  File \\\"/Users/hardiksahi/miniconda3/envs/rag_env/lib/python3.11/site-packages/langchain_core/runnables/base.py\\\", line 1509, in _call_with_config\\n    print(runnable.map().invoke([1, 2, 3])) # [2, 3, 4]\\n\\n\\n  File \\\"/Users/hardiksahi/miniconda3/envs/rag_env/lib/python3.11/site-packages/langchain_core/runnables/config.py\\\", line 366, in call_func_with_variable_args\\n    pass to the function.\\n\\n\\n  File \\\"/Users/hardiksahi/miniconda3/envs/rag_env/lib/python3.11/site-packages/langchain_core/output_parsers/base.py\\\", line 179, in <lambda>\\n    lambda inner_input: self.parse_result([Generation(text=inner_input)]),\\n                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"/Users/hardiksahi/miniconda3/envs/rag_env/lib/python3.11/site-packages/pydantic/v1/main.py\\\", line 341, in __init__\\n    raise validation_error\\n\\n\\npydantic.v1.error_wrappers.ValidationError: 1 validation error for Generation\\ntext\\n  str type expected (type=type_error.str)\"\n",
      "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[chain:RunnableSequence] [1.68s] Chain run errored with error:\n",
      "\u001b[0m\"ValidationError(model='Generation', errors=[{'loc': ('text',), 'msg': 'str type expected', 'type': 'type_error.str'}])Traceback (most recent call last):\\n\\n\\n  File \\\"/Users/hardiksahi/miniconda3/envs/rag_env/lib/python3.11/site-packages/langchain_core/runnables/base.py\\\", line 2408, in invoke\\n    step_first_node, _ = graph.extend(step_graph)\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"/Users/hardiksahi/miniconda3/envs/rag_env/lib/python3.11/site-packages/langchain_core/output_parsers/base.py\\\", line 178, in invoke\\n    return self._call_with_config(\\n           ^^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"/Users/hardiksahi/miniconda3/envs/rag_env/lib/python3.11/site-packages/langchain_core/runnables/base.py\\\", line 1509, in _call_with_config\\n    print(runnable.map().invoke([1, 2, 3])) # [2, 3, 4]\\n\\n\\n  File \\\"/Users/hardiksahi/miniconda3/envs/rag_env/lib/python3.11/site-packages/langchain_core/runnables/config.py\\\", line 366, in call_func_with_variable_args\\n    pass to the function.\\n\\n\\n  File \\\"/Users/hardiksahi/miniconda3/envs/rag_env/lib/python3.11/site-packages/langchain_core/output_parsers/base.py\\\", line 179, in <lambda>\\n    lambda inner_input: self.parse_result([Generation(text=inner_input)]),\\n                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"/Users/hardiksahi/miniconda3/envs/rag_env/lib/python3.11/site-packages/pydantic/v1/main.py\\\", line 341, in __init__\\n    raise validation_error\\n\\n\\npydantic.v1.error_wrappers.ValidationError: 1 validation error for Generation\\ntext\\n  str type expected (type=type_error.str)\"\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Generation\ntext\n  str type expected (type=type_error.str)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m experiental_response \u001b[38;5;241m=\u001b[39m \u001b[43mexperiental_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mExtract information for person described in context\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mI know someone named Oliver who lives in Toronto, aged 32 and likes Biryani\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rag_env/lib/python3.11/site-packages/langchain_core/runnables/base.py:2408\u001b[0m, in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast:\n\u001b[1;32m   2407\u001b[0m     step_graph\u001b[38;5;241m.\u001b[39mtrim_last_node()\n\u001b[0;32m-> 2408\u001b[0m step_first_node, _ \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mextend(step_graph)\n\u001b[1;32m   2409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m step_first_node:\n\u001b[1;32m   2410\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunnable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no first node\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/rag_env/lib/python3.11/site-packages/langchain_core/output_parsers/base.py:178\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result(\n\u001b[1;32m    171\u001b[0m             [ChatGeneration(message\u001b[38;5;241m=\u001b[39minner_input)]\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    175\u001b[0m         run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    176\u001b[0m     )\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rag_env/lib/python3.11/site-packages/langchain_core/runnables/base.py:1509\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1505\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1506\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m   1507\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1508\u001b[0m         Output,\n\u001b[0;32m-> 1509\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1510\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1511\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1512\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1513\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1514\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1515\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1516\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1517\u001b[0m     )\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1519\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/miniconda3/envs/rag_env/lib/python3.11/site-packages/langchain_core/runnables/config.py:366\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    365\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 366\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rag_env/lib/python3.11/site-packages/langchain_core/output_parsers/base.py:179\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke.<locals>.<lambda>\u001b[0;34m(inner_input)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result(\n\u001b[1;32m    171\u001b[0m             [ChatGeneration(message\u001b[38;5;241m=\u001b[39minner_input)]\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    175\u001b[0m         run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    176\u001b[0m     )\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result([\u001b[43mGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m]),\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    181\u001b[0m         config,\n\u001b[1;32m    182\u001b[0m         run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    183\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/rag_env/lib/python3.11/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for Generation\ntext\n  str type expected (type=type_error.str)"
     ]
    }
   ],
   "source": [
    "experiental_response = experiental_chain.invoke({\"question\": \"Extract information for person described in context\", \"context\": \"I know someone named Oliver who lives in Toronto, aged 32 and likes Biryani\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c3836d51-b92b-4540-aacd-d533dc6cf757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Oliver' age=32 city='Toronto'\n"
     ]
    }
   ],
   "source": [
    "print(experiental_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "714b14a7-f1c7-4b45-8e17-1593574a6c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='Oliver', age=32, city='Toronto')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Interesting: https://stackoverflow.com/questions/78591465/unexpected-string-validation-error-in-langchain-pydantic-output-parser\n",
    "Person.parse_obj(experiental_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ec7f83-f4f5-4ae2-aa37-818926364972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a868b8-6518-4c15-ac55-539da56149a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8fa92c-e001-40a5-a1b3-5c7e24978fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988d5ac4-cb1a-4fbd-a4ed-ffc7389e078c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078b5187-2989-4918-b96f-57ce79ff52cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7298756d-9b59-4f38-83dc-46d8df1132f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c0922c-9588-4b8a-b6d9-c1b7383b03ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf00ffa-1b80-47ed-96ef-321a02ab7ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4efe18-790b-4304-9f79-be9d91e5122b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a5ff2341-fa6a-43a7-b3ad-f0d84d35eee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to setup a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "joke_query = \"Tell me a joke\"\n",
    "joke_parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "joke_prompt = PromptTemplate(template = \"Answer the user query. \\n{format_instructions}\\n{query}\\n\", input_variables=[\"query\"], partial_variables={\"format_instructions\": joke_parser.get_format_instructions()})\n",
    "\n",
    "joke_chain = joke_prompt | structured_local_llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b581a77e-1eca-40af-a0a8-85f12e0c526c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"Tell me a joke\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='Answer the user query. \\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"setup\": {\"title\": \"Setup\", \"description\": \"question to setup a joke\", \"type\": \"string\"}, \"punchline\": {\"title\": \"Punchline\", \"description\": \"answer to resolve the joke\", \"type\": \"string\"}}, \"required\": [\"setup\", \"punchline\"]}\\n```\\nTell me a joke\\n')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke_prompt.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a79669db-110b-4a9c-8604-3aa863ae7b40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"Tell me a joke\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"Tell me a joke\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:OllamaFunctions] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Answer the user query. \\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\\\"properties\\\": {\\\"foo\\\": {\\\"title\\\": \\\"Foo\\\", \\\"description\\\": \\\"a list of strings\\\", \\\"type\\\": \\\"array\\\", \\\"items\\\": {\\\"type\\\": \\\"string\\\"}}}, \\\"required\\\": [\\\"foo\\\"]}\\nthe object {\\\"foo\\\": [\\\"bar\\\", \\\"baz\\\"]} is a well-formatted instance of the schema. The object {\\\"properties\\\": {\\\"foo\\\": [\\\"bar\\\", \\\"baz\\\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\\\"properties\\\": {\\\"setup\\\": {\\\"title\\\": \\\"Setup\\\", \\\"description\\\": \\\"question to setup a joke\\\", \\\"type\\\": \\\"string\\\"}, \\\"punchline\\\": {\\\"title\\\": \\\"Punchline\\\", \\\"description\\\": \\\"answer to resolve the joke\\\", \\\"type\\\": \\\"string\\\"}}, \\\"required\\\": [\\\"setup\\\", \\\"punchline\\\"]}\\n```\\nTell me a joke\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:OllamaFunctions] [2.04s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-77129080-2b0b-4c08-bec9-98e73c58b15c-0\",\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"name\": \"Joke\",\n",
      "                \"args\": {\n",
      "                  \"setup\": \"Why was the math book sad? Because it had too many problems.\",\n",
      "                  \"punchline\": \"Get it? Problems!\"\n",
      "                },\n",
      "                \"id\": \"call_068166d2cc2447d7a0ad2dfb6ce0502d\"\n",
      "              }\n",
      "            ],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:parse_response] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:parse_response] [4ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"{\\\"setup\\\": \\\"Why was the math book sad? Because it had too many problems.\\\", \\\"punchline\\\": \\\"Get it? Problems!\\\"}\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:PydanticOutputParser] Entering Parser run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"{\\\"setup\\\": \\\"Why was the math book sad? Because it had too many problems.\\\", \\\"punchline\\\": \\\"Get it? Problems!\\\"}\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:PydanticOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [2.05s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Joke(setup='Why was the math book sad? Because it had too many problems.', punchline='Get it? Problems!')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Joke.parse_obj(joke_chain.invoke({\"query\": joke_query}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebd319d-5747-4aa9-b567-c28879e4e485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191aa88a-c131-4264-9c7f-6a3a5d614f19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6246b6-f426-4777-96ab-665149f793e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0a8d26-86c8-4cc9-b781-19f457e48abc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87194ebe-1dbb-4e41-8d74-4d84b4570945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ec0c47f-cafe-428e-a054-fb8873bfaebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51d61a18-00f4-42d9-97bb-0afc33b0677b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e3b64e-baf7-4ae1-89fd-ec6908bf2cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "rag_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
