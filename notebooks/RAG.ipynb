{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a02c77c-b776-4445-8d79-c75b956e06e6",
   "metadata": {},
   "source": [
    "Follows steps in https://www.youtube.com/watch?v=sVcwVQRHIc8&t=2s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397722b9-d6ba-40d7-85d5-4e3c123cb08e",
   "metadata": {},
   "source": [
    "Part 1: https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_1_to_4.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62162c47-10aa-42f5-b9e1-47c36f933298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "from tiktoken._educational import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fd141b6-b7af-446e-ad05-21d067de9041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9e0afcd-2b23-4472-84f2-6290d2f0ef7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "4c92304f-a84e-4179-aa82-a5ba5784a909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import WebBaseLoader, YoutubeLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7351099a-ddb1-4fc2-b1eb-0d65adc84410",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27f52546-13bf-48e3-b6cb-6bb475b09749",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6ef917c-2c3b-4c0c-9424-219223928738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46515cc1-1eb5-4e50-883b-6123a9804903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0fbab9e-f847-4ed5-8999-276086510142",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ChatPromptTemplate: Creates a chat template consisting of a single message assumed to be from the human (https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)\n",
    "from langchain.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "816a8bca-169b-49da-b46e-7d9f90181ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c29f126-a3a0-47f9-889b-a0957dd170eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "18fa10e1-8eb4-433d-a0f7-c20d3d969db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser, PydanticOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e01c18bc-c491-4f2f-a54b-ad77ccd45a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65261d94-24dc-451c-8c26-54056ca8cccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.load import dumps, loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f578d387-5b80-49f1-831d-b1a76a3ae424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "351d037c-7fce-420b-9c4c-14add2d6cf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "a2ee53cf-f453-4437-8593-c9c2963b6467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, Optional, Tuple\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "47c128dd-c318-4131-b2e1-489704b348f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utils.math import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "30d99108-d4ac-40b0-9290-70461f254427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "d4275cff-f4db-4c47-bd5a-1cdbe5be29e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "81a47055-4127-4341-ad8f-971d479ec1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec0fd6f-6978-4352-a85b-34a89f9993e2",
   "metadata": {},
   "source": [
    "## Get embeddings model (SentenceBERT) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36f462fa-2cea-49fb-9579-57944e59c3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sentence BERT for sentence embeddings\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0af948-e33d-42b8-bddc-64eea02f2973",
   "metadata": {},
   "source": [
    "## Get embeddings model (Nomic embddings)\n",
    "## Original : https://blog.nomic.ai/posts/nomic-embed-text-v1, https://static.nomic.ai/reports/2024_Nomic_Embed_Text_Technical_Report.pdf\n",
    "## https://huggingface.co/nomic-ai/nomic-embed-text-v1\n",
    "## https://api.python.langchain.com/en/latest/embeddings/langchain_community.embeddings.huggingface.HuggingFaceBgeEmbeddings.html#langchain_community.embeddings.huggingface.HuggingFaceBgeEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "021e5190-2fe5-4ab4-bfef-a271fb70fa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "## nomic-embed-text-v1\tis 8192 seq len embedder that is open source\n",
    "model_name = \"nomic-ai/nomic-embed-text-v1\"\n",
    "model_kwargs = {\n",
    "    'device': 'cpu',\n",
    "    'trust_remote_code':True\n",
    "    }\n",
    "encode_kwargs = {'normalize_embeddings': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2684cb69-8383-461a-987a-05e9d84180dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hardiksahi/miniconda3/envs/rag_env/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/Users/hardiksahi/miniconda3/envs/rag_env/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "WARNING:transformers_modules.nomic-ai.nomic-bert-2048.e55a7d4324f65581af5f483e830b80f34680e8ff.modeling_hf_nomic_bert:<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceBgeEmbeddings(model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs, query_instruction=\"search_query:\", embed_instruction=\"search_document:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eaf67404-154b-4126-aae0-0fb7bf2b5ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What kinds of pets do I like?\"\n",
    "document = \"My favorite pet is a cat.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "921db44f-9466-48a5-95ef-4cbd89939ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionality of question_embedding: 768\n",
      "Dimensionality of document_embedding: 768\n"
     ]
    }
   ],
   "source": [
    "question_embedding = embeddings.embed_query(question)\n",
    "document_embedding = embeddings.embed_query(document)\n",
    "print(f\"Dimensionality of question_embedding: {len(question_embedding)}\")\n",
    "print(f\"Dimensionality of document_embedding: {len(document_embedding)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506cd46d-5025-4f43-9eb1-91d27f743640",
   "metadata": {},
   "source": [
    "## Define similarity metric (cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "918c90dc-ef9c-4c70-bed6-be66e964af49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product/(norm_vec1*norm_vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55252c68-7ad8-4ede-b024-09edcb053fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between questiona dn document: 0.7388467122620958\n"
     ]
    }
   ],
   "source": [
    "sim = cosine_similarity(question_embedding, document_embedding)\n",
    "print(f\"Cosine Similarity between questiona dn document: {sim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cda394d-9fd1-4297-ada2-92f0b5a8c04e",
   "metadata": {},
   "source": [
    "## Get token count (as per BPE implemented in tiktoken library by OpenAI). Does not make sense for SentenceBert embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4fc4c9f-f9c9-4919-a6c2-811121866bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_token_number(string: str, encoding_name: str) -> int:\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4892ea6-db9a-4919-81b5-3d6a5db34b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## cl100k_base is GPT-4 tokenizer\n",
    "count_token_number(question, \"cl100k_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4359c0-0ee1-4267-b080-1bba0fe600c7",
   "metadata": {},
   "source": [
    "## Visualize tokenization done by cl100k_base (GPT-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "528ab1e3-7171-4560-b166-5d52ac1a77e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[48;5;167mW\u001b[48;5;179mh\u001b[48;5;185ma\u001b[48;5;77mt\u001b[0m\n",
      "\u001b[48;5;167mW\u001b[48;5;179mh\u001b[48;5;185mat\u001b[0m\n",
      "\u001b[48;5;167mWh\u001b[48;5;185mat\u001b[0m\n",
      "\u001b[48;5;167mWhat\u001b[0m\n",
      "\n",
      "\u001b[48;5;167m \u001b[48;5;179mk\u001b[48;5;185mi\u001b[48;5;77mn\u001b[48;5;80md\u001b[48;5;68ms\u001b[0m\n",
      "\u001b[48;5;167m \u001b[48;5;179mk\u001b[48;5;185min\u001b[48;5;80md\u001b[48;5;68ms\u001b[0m\n",
      "\u001b[48;5;167m \u001b[48;5;179mk\u001b[48;5;185mind\u001b[48;5;68ms\u001b[0m\n",
      "\u001b[48;5;167m k\u001b[48;5;185mind\u001b[48;5;68ms\u001b[0m\n",
      "\u001b[48;5;167m kind\u001b[48;5;68ms\u001b[0m\n",
      "\u001b[48;5;167m kinds\u001b[0m\n",
      "\n",
      "\u001b[48;5;167m \u001b[48;5;179mo\u001b[48;5;185mf\u001b[0m\n",
      "\u001b[48;5;167m o\u001b[48;5;185mf\u001b[0m\n",
      "\u001b[48;5;167m of\u001b[0m\n",
      "\n",
      "\u001b[48;5;167m \u001b[48;5;179mp\u001b[48;5;185me\u001b[48;5;77mt\u001b[48;5;80ms\u001b[0m\n",
      "\u001b[48;5;167m p\u001b[48;5;185me\u001b[48;5;77mt\u001b[48;5;80ms\u001b[0m\n",
      "\u001b[48;5;167m p\u001b[48;5;185met\u001b[48;5;80ms\u001b[0m\n",
      "\u001b[48;5;167m p\u001b[48;5;185mets\u001b[0m\n",
      "\u001b[48;5;167m pets\u001b[0m\n",
      "\n",
      "\u001b[48;5;167m \u001b[48;5;179md\u001b[48;5;185mo\u001b[0m\n",
      "\u001b[48;5;167m d\u001b[48;5;185mo\u001b[0m\n",
      "\u001b[48;5;167m do\u001b[0m\n",
      "\n",
      "\u001b[48;5;167m \u001b[48;5;179mI\u001b[0m\n",
      "\u001b[48;5;167m I\u001b[0m\n",
      "\n",
      "\u001b[48;5;167m \u001b[48;5;179ml\u001b[48;5;185mi\u001b[48;5;77mk\u001b[48;5;80me\u001b[0m\n",
      "\u001b[48;5;167m l\u001b[48;5;185mi\u001b[48;5;77mk\u001b[48;5;80me\u001b[0m\n",
      "\u001b[48;5;167m l\u001b[48;5;185mi\u001b[48;5;77mke\u001b[0m\n",
      "\u001b[48;5;167m li\u001b[48;5;77mke\u001b[0m\n",
      "\u001b[48;5;167m like\u001b[0m\n",
      "\n",
      "\u001b[48;5;167m?\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3923, 13124, 315, 26159, 656, 358, 1093, 30]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = SimpleBytePairEncoding.from_tiktoken(\"cl100k_base\")\n",
    "enc.encode(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc58711-0b63-464a-b89d-38a19c058b92",
   "metadata": {},
   "source": [
    "## INDEXING (load, split and embed documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2033c3-1e5d-4787-a8c9-98e1b87f0cc6",
   "metadata": {},
   "source": [
    "## 1. Load data from web page and use Beautifuloup to parse it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41d1538c-ae52-4f20-aa07-f6c1b3fd34c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "blog_docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d375bb-a261-4853-9465-2e240bfba581",
   "metadata": {},
   "source": [
    "## 2. Split data using chunking strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7489cc8-e988-4001-acc2-9fc952972122",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=300, chunk_overlap=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7d9c81a-5228-419d-a7c5-ec09395d994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = splitter.split_documents(blog_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88531a30-af2b-45db-ab72-751fcc9eb104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of splits from blog_docs: 52 \n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of splits from blog_docs: {len(splits)} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a8402a-9c7c-4454-8328-f6e5fdb5bfc2",
   "metadata": {},
   "source": [
    "## SPlits doc into splits. Each split has 300 tokens with overlap of 50 tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b93f404-d33e-4c9a-b0bf-52621a8a592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_length_list = [len(sp.page_content) for sp in splits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "218df6fc-c099-4004-a883-f956a2460612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=content_length_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3e2c2e4-a045-40c9-8559-ab976f0c2092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Metadata is the extra information around the doc that is split using recursive splitter\n",
    "splits[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8077ab90-2fa2-4c13-acbb-992ecc0fd082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hardiksahi/Personal/rag/notebooks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7818cbfd-e0c7-493c-9a69-8c57d0e502e9",
   "metadata": {},
   "source": [
    "## 3. Store embeddings to chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5e5f2dce-4cbf-46fb-aeb1-764a686255cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize chroma db client\n",
    "vectorstore = Chroma.from_documents(collection_name=\"rag_store_nomic\", persist_directory=\"notebooks/chroma\", documents=splits, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ddfdfa5-dab1-4bc7-983a-a754ccb04d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [],\n",
       " 'documents': [],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.get('043be940-5eb3-4ca9-ae66-6d07e094b493')#.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2c6fe4c8-bf01-4fda-90bf-adc271dbe554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorstore.delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "100d6741-f214-48fc-a75d-390d2d0e4410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retreiver = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs = {\"k\":4})\n",
    "\n",
    "## This will prevent from getting unsure documents\n",
    "retreiver = vectorstore.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={'score_threshold': 0.35}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eacaf02a-38e0-4b83-97f2-b66ae49da5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_docs = await retreiver.ainvoke(\"What is task decoposition?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def08824-6e96-4b72-8377-ffe5665fac57",
   "metadata": {},
   "source": [
    "## These retreived splits are embedded into the context of LLM(GPT or LLama) as prompt to answer the query. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87318109-6029-4dc4-942d-a1dc0a6c34b0",
   "metadata": {},
   "source": [
    "## 4. Create prompt (https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html#langchain_core.prompts.chat.ChatPromptTemplate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "473b9da8-54c8-49fb-b40c-afa74d1e4405",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4dd0cb68-e585-437c-8fc5-1b3db88fd311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template='Answer the question based only on the following context:\\n{context}\\n\\nQuestion: {question}\\n'))]\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "de89d940-4e79-433d-9b48-60de87a47960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.chat.ChatPromptTemplate'>\n"
     ]
    }
   ],
   "source": [
    "print(type(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "68a52780-38ba-4c44-9450-549fd9b53260",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm = ChatOllama(model=\"llama2:latest\") ## num_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c432561c-3881-4c59-8046-ae990707c8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = {\"context\":retreiver, \"question\": RunnablePassthrough()} | prompt | local_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f3dabf5e-3586-4648-807b-6cdfdc41dc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain = prompt | local_llm\n",
    "\n",
    "# chain.invoke({\"context\":relevant_docs,\"question\":\"What is Task Decomposition?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2d8bd67c-b7af-4df8-bf7b-da90a867663f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition is a process of breaking down a complex task into smaller and more manageable subtasks or steps. This is typically done to help an agent or model understand the task better, plan ahead, and perform the task more effectively. In the context of the passage, task decomposition is mentioned as a technique used by LLM-powered autonomous agent systems to improve their performance on complex tasks.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"What is task decomposition?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "def80f95-8fe7-469c-9e83-1d249accdff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Algorithm Distillation (AD) is a method to transfer knowledge from a set of source policies to a neural network, allowing the learned policy to be task-agnostic. The process involves behavioral cloning over actions, where the history data is generated by the source policies and used for training the neural network. The key insight is that any algorithm that generates a set of learning histories can be distilled into a neural network. AD demonstrates in-context RL with performance close to an upper bound (RL^2) despite only using offline RL, and learns much faster than other baselines when conditioned on partial training history of the source policy.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"Summarize algorithm distillation for me\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3d1b6cf9-79b9-482d-b222-1ea370fa6999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, there are two main types of agent memory:\\n\\n1. Short-term Memory (STM): Also known as working memory, STM is responsible for storing information that the agent is currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. STM typically lasts for up to 30 seconds.\\n2. Long-term Memory (LTM): LTM can store information for an extended period, ranging from days to decades, with an essentially unlimited storage capacity. LTM includes two subtypes: explicit/declarative memory and implicit/procedural memory. Explicit memory refers to the ability to consciously recall facts and events, while implicit memory involves skills and routines that are performed automatically.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"What are the different types of agent memory?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06029860-aeb8-426e-9a96-cdefb4090cd5",
   "metadata": {},
   "source": [
    "## Updated prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "54008cc1-894b-4d39-80ca-b721db577ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_hub_rag = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "79f7b927-8d8f-4cdc-a1dd-88b9ad66b119",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_rag_chain = {\"context\":retreiver, \"question\": RunnablePassthrough()} | prompt_hub_rag | local_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "746d3e92-28bd-4160-96cd-a62750148da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Training large language models (LLMs) has gained significant attention in recent years due to their potential to revolutionize various fields such as natural language processing, problem-solving, and decision-making. Here are some key aspects of training LLMs:\\n\\n1. Large scale: LLMs are trained on vast amounts of data, often exceeding tens of gigabytes in size. This requires powerful hardware and sophisticated distributed training frameworks to manage the computational resources and data parallelism.\\n2. Transfer learning: LLMs are typically trained on a combination of pre-training tasks such as language modeling, text classification, and question answering. This allows them to leverage the knowledge gained from these tasks to improve their performance on other NLP tasks.\\n3. Fine-tuning: After pre-training, LLMs are fine-tuned on specific tasks or domains to adapt to new contexts and improve their performance. This involves adjusting the model's weights and biases to fit the new task or domain.\\n4. Prompt engineering: The quality of the training data and the prompts used to elicit reasoning in LLMs are crucial factors that determine their performance. Well-crafted prompts can help LLMs generate more informative and accurate responses.\\n5. Adversarial training: To improve the robustness of LLMs, adversarial training techniques are employed to expose them to various types of attacks or distorted inputs. This helps the models learn to generalize better and be more resilient to malicious inputs.\\n6. Multi-modal input: LLMs can process and generate responses to multiple forms of input, such as text, images, audio, and video. This enables them to interact with users in a more natural and intuitive way.\\n7. Continual learning: LLMs are designed to learn continuously, adapting to new data and tasks over time. This allows them to improve their performance on existing tasks while also acquiring new capabilities.\\n8. Explainability and interpretability: As LLMs become more ubiquitous, there is a growing need to understand how they make decisions and generate responses. Researchers are developing techniques to explain and interpret the behavior of LLMs, which can help build trust in these models.\\n9. Ethical considerations: With the increasing use of LLMs in various applications, ethical concerns arise regarding their potential impact on society. Researchers must address these issues by developing frameworks for responsible AI development and deployment.\\n10. Future directions: The field of LLM training is rapidly evolving, with new techniques and architectures being proposed regularly. Some promising future directions include exploring hybrid models that combine LLMs with other AI components, such as symbolic reasoning or computer vision, and developing more efficient and scalable training methods.\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This is from the pretrained knowledge of Llama2. It is not in the context\n",
    "updated_rag_chain.invoke(\"What can you say about training of large language models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "021b8fdb-7da2-4ad4-adce-cf7d5983eecd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_hub_rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e1ec8318-68f0-4441-b504-a16a654004a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hardiksahi/miniconda3/envs/rag_env/lib/python3.11/site-packages/langchain_core/vectorstores.py:389: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.35\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "relevant_docs1 = await retreiver.ainvoke(\"What can you say about Narendra Modi?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0e55a101-2114-4d9d-b9c4-370f124d2079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_docs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9fb2c01d-0134-4509-8dfb-a254ab30178e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hardiksahi/miniconda3/envs/rag_env/lib/python3.11/site-packages/langchain_core/vectorstores.py:342: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.35\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Narendra Modi is the current Prime Minister of India, serving since 2014. He is known for his leadership style and vision for India's growth and development. He has implemented several policies and initiatives aimed at promoting economic development, improving infrastructure, and enhancing social welfare in the country.\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_rag_chain.invoke(\"What can you say about Narendra Modi?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ca2228-7457-4940-8765-44013942914a",
   "metadata": {},
   "source": [
    "# Part2: https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_5_to_9.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae81b1b-15a5-4493-ad59-a789bb1b3c73",
   "metadata": {},
   "source": [
    "## QUERY TRANSLATION: Rewriting the query input by the user in a way that makes retreival easier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630e0a6a-a110-4fb3-ac99-6bf2c9469c0c",
   "metadata": {},
   "source": [
    "### Way1: MultiQuery:\n",
    "1. Break input query into multiple queries from different perspectives (Ask the LLm to do so)\n",
    "2. Retreive documents for each of the above queries parallely\n",
    "3. Union of documents returned above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7dd158ce-4c07-4f00-ae21-dc286d5f3199",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiquery_template = \"\"\"You are an AI language model assistant. Your task is to generate five \n",
    "different versions of the given user question to retrieve relevant documents from a vector \n",
    "database. By generating multiple perspectives on the user question, your goal is to help\n",
    "the user overcome some of the limitations of the distance-based similarity search. \n",
    "Provide these alternative questions separated by newlines. Original question: {question}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b191dc98-8c1b-43e1-afa1-3659b2037b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_perspectives = ChatPromptTemplate.from_template(multiquery_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2b24f615-42a6-4ab0-b978-ceb7c12670e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='You are an AI language model assistant. Your task is to generate five \\ndifferent versions of the given user question to retrieve relevant documents from a vector \\ndatabase. By generating multiple perspectives on the user question, your goal is to help\\nthe user overcome some of the limitations of the distance-based similarity search. \\nProvide these alternative questions separated by newlines. Original question: {question}'))])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_perspectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4cf7039c-b47a-42bb-a05d-f3f1dc5b1e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_related_queries_chain = prompt_perspectives | local_llm  | StrOutputParser() | (lambda x: x.split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ae4c4f1e-2985-4021-959b-3095b5fe1251",
   "metadata": {},
   "outputs": [],
   "source": [
    "perspective_questions = await generate_related_queries_chain.ainvoke({\"question\": \"What is task decomposition for LLM agents?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ea00d5f7-4fd6-4321-8b74-333466cc5d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'Certainly! Here are five alternative versions of the user question to retrieve relevant documents from a vector database:',\n",
       " '',\n",
       " '1. How can LLM agents decompose tasks into smaller, manageable parts to improve their overall performance?',\n",
       " '2. What are some strategies that LLM agents can use to break down complex tasks into simpler ones, and how can they leverage task decomposition to enhance their capabilities?',\n",
       " '3. How does task decomposition impact the performance of LLM agents in various applications, such as natural language processing, computer vision, or robotics?',\n",
       " '4. Can you provide examples of real-world scenarios where task decomposition has been particularly useful for LLM agents, and how did they handle these situations?',\n",
       " '5. In what ways can LLM agents use task decomposition to adapt to new tasks or environments, and how can they leverage this capability to improve their overall performance in dynamic settings?']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perspective_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1474af3c-acad-41b2-bb4d-0d71081b39b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_union(documents: list[int]):\n",
    "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "    unique_docs = list(set(flattened_docs))\n",
    "    return [loads(doc) for doc in unique_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4a5327b2-1d7d-44ae-b85e-88fc937dd84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiquery_retreival_chain = generate_related_queries_chain | retreiver.map() | get_unique_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c43cc2f6-381c-475f-b3d1-e2e0d603a203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hardiksahi/miniconda3/envs/rag_env/lib/python3.11/site-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    }
   ],
   "source": [
    "multiquery_question = \"What is task decomposition for LLM agents?\"\n",
    "multiquery_docs = multiquery_retreival_chain.invoke({\"question\":multiquery_question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "feb385a1-0ec4-4e04-a8fc-3d23f3f6a6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(multiquery_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9fde8347-b8c7-409b-a316-d02cd6be51b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiquery_rag_chain = {\"context\":multiquery_retreival_chain, \"question\": RunnablePassthrough()} | prompt_hub_rag | local_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0bb8a1d0-930b-476e-aaaa-aad85edb61dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe document provides an overview of LLM-powered autonomous agents, including their architecture, capabilities, and limitations. The author discusses the potential of LLMs to act as a powerful general problem solver, and highlights several challenges and risks associated with their use, such as limited context windows, difficulties in long-term planning and task decomposition, and reliance on natural language interfaces.\\n\\nThe document also mentions several other documents and projects related to LLM-powered agents, including:\\n\\n* \"ChemCrow: Augmenting large-language models with chemistry tools\" by Bran et al. (2023)\\n* \"Emergent autonomous scientific research capabilities of large language models\" by Boiko et al. (2023)\\n* \"Generative Agents: Interactive Simulacra of Human Behavior\" by Joon Sung Park, et al. (2023)\\n* AutoGPT and GPT-Engineer, which are tools for generating code and text respectively.\\n\\nThe document concludes by highlighting the potential of generative agents to create believable simulacra of human behavior, and discusses the design of these agents, which combine LLMs with memory, planning, and reflection mechanisms.'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiquery_rag_chain.invoke(multiquery_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a103d17-b548-43e4-89bb-8589ee1daeb0",
   "metadata": {},
   "source": [
    "## My understanding is mutliquery query translation makes sense when the question is very broad since it breaks initial question into queries from different perspectives. This might be problematic when initial questions are very pointed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e44ae9-53b5-4027-ab31-14efb19c993a",
   "metadata": {},
   "source": [
    "### Way2: RAG-Fusion\n",
    "1. Break query into different queries from varying perspectives\n",
    "2. Ask LLM to answer these queries parallely\n",
    "3. Combine the answers using a special technique called reciprocal rank fusion (RRF) \n",
    "4. Return the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dcb5716e-f753-404d-b48f-50bcc933c7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    fused_scores = {}\n",
    "    ## results is a list of lists of size 4 (# subqueries). Each element is a list of retreived documents\n",
    "    for docs in results:\n",
    "        for rank, doc in enumerate(docs):\n",
    "            doc_str = dumps(docs) ## Convert doc to string\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            #previous_score = fused_scores[doc_str]\n",
    "            fused_scores[doc_str]+=1/(rank+k)\n",
    "\n",
    "    reranked_results = [(loads(doc), rrf_score) for doc, rrf_score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)]\n",
    "    return reranked_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8eb1cc95-a88a-499c-8738-eb6ee39f4f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_for_splitting_single_query = \"\"\"You are a helpful assistant that generates multiple search queries based on single input query.\n",
    "Generate multiple search queries related to : {question}\n",
    "Output 4 queries:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6b73e77f-3e4a-4a93-b4f0-09d0ac3d3996",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_splitting_single_query = ChatPromptTemplate.from_template(template_for_splitting_single_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "33a3e1d7-17d1-418b-adfc-d87886ff4faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cc = {\"question\": RunnablePassthrough()} | prompt_splitting_single_query\n",
    "#cc.invoke(\"how to train LLM?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7d6444e6-d101-433d-b698-05bee721176c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_queries_chain = prompt_splitting_single_query | local_llm | StrOutputParser() | (lambda x: x.split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "00adfb10-e63c-4f69-8f9d-f3615f858d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generates 4 related queries\n",
    "#generate_queries_chain.invoke({\"question\": \"how to train LLM?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c9fd3327-df81-4c3d-86fc-028a922fe71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_fusion_retreival_chain = generate_queries_chain | retreiver.map() | reciprocal_rank_fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ff1fdf80-9e97-4b91-84ef-cf3355d1287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.debug=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "da2844c8-f0ef-48e8-babd-1355aa9aff86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"what can you tell me about chain of thought?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"what can you tell me about chain of thought?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a helpful assistant that generates multiple search queries based on single input query.\\nGenerate multiple search queries related to : what can you tell me about chain of thought?\\nOutput 4 queries:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [4.69s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\\nGreat, I'd be happy to help! Here are four search queries related to \\\"chain of thought\\\":\\n\\n1. What is the psychology behind chain of thought, and how does it impact decision-making? - (Source: Psychology Today)\\n2. How does chain of thought affect creativity and problem-solving? - (Source: Harvard Business Review)\\n3. Can chain of thought be influenced or manipulated through various techniques, such as mindfulness or deliberate practice? - (Source: Scientific American)\\n4. What are some strategies for improving chain of thought in everyday life, such as enhancing critical thinking skills or reducing mental clutter? - (Source: TEDx Talks)\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama2:latest\",\n",
      "          \"created_at\": \"2024-06-18T20:18:07.456435Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 4685964292,\n",
      "          \"load_duration\": 1007708,\n",
      "          \"prompt_eval_count\": 57,\n",
      "          \"prompt_eval_duration\": 262504000,\n",
      "          \"eval_count\": 158,\n",
      "          \"eval_duration\": 4420311000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\\nGreat, I'd be happy to help! Here are four search queries related to \\\"chain of thought\\\":\\n\\n1. What is the psychology behind chain of thought, and how does it impact decision-making? - (Source: Psychology Today)\\n2. How does chain of thought affect creativity and problem-solving? - (Source: Harvard Business Review)\\n3. Can chain of thought be influenced or manipulated through various techniques, such as mindfulness or deliberate practice? - (Source: Scientific American)\\n4. What are some strategies for improving chain of thought in everyday life, such as enhancing critical thinking skills or reducing mental clutter? - (Source: TEDx Talks)\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama2:latest\",\n",
      "              \"created_at\": \"2024-06-18T20:18:07.456435Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 4685964292,\n",
      "              \"load_duration\": 1007708,\n",
      "              \"prompt_eval_count\": 57,\n",
      "              \"prompt_eval_duration\": 262504000,\n",
      "              \"eval_count\": 158,\n",
      "              \"eval_duration\": 4420311000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-8be3a03c-18aa-4513-a265-c4698baa65c0-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [2ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"\\nGreat, I'd be happy to help! Here are four search queries related to \\\"chain of thought\\\":\\n\\n1. What is the psychology behind chain of thought, and how does it impact decision-making? - (Source: Psychology Today)\\n2. How does chain of thought affect creativity and problem-solving? - (Source: Harvard Business Review)\\n3. Can chain of thought be influenced or manipulated through various techniques, such as mindfulness or deliberate practice? - (Source: Scientific American)\\n4. What are some strategies for improving chain of thought in everyday life, such as enhancing critical thinking skills or reducing mental clutter? - (Source: TEDx Talks)\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"\\nGreat, I'd be happy to help! Here are four search queries related to \\\"chain of thought\\\":\\n\\n1. What is the psychology behind chain of thought, and how does it impact decision-making? - (Source: Psychology Today)\\n2. How does chain of thought affect creativity and problem-solving? - (Source: Harvard Business Review)\\n3. Can chain of thought be influenced or manipulated through various techniques, such as mindfulness or deliberate practice? - (Source: Scientific American)\\n4. What are some strategies for improving chain of thought in everyday life, such as enhancing critical thinking skills or reducing mental clutter? - (Source: TEDx Talks)\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": [\n",
      "    \"\",\n",
      "    \"Great, I'd be happy to help! Here are four search queries related to \\\"chain of thought\\\":\",\n",
      "    \"\",\n",
      "    \"1. What is the psychology behind chain of thought, and how does it impact decision-making? - (Source: Psychology Today)\",\n",
      "    \"2. How does chain of thought affect creativity and problem-solving? - (Source: Harvard Business Review)\",\n",
      "    \"3. Can chain of thought be influenced or manipulated through various techniques, such as mindfulness or deliberate practice? - (Source: Scientific American)\",\n",
      "    \"4. What are some strategies for improving chain of thought in everyday life, such as enhancing critical thinking skills or reducing mental clutter? - (Source: TEDx Talks)\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableEach<VectorStoreRetriever>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": [\n",
      "    \"\",\n",
      "    \"Great, I'd be happy to help! Here are four search queries related to \\\"chain of thought\\\":\",\n",
      "    \"\",\n",
      "    \"1. What is the psychology behind chain of thought, and how does it impact decision-making? - (Source: Psychology Today)\",\n",
      "    \"2. How does chain of thought affect creativity and problem-solving? - (Source: Harvard Business Review)\",\n",
      "    \"3. Can chain of thought be influenced or manipulated through various techniques, such as mindfulness or deliberate practice? - (Source: Scientific American)\",\n",
      "    \"4. What are some strategies for improving chain of thought in everyday life, such as enhancing critical thinking skills or reducing mental clutter? - (Source: TEDx Talks)\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableEach<VectorStoreRetriever>] [256ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:reciprocal_rank_fusion] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:reciprocal_rank_fusion] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [4.96s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n"
     ]
    }
   ],
   "source": [
    "returned_docs_as_per_rrf = await rag_fusion_retreival_chain.ainvoke({\"question\": \"what can you tell me about chain of thought?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "657fc744-8496-452d-be15-a99fc4c07fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_for_generation = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b8aa4746-3b96-4363-9d69-c00c155d1136",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_for_generation = ChatPromptTemplate.from_template(template_for_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c87fff73-0475-4b4c-9a0a-2f4a5a936040",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rag_fusion_generation_chain = {\"context\":rag_fusion_retreival_chain, \"question\": itemgetter(\"question\")} | prompt_for_generation | local_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f014767a-e250-4b7b-b9cf-005ac4053eb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a helpful assistant that generates multiple search queries based on single input query.\\nGenerate multiple search queries related to : What is task decomposition for LLM agents?\\nOutput 4 queries:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > llm:ChatOllama] [9.15s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\\nCertainly! Here are four search queries related to \\\"What is task decomposition for LLM agents?\\\"\\n\\n1. \\\"Task Decomposition for LLM Agents: A Survey of Recent Approaches and Challenges\\\" - This query could lead to a comprehensive survey of recent approaches to task decomposition for large language models (LLMs), including the different techniques and algorithms used, as well as the challenges and limitations of these approaches.\\n2. \\\"Decomposing Tasks for LLM Agents: A Focus on Natural Language Processing Applications\\\" - This query could lead to a search for research papers and articles focused specifically on task decomposition for NLP applications using LLM agents, including the use of LLMs in natural language processing tasks such as text classification, sentiment analysis, and machine translation.\\n3. \\\"Task Decomposition Strategies for Efficient LLM Execution\\\" - This query could lead to a search for research on strategies for decomposing tasks into smaller sub-tasks or sub-processes that can be executed more efficiently by LLM agents, including the use of parallel processing, distributed computing, and other optimization techniques.\\n4. \\\"Task Decomposition in Multi-Agent Systems with LLMs\\\" - This query could lead to a search for research on task decomposition in multi-agent systems that incorporate LLM agents, including the use of LLMs to coordinate and manage tasks between multiple agents, and the challenges and opportunities of task decomposition in these systems.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama2:latest\",\n",
      "          \"created_at\": \"2024-06-18T20:18:16.904886Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 9148528334,\n",
      "          \"load_duration\": 1355625,\n",
      "          \"prompt_eval_count\": 20,\n",
      "          \"prompt_eval_duration\": 158740000,\n",
      "          \"eval_count\": 318,\n",
      "          \"eval_duration\": 8985364000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\\nCertainly! Here are four search queries related to \\\"What is task decomposition for LLM agents?\\\"\\n\\n1. \\\"Task Decomposition for LLM Agents: A Survey of Recent Approaches and Challenges\\\" - This query could lead to a comprehensive survey of recent approaches to task decomposition for large language models (LLMs), including the different techniques and algorithms used, as well as the challenges and limitations of these approaches.\\n2. \\\"Decomposing Tasks for LLM Agents: A Focus on Natural Language Processing Applications\\\" - This query could lead to a search for research papers and articles focused specifically on task decomposition for NLP applications using LLM agents, including the use of LLMs in natural language processing tasks such as text classification, sentiment analysis, and machine translation.\\n3. \\\"Task Decomposition Strategies for Efficient LLM Execution\\\" - This query could lead to a search for research on strategies for decomposing tasks into smaller sub-tasks or sub-processes that can be executed more efficiently by LLM agents, including the use of parallel processing, distributed computing, and other optimization techniques.\\n4. \\\"Task Decomposition in Multi-Agent Systems with LLMs\\\" - This query could lead to a search for research on task decomposition in multi-agent systems that incorporate LLM agents, including the use of LLMs to coordinate and manage tasks between multiple agents, and the challenges and opportunities of task decomposition in these systems.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama2:latest\",\n",
      "              \"created_at\": \"2024-06-18T20:18:16.904886Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 9148528334,\n",
      "              \"load_duration\": 1355625,\n",
      "              \"prompt_eval_count\": 20,\n",
      "              \"prompt_eval_duration\": 158740000,\n",
      "              \"eval_count\": 318,\n",
      "              \"eval_duration\": 8985364000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-7b3c89ac-fcd8-431e-8c1a-6870ca780069-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > parser:StrOutputParser] [2ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"\\nCertainly! Here are four search queries related to \\\"What is task decomposition for LLM agents?\\\"\\n\\n1. \\\"Task Decomposition for LLM Agents: A Survey of Recent Approaches and Challenges\\\" - This query could lead to a comprehensive survey of recent approaches to task decomposition for large language models (LLMs), including the different techniques and algorithms used, as well as the challenges and limitations of these approaches.\\n2. \\\"Decomposing Tasks for LLM Agents: A Focus on Natural Language Processing Applications\\\" - This query could lead to a search for research papers and articles focused specifically on task decomposition for NLP applications using LLM agents, including the use of LLMs in natural language processing tasks such as text classification, sentiment analysis, and machine translation.\\n3. \\\"Task Decomposition Strategies for Efficient LLM Execution\\\" - This query could lead to a search for research on strategies for decomposing tasks into smaller sub-tasks or sub-processes that can be executed more efficiently by LLM agents, including the use of parallel processing, distributed computing, and other optimization techniques.\\n4. \\\"Task Decomposition in Multi-Agent Systems with LLMs\\\" - This query could lead to a search for research on task decomposition in multi-agent systems that incorporate LLM agents, including the use of LLMs to coordinate and manage tasks between multiple agents, and the challenges and opportunities of task decomposition in these systems.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"\\nCertainly! Here are four search queries related to \\\"What is task decomposition for LLM agents?\\\"\\n\\n1. \\\"Task Decomposition for LLM Agents: A Survey of Recent Approaches and Challenges\\\" - This query could lead to a comprehensive survey of recent approaches to task decomposition for large language models (LLMs), including the different techniques and algorithms used, as well as the challenges and limitations of these approaches.\\n2. \\\"Decomposing Tasks for LLM Agents: A Focus on Natural Language Processing Applications\\\" - This query could lead to a search for research papers and articles focused specifically on task decomposition for NLP applications using LLM agents, including the use of LLMs in natural language processing tasks such as text classification, sentiment analysis, and machine translation.\\n3. \\\"Task Decomposition Strategies for Efficient LLM Execution\\\" - This query could lead to a search for research on strategies for decomposing tasks into smaller sub-tasks or sub-processes that can be executed more efficiently by LLM agents, including the use of parallel processing, distributed computing, and other optimization techniques.\\n4. \\\"Task Decomposition in Multi-Agent Systems with LLMs\\\" - This query could lead to a search for research on task decomposition in multi-agent systems that incorporate LLM agents, including the use of LLMs to coordinate and manage tasks between multiple agents, and the challenges and opportunities of task decomposition in these systems.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > chain:RunnableLambda] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": [\n",
      "    \"\",\n",
      "    \"Certainly! Here are four search queries related to \\\"What is task decomposition for LLM agents?\\\"\",\n",
      "    \"\",\n",
      "    \"1. \\\"Task Decomposition for LLM Agents: A Survey of Recent Approaches and Challenges\\\" - This query could lead to a comprehensive survey of recent approaches to task decomposition for large language models (LLMs), including the different techniques and algorithms used, as well as the challenges and limitations of these approaches.\",\n",
      "    \"2. \\\"Decomposing Tasks for LLM Agents: A Focus on Natural Language Processing Applications\\\" - This query could lead to a search for research papers and articles focused specifically on task decomposition for NLP applications using LLM agents, including the use of LLMs in natural language processing tasks such as text classification, sentiment analysis, and machine translation.\",\n",
      "    \"3. \\\"Task Decomposition Strategies for Efficient LLM Execution\\\" - This query could lead to a search for research on strategies for decomposing tasks into smaller sub-tasks or sub-processes that can be executed more efficiently by LLM agents, including the use of parallel processing, distributed computing, and other optimization techniques.\",\n",
      "    \"4. \\\"Task Decomposition in Multi-Agent Systems with LLMs\\\" - This query could lead to a search for research on task decomposition in multi-agent systems that incorporate LLM agents, including the use of LLMs to coordinate and manage tasks between multiple agents, and the challenges and opportunities of task decomposition in these systems.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > chain:RunnableEach<VectorStoreRetriever>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": [\n",
      "    \"\",\n",
      "    \"Certainly! Here are four search queries related to \\\"What is task decomposition for LLM agents?\\\"\",\n",
      "    \"\",\n",
      "    \"1. \\\"Task Decomposition for LLM Agents: A Survey of Recent Approaches and Challenges\\\" - This query could lead to a comprehensive survey of recent approaches to task decomposition for large language models (LLMs), including the different techniques and algorithms used, as well as the challenges and limitations of these approaches.\",\n",
      "    \"2. \\\"Decomposing Tasks for LLM Agents: A Focus on Natural Language Processing Applications\\\" - This query could lead to a search for research papers and articles focused specifically on task decomposition for NLP applications using LLM agents, including the use of LLMs in natural language processing tasks such as text classification, sentiment analysis, and machine translation.\",\n",
      "    \"3. \\\"Task Decomposition Strategies for Efficient LLM Execution\\\" - This query could lead to a search for research on strategies for decomposing tasks into smaller sub-tasks or sub-processes that can be executed more efficiently by LLM agents, including the use of parallel processing, distributed computing, and other optimization techniques.\",\n",
      "    \"4. \\\"Task Decomposition in Multi-Agent Systems with LLMs\\\" - This query could lead to a search for research on task decomposition in multi-agent systems that incorporate LLM agents, including the use of LLMs to coordinate and manage tasks between multiple agents, and the challenges and opportunities of task decomposition in these systems.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > chain:RunnableEach<VectorStoreRetriever>] [447ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > chain:reciprocal_rank_fusion] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > chain:reciprocal_rank_fusion] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence] [9.61s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question>] [9.62s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Answer the following question based on this context:\\n\\n[([Document(page_content='inquired about current trends in anticancer drug discovery;\\\\nselected a target;\\\\nrequested a scaffold targeting these compounds;\\\\nOnce the compound was identified, the model attempted its synthesis.\\\\n\\\\nThey also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\\\nGenerative Agents Simulation#\\\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\\\n\\\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents experience in natural language.\\\\n\\\\nEach element is an observation, an event directly provided by the agent.\\\\n- Inter-agent communication can trigger new natural language statements.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}), Document(page_content='[17] Bran et al. ChemCrow: Augmenting large-language models with chemistry tools. arXiv preprint arXiv:2304.05376 (2023).\\\\n[18] Boiko et al. Emergent autonomous scientific research capabilities of large language models. arXiv preprint arXiv:2304.05332 (2023).\\\\n[19] Joon Sung Park, et al. Generative Agents: Interactive Simulacra of Human Behavior. arXiv preprint arXiv:2304.03442 (2023).\\\\n[20] AutoGPT. https://github.com/Significant-Gravitas/Auto-GPT\\\\n[21] GPT-Engineer. https://github.com/AntonOsika/gpt-engineer', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}), Document(page_content='Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into Problem PDDL, then (2) requests a classical planner to generate a PDDL plan based on an existing Domain PDDL, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\\\nSelf-Reflection#\\\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}), Document(page_content='Or\\\\n@article{weng2023agent,\\\\n  title   = \\\"LLM-powered Autonomous Agents\\\",\\\\n  author  = \\\"Weng, Lilian\\\",\\\\n  journal = \\\"lilianweng.github.io\\\",\\\\n  year    = \\\"2023\\\",\\\\n  month   = \\\"Jun\\\",\\\\n  url     = \\\"https://lilianweng.github.io/posts/2023-06-23-agent/\\\"\\\\n}\\\\nReferences#\\\\n[1] Wei et al. Chain of thought prompting elicits reasoning in large language models. NeurIPS 2022\\\\n[2] Yao et al. Tree of Thoughts: Dliberate Problem Solving with Large Language Models. arXiv preprint arXiv:2305.10601 (2023).\\\\n[3] Liu et al. Chain of Hindsight Aligns Language Models with Feedback\\\\n arXiv preprint arXiv:2302.02676 (2023).\\\\n[4] Liu et al. LLM+P: Empowering Large Language Models with Optimal Planning Proficiency arXiv preprint arXiv:2304.11477 (2023).', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'})], 0.13012431484139575), ([Document(page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\\\nComponent One: Planning#\\\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\\\nTask Decomposition#\\\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to think step by step to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the models thinking process.\\\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\\\nTask decomposition can be done (1) by LLM with simple prompting like \\\"Steps for XYZ.\\\\\\\\n1.\\\", \\\"What are the subgoals for achieving XYZ?\\\", (2) by using task-specific instructions; e.g. \\\"Write a story outline.\\\" for writing a novel, or (3) with human inputs.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}), Document(page_content='LLM Powered Autonomous Agents\\\\n    \\\\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\\\n\\\\n\\\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview#\\\\nIn a LLM-powered autonomous agent system, LLM functions as the agents brain, complemented by several key components:\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}), Document(page_content='One interesting observation is that while the LLM-based evaluation concluded that GPT-4 and ChemCrow perform nearly equivalently, human evaluations with experts oriented towards the completion and chemical correctness of the solutions showed that ChemCrow outperforms GPT-4 by a large margin. This indicates a potential problem with using LLM to evaluate its own performance on domains that requires deep expertise. The lack of expertise may cause LLMs not knowing its flaws and thus cannot well judge the correctness of task results.\\\\nBoiko et al. (2023) also looked into LLM-empowered agents for scientific discovery, to handle autonomous design, planning, and performance of complex scientific experiments. This agent can use tools to browse the Internet, read documentation, execute code, call robotics experimentation APIs and leverage other LLMs.\\\\nFor example, when requested to \\\"develop a novel anticancer drug\\\", the model came up with the following reasoning steps:\\\\n\\\\ninquired about current trends in anticancer drug discovery;\\\\nselected a target;\\\\nrequested a scaffold targeting these compounds;\\\\nOnce the compound was identified, the model attempted its synthesis.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}), Document(page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\\\n\\\\n\\\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\\\n\\\\n\\\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\\\n\\\\n\\\\nCitation#\\\\nCited as:\\\\n\\\\nWeng, Lilian. (Jun 2023). LLM-powered Autonomous Agents. LilLog. https://lilianweng.github.io/posts/2023-06-23-agent/.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'})], 0.13012431484139575), ([Document(page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\\\nComponent One: Planning#\\\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\\\nTask Decomposition#\\\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to think step by step to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the models thinking process.\\\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\\\nTask decomposition can be done (1) by LLM with simple prompting like \\\"Steps for XYZ.\\\\\\\\n1.\\\", \\\"What are the subgoals for achieving XYZ?\\\", (2) by using task-specific instructions; e.g. \\\"Write a story outline.\\\" for writing a novel, or (3) with human inputs.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}), Document(page_content='LLM Powered Autonomous Agents\\\\n    \\\\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\\\n\\\\n\\\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview#\\\\nIn a LLM-powered autonomous agent system, LLM functions as the agents brain, complemented by several key components:\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}), Document(page_content='Or\\\\n@article{weng2023agent,\\\\n  title   = \\\"LLM-powered Autonomous Agents\\\",\\\\n  author  = \\\"Weng, Lilian\\\",\\\\n  journal = \\\"lilianweng.github.io\\\",\\\\n  year    = \\\"2023\\\",\\\\n  month   = \\\"Jun\\\",\\\\n  url     = \\\"https://lilianweng.github.io/posts/2023-06-23-agent/\\\"\\\\n}\\\\nReferences#\\\\n[1] Wei et al. Chain of thought prompting elicits reasoning in large language models. NeurIPS 2022\\\\n[2] Yao et al. Tree of Thoughts: Dliberate Problem Solving with Large Language Models. arXiv preprint arXiv:2305.10601 (2023).\\\\n[3] Liu et al. Chain of Hindsight Aligns Language Models with Feedback\\\\n arXiv preprint arXiv:2302.02676 (2023).\\\\n[4] Liu et al. LLM+P: Empowering Large Language Models with Optimal Planning Proficiency arXiv preprint arXiv:2304.11477 (2023).', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}), Document(page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\\\n\\\\n\\\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\\\n\\\\n\\\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\\\n\\\\n\\\\nCitation#\\\\nCited as:\\\\n\\\\nWeng, Lilian. (Jun 2023). LLM-powered Autonomous Agents. LilLog. https://lilianweng.github.io/posts/2023-06-23-agent/.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'})], 0.06506215742069787), ([Document(page_content='LLM Powered Autonomous Agents\\\\n    \\\\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\\\n\\\\n\\\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview#\\\\nIn a LLM-powered autonomous agent system, LLM functions as the agents brain, complemented by several key components:\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}), Document(page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\\\nComponent One: Planning#\\\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\\\nTask Decomposition#\\\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to think step by step to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the models thinking process.\\\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\\\nTask decomposition can be done (1) by LLM with simple prompting like \\\"Steps for XYZ.\\\\\\\\n1.\\\", \\\"What are the subgoals for achieving XYZ?\\\", (2) by using task-specific instructions; e.g. \\\"Write a story outline.\\\" for writing a novel, or (3) with human inputs.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}), Document(page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\\\n\\\\n\\\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\\\n\\\\n\\\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\\\n\\\\n\\\\nCitation#\\\\nCited as:\\\\n\\\\nWeng, Lilian. (Jun 2023). LLM-powered Autonomous Agents. LilLog. https://lilianweng.github.io/posts/2023-06-23-agent/.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}), Document(page_content='Or\\\\n@article{weng2023agent,\\\\n  title   = \\\"LLM-powered Autonomous Agents\\\",\\\\n  author  = \\\"Weng, Lilian\\\",\\\\n  journal = \\\"lilianweng.github.io\\\",\\\\n  year    = \\\"2023\\\",\\\\n  month   = \\\"Jun\\\",\\\\n  url     = \\\"https://lilianweng.github.io/posts/2023-06-23-agent/\\\"\\\\n}\\\\nReferences#\\\\n[1] Wei et al. Chain of thought prompting elicits reasoning in large language models. NeurIPS 2022\\\\n[2] Yao et al. Tree of Thoughts: Dliberate Problem Solving with Large Language Models. arXiv preprint arXiv:2305.10601 (2023).\\\\n[3] Liu et al. Chain of Hindsight Aligns Language Models with Feedback\\\\n arXiv preprint arXiv:2302.02676 (2023).\\\\n[4] Liu et al. LLM+P: Empowering Large Language Models with Optimal Planning Proficiency arXiv preprint arXiv:2304.11477 (2023).', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'})], 0.06506215742069787), ([Document(page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\\\nComponent One: Planning#\\\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\\\nTask Decomposition#\\\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to think step by step to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the models thinking process.\\\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\\\nTask decomposition can be done (1) by LLM with simple prompting like \\\"Steps for XYZ.\\\\\\\\n1.\\\", \\\"What are the subgoals for achieving XYZ?\\\", (2) by using task-specific instructions; e.g. \\\"Write a story outline.\\\" for writing a novel, or (3) with human inputs.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}), Document(page_content='LLM Powered Autonomous Agents\\\\n    \\\\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\\\n\\\\n\\\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview#\\\\nIn a LLM-powered autonomous agent system, LLM functions as the agents brain, complemented by several key components:\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}), Document(page_content='One interesting observation is that while the LLM-based evaluation concluded that GPT-4 and ChemCrow perform nearly equivalently, human evaluations with experts oriented towards the completion and chemical correctness of the solutions showed that ChemCrow outperforms GPT-4 by a large margin. This indicates a potential problem with using LLM to evaluate its own performance on domains that requires deep expertise. The lack of expertise may cause LLMs not knowing its flaws and thus cannot well judge the correctness of task results.\\\\nBoiko et al. (2023) also looked into LLM-empowered agents for scientific discovery, to handle autonomous design, planning, and performance of complex scientific experiments. This agent can use tools to browse the Internet, read documentation, execute code, call robotics experimentation APIs and leverage other LLMs.\\\\nFor example, when requested to \\\"develop a novel anticancer drug\\\", the model came up with the following reasoning steps:\\\\n\\\\ninquired about current trends in anticancer drug discovery;\\\\nselected a target;\\\\nrequested a scaffold targeting these compounds;\\\\nOnce the compound was identified, the model attempted its synthesis.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}), Document(page_content='Resources:\\\\n1. Internet access for searches and information gathering.\\\\n2. Long Term memory management.\\\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\\\n4. File output.\\\\n\\\\nPerformance Evaluation:\\\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\\\n2. Constructively self-criticize your big-picture behavior constantly.\\\\n3. Reflect on past decisions and strategies to refine your approach.\\\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'})], 0.06506215742069787)]\\n\\nQuestion: What is task decomposition for LLM agents?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [15.71s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex tasks into smaller, manageable subtasks or steps. This technique is often used in LLM-powered autonomous agent systems to enable efficient handling of complex tasks by leveraging the model's ability to generate multiple thoughts per step and explore multiple reasoning possibilities at each step.\\n\\nTask decomposition can be achieved through various methods, including:\\n\\n1. Using simple prompting techniques like \\\"Steps for XYZ\\\" or \\\"What are the subgoals for achieving XYZ?\\\" to guide the model's thinking process.\\n2. Providing task-specific instructions to the model, such as \\\"Write a story outline\\\" for writing a novel or \\\"Design a new drug\\\" for developing a new medication.\\n3. Utilizing human inputs to provide additional guidance and structure to the task decomposition process.\\n\\nBy decomposing complex tasks into smaller subtasks, LLM agents can better handle challenging problems and make more informed decisions. This approach also allows for more efficient handling of tasks by leveraging the model's ability to generate multiple thoughts per step and explore multiple reasoning possibilities at each step.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama2:latest\",\n",
      "          \"created_at\": \"2024-06-18T20:18:33.075772Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 15705623791,\n",
      "          \"load_duration\": 1651041,\n",
      "          \"prompt_eval_count\": 1656,\n",
      "          \"prompt_eval_duration\": 6145788000,\n",
      "          \"eval_count\": 253,\n",
      "          \"eval_duration\": 9534887000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex tasks into smaller, manageable subtasks or steps. This technique is often used in LLM-powered autonomous agent systems to enable efficient handling of complex tasks by leveraging the model's ability to generate multiple thoughts per step and explore multiple reasoning possibilities at each step.\\n\\nTask decomposition can be achieved through various methods, including:\\n\\n1. Using simple prompting techniques like \\\"Steps for XYZ\\\" or \\\"What are the subgoals for achieving XYZ?\\\" to guide the model's thinking process.\\n2. Providing task-specific instructions to the model, such as \\\"Write a story outline\\\" for writing a novel or \\\"Design a new drug\\\" for developing a new medication.\\n3. Utilizing human inputs to provide additional guidance and structure to the task decomposition process.\\n\\nBy decomposing complex tasks into smaller subtasks, LLM agents can better handle challenging problems and make more informed decisions. This approach also allows for more efficient handling of tasks by leveraging the model's ability to generate multiple thoughts per step and explore multiple reasoning possibilities at each step.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama2:latest\",\n",
      "              \"created_at\": \"2024-06-18T20:18:33.075772Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 15705623791,\n",
      "              \"load_duration\": 1651041,\n",
      "              \"prompt_eval_count\": 1656,\n",
      "              \"prompt_eval_duration\": 6145788000,\n",
      "              \"eval_count\": 253,\n",
      "              \"eval_duration\": 9534887000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-1f08f812-c675-4c81-b17e-2dab77f98745-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [2ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex tasks into smaller, manageable subtasks or steps. This technique is often used in LLM-powered autonomous agent systems to enable efficient handling of complex tasks by leveraging the model's ability to generate multiple thoughts per step and explore multiple reasoning possibilities at each step.\\n\\nTask decomposition can be achieved through various methods, including:\\n\\n1. Using simple prompting techniques like \\\"Steps for XYZ\\\" or \\\"What are the subgoals for achieving XYZ?\\\" to guide the model's thinking process.\\n2. Providing task-specific instructions to the model, such as \\\"Write a story outline\\\" for writing a novel or \\\"Design a new drug\\\" for developing a new medication.\\n3. Utilizing human inputs to provide additional guidance and structure to the task decomposition process.\\n\\nBy decomposing complex tasks into smaller subtasks, LLM agents can better handle challenging problems and make more informed decisions. This approach also allows for more efficient handling of tasks by leveraging the model's ability to generate multiple thoughts per step and explore multiple reasoning possibilities at each step.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [25.34s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex tasks into smaller, manageable subtasks or steps. This technique is often used in LLM-powered autonomous agent systems to enable efficient handling of complex tasks by leveraging the model's ability to generate multiple thoughts per step and explore multiple reasoning possibilities at each step.\\n\\nTask decomposition can be achieved through various methods, including:\\n\\n1. Using simple prompting techniques like \\\"Steps for XYZ\\\" or \\\"What are the subgoals for achieving XYZ?\\\" to guide the model's thinking process.\\n2. Providing task-specific instructions to the model, such as \\\"Write a story outline\\\" for writing a novel or \\\"Design a new drug\\\" for developing a new medication.\\n3. Utilizing human inputs to provide additional guidance and structure to the task decomposition process.\\n\\nBy decomposing complex tasks into smaller subtasks, LLM agents can better handle challenging problems and make more informed decisions. This approach also allows for more efficient handling of tasks by leveraging the model's ability to generate multiple thoughts per step and explore multiple reasoning possibilities at each step.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "rag_fusion_response = await final_rag_fusion_generation_chain.ainvoke({\"question\":\"What is task decomposition for LLM agents?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9b64d994-80ff-4d51-9c54-026f5cfa24d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex tasks into smaller, manageable subtasks or steps. This technique is often used in LLM-powered autonomous agent systems to enable efficient handling of complex tasks by leveraging the model's ability to generate multiple thoughts per step and explore multiple reasoning possibilities at each step.\n",
      "\n",
      "Task decomposition can be achieved through various methods, including:\n",
      "\n",
      "1. Using simple prompting techniques like \"Steps for XYZ\" or \"What are the subgoals for achieving XYZ?\" to guide the model's thinking process.\n",
      "2. Providing task-specific instructions to the model, such as \"Write a story outline\" for writing a novel or \"Design a new drug\" for developing a new medication.\n",
      "3. Utilizing human inputs to provide additional guidance and structure to the task decomposition process.\n",
      "\n",
      "By decomposing complex tasks into smaller subtasks, LLM agents can better handle challenging problems and make more informed decisions. This approach also allows for more efficient handling of tasks by leveraging the model's ability to generate multiple thoughts per step and explore multiple reasoning possibilities at each step.\n"
     ]
    }
   ],
   "source": [
    "print(rag_fusion_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64902b15-6e4f-4970-9ff4-ed8a44da6837",
   "metadata": {},
   "source": [
    "### Way 3: Query decomposition using Least to Most prompting and IR-CoT (Information retreival with Chain of Thought)\n",
    "Note: \n",
    "- Chain of Thought prompting combines natural language based rationale with few shot prompt. (https://arxiv.org/pdf/2201.11903)\n",
    "- CoT is further improved by adding self-consistency decoder (opposed to greedy decoder in vanilla CoT) (https://arxiv.org/pdf/2203.11171)\n",
    "- However, CoT has limitations that it performs poorly on tasks that require generalization of solving problems harder than few shot prompt examples.This is where Least to Most prompting comes in picture\n",
    "\n",
    "Least to Most prompting:\n",
    "1. Decompose a query into easier subqueries\n",
    "2. Sequentially solve subqueries using the reponse/ answer to previous subqueries\n",
    "3. Both stages are implemented by few-shot prompting, so that there is no training or\n",
    "finetuning in either stage\n",
    "\n",
    "IR-CoT (Information retreival with Chain of Thought): (https://arxiv.org/pdf/2212.10509)\n",
    "1. How can we augment chain-of-thought prompting for open-domain, knowledge-intensive tasks that require complex, multi-step reasoning?\n",
    "2. Use retrieval to guide the chain-of-thought (CoT) reasoning steps and use CoT reasoning to guide the retrieval.\n",
    "Steps:\n",
    "a. We begin by retrieving a base set of paragraphs using the question as a query.\n",
    "b. Subsequently, we alternate between the following two steps: (i) extend CoT: use the question, the paragraphs collected thus far, and the CoT sentences generated thus far to generate the next CoT sentence; (ii) expand retrieved information: use the last CoT sentence as a query to retrieve,additional paragraphs to add to the collected set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cdefdf-c9a7-41f1-9f0a-d47c9b5f371c",
   "metadata": {},
   "source": [
    "## So, Query decomposition means break query into simpler subproblems and then dynamically retreive answers for smaller problem and use to answer next subproblem.Useful only if it makes sense to decompose query into sub problems. e.g. complicated reasoning question where answer of simpler query will help answer more complicated query. else this approach is an overkill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5d03b4ca-1940-4562-8f64-887ba758ee52",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpler_subproblems_template = \"\"\"You are a helpful assistant that generates multiple sub-questions related to an input question. \\n\n",
    "The goal is to break down the input into a set of sub-problems / sub-questions that can be answers in isolation. Only return the sub problems, nothing else \\n\n",
    "Generate multiple search queries related to: {question} \\n\n",
    "Output (3 queries):\"\"\"\n",
    "prompt_simpler_subproblems_query = ChatPromptTemplate.from_template(simpler_subproblems_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f47711e4-0418-4151-8b77-801fe5d11585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant that generates multiple sub-questions related to an input question. \n",
      "\n",
      "The goal is to break down the input into a set of sub-problems / sub-questions that can be answers in isolation. Only return the sub problems, nothing else \n",
      "\n",
      "Generate multiple search queries related to: {question} \n",
      "\n",
      "Output (3 queries):\n"
     ]
    }
   ],
   "source": [
    "print(simpler_subproblems_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cc7696fd-a5c8-4870-bb93-8542b4f5427e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_queries_decomposition_chain = prompt_simpler_subproblems_query | local_llm | StrOutputParser() | (lambda x: [ss for ss in x.split(\"\\n\") if ss.strip() != '' and ss[0].isdigit()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0d585aa7-f29f-4731-8af5-510f8e5738ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the main components of an LLM-powered autonomous agent system?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the main components of an LLM-powered autonomous agent system?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a helpful assistant that generates multiple sub-questions related to an input question. \\n\\nThe goal is to break down the input into a set of sub-problems / sub-questions that can be answers in isolation. Only return the sub problems, nothing else \\n\\nGenerate multiple search queries related to: What are the main components of an LLM-powered autonomous agent system? \\n\\nOutput (3 queries):\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [4.56s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\\nHere are three sub-questions related to the input question \\\"What are the main components of an LLM-powered autonomous agent system?\\\":\\n\\n1. What types of machine learning algorithms does an LLM-powered autonomous agent system typically use for decision-making and control?\\n2. How does the LLM integrate with other technologies, such as computer vision or natural language processing, to enable more comprehensive and intelligent behavior?\\n3. What are some common applications of LLM-powered autonomous agent systems, such as robotics, self-driving cars, or virtual assistants, and how do they leverage the capabilities of the LLM?\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama2:latest\",\n",
      "          \"created_at\": \"2024-06-18T20:18:37.682642Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 4556826167,\n",
      "          \"load_duration\": 2447042,\n",
      "          \"prompt_eval_count\": 108,\n",
      "          \"prompt_eval_duration\": 509853000,\n",
      "          \"eval_count\": 144,\n",
      "          \"eval_duration\": 4042101000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\\nHere are three sub-questions related to the input question \\\"What are the main components of an LLM-powered autonomous agent system?\\\":\\n\\n1. What types of machine learning algorithms does an LLM-powered autonomous agent system typically use for decision-making and control?\\n2. How does the LLM integrate with other technologies, such as computer vision or natural language processing, to enable more comprehensive and intelligent behavior?\\n3. What are some common applications of LLM-powered autonomous agent systems, such as robotics, self-driving cars, or virtual assistants, and how do they leverage the capabilities of the LLM?\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama2:latest\",\n",
      "              \"created_at\": \"2024-06-18T20:18:37.682642Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 4556826167,\n",
      "              \"load_duration\": 2447042,\n",
      "              \"prompt_eval_count\": 108,\n",
      "              \"prompt_eval_duration\": 509853000,\n",
      "              \"eval_count\": 144,\n",
      "              \"eval_duration\": 4042101000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-6c9f246d-1441-4cc9-817f-1d3e7faea1f1-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [2ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"\\nHere are three sub-questions related to the input question \\\"What are the main components of an LLM-powered autonomous agent system?\\\":\\n\\n1. What types of machine learning algorithms does an LLM-powered autonomous agent system typically use for decision-making and control?\\n2. How does the LLM integrate with other technologies, such as computer vision or natural language processing, to enable more comprehensive and intelligent behavior?\\n3. What are some common applications of LLM-powered autonomous agent systems, such as robotics, self-driving cars, or virtual assistants, and how do they leverage the capabilities of the LLM?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"\\nHere are three sub-questions related to the input question \\\"What are the main components of an LLM-powered autonomous agent system?\\\":\\n\\n1. What types of machine learning algorithms does an LLM-powered autonomous agent system typically use for decision-making and control?\\n2. How does the LLM integrate with other technologies, such as computer vision or natural language processing, to enable more comprehensive and intelligent behavior?\\n3. What are some common applications of LLM-powered autonomous agent systems, such as robotics, self-driving cars, or virtual assistants, and how do they leverage the capabilities of the LLM?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": [\n",
      "    \"1. What types of machine learning algorithms does an LLM-powered autonomous agent system typically use for decision-making and control?\",\n",
      "    \"2. How does the LLM integrate with other technologies, such as computer vision or natural language processing, to enable more comprehensive and intelligent behavior?\",\n",
      "    \"3. What are some common applications of LLM-powered autonomous agent systems, such as robotics, self-driving cars, or virtual assistants, and how do they leverage the capabilities of the LLM?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [4.57s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": [\n",
      "    \"1. What types of machine learning algorithms does an LLM-powered autonomous agent system typically use for decision-making and control?\",\n",
      "    \"2. How does the LLM integrate with other technologies, such as computer vision or natural language processing, to enable more comprehensive and intelligent behavior?\",\n",
      "    \"3. What are some common applications of LLM-powered autonomous agent systems, such as robotics, self-driving cars, or virtual assistants, and how do they leverage the capabilities of the LLM?\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "decomposed_questions = await generate_queries_decomposition_chain.ainvoke({\"question\": \"What are the main components of an LLM-powered autonomous agent system?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "45029ba8-9eef-424e-89e3-be720b5a6ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. What types of machine learning algorithms does an LLM-powered autonomous agent system typically use for decision-making and control?',\n",
       " '2. How does the LLM integrate with other technologies, such as computer vision or natural language processing, to enable more comprehensive and intelligent behavior?',\n",
       " '3. What are some common applications of LLM-powered autonomous agent systems, such as robotics, self-driving cars, or virtual assistants, and how do they leverage the capabilities of the LLM?']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decomposed_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d3a09e4a-62f7-497b-a104-9245cfbbc7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ir_cot_template = \"\"\"Here is the question you need to answer:\n",
    "\n",
    "\\n --- \\n {question} \\n --- \\n\n",
    "\n",
    "Here is any available background question + answer pairs:\n",
    "\n",
    "\\n --- \\n {q_a_pairs} \\n --- \\n\n",
    "\n",
    "Here is additional context relevant to the question: \n",
    "\n",
    "\\n --- \\n {context} \\n --- \\n\n",
    "\n",
    "Use the above context and any background question + answer pairs to answer the question: \\n {question}\n",
    "\"\"\"\n",
    "prompt_ir_cot = ChatPromptTemplate.from_template(ir_cot_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3f44f9b0-41d5-4ed8-9820-2cb4a1199592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_qa_pair(question, answer):\n",
    "    \"\"\"Format Q and A pair\"\"\"\n",
    "    \n",
    "    formatted_string = \"\"\n",
    "    formatted_string += f\"Question: {question}\\nAnswer: {answer}\\n\\n\"\n",
    "    return formatted_string.strip() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "436fa51d-4b4d-4b0f-a5e4-8a4c4646dc64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"1. What types of machine learning algorithms does an LLM-powered autonomous agent system typically use for decision-making and control?\",\n",
      "  \"q_a_pairs\": \"\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question,q_a_pairs>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"1. What types of machine learning algorithms does an LLM-powered autonomous agent system typically use for decision-making and control?\",\n",
      "  \"q_a_pairs\": \"\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question,q_a_pairs> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"1. What types of machine learning algorithms does an LLM-powered autonomous agent system typically use for decision-making and control?\",\n",
      "  \"q_a_pairs\": \"\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question,q_a_pairs> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"1. What types of machine learning algorithms does an LLM-powered autonomous agent system typically use for decision-making and control?\",\n",
      "  \"q_a_pairs\": \"\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question,q_a_pairs> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"1. What types of machine learning algorithms does an LLM-powered autonomous agent system typically use for decision-making and control?\",\n",
      "  \"q_a_pairs\": \"\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question,q_a_pairs> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"1. What types of machine learning algorithms does an LLM-powered autonomous agent system typically use for decision-making and control?\",\n",
      "  \"q_a_pairs\": \"\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question,q_a_pairs> > chain:RunnableLambda] [3ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"1. What types of machine learning algorithms does an LLM-powered autonomous agent system typically use for decision-making and control?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question,q_a_pairs> > chain:RunnableLambda] [3ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question,q_a_pairs> > chain:RunnableSequence > chain:RunnableLambda] [3ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"1. What types of machine learning algorithms does an LLM-powered autonomous agent system typically use for decision-making and control?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question,q_a_pairs> > chain:RunnableSequence] [71ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question,q_a_pairs>] [72ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Here is the question you need to answer:\\n\\n\\n --- \\n 1. What types of machine learning algorithms does an LLM-powered autonomous agent system typically use for decision-making and control? \\n --- \\n\\n\\nHere is any available background question + answer pairs:\\n\\n\\n --- \\n  \\n --- \\n\\n\\nHere is additional context relevant to the question: \\n\\n\\n --- \\n [Document(page_content='LLM Powered Autonomous Agents\\\\n    \\\\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\\\n\\\\n\\\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview#\\\\nIn a LLM-powered autonomous agent system, LLM functions as the agents brain, complemented by several key components:\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}), Document(page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\\\nComponent One: Planning#\\\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\\\nTask Decomposition#\\\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to think step by step to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the models thinking process.\\\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\\\nTask decomposition can be done (1) by LLM with simple prompting like \\\"Steps for XYZ.\\\\\\\\n1.\\\", \\\"What are the subgoals for achieving XYZ?\\\", (2) by using task-specific instructions; e.g. \\\"Write a story outline.\\\" for writing a novel, or (3) with human inputs.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}), Document(page_content='Or\\\\n@article{weng2023agent,\\\\n  title   = \\\"LLM-powered Autonomous Agents\\\",\\\\n  author  = \\\"Weng, Lilian\\\",\\\\n  journal = \\\"lilianweng.github.io\\\",\\\\n  year    = \\\"2023\\\",\\\\n  month   = \\\"Jun\\\",\\\\n  url     = \\\"https://lilianweng.github.io/posts/2023-06-23-agent/\\\"\\\\n}\\\\nReferences#\\\\n[1] Wei et al. Chain of thought prompting elicits reasoning in large language models. NeurIPS 2022\\\\n[2] Yao et al. Tree of Thoughts: Dliberate Problem Solving with Large Language Models. arXiv preprint arXiv:2305.10601 (2023).\\\\n[3] Liu et al. Chain of Hindsight Aligns Language Models with Feedback\\\\n arXiv preprint arXiv:2302.02676 (2023).\\\\n[4] Liu et al. LLM+P: Empowering Large Language Models with Optimal Planning Proficiency arXiv preprint arXiv:2304.11477 (2023).', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}), Document(page_content='[4] Liu et al. LLM+P: Empowering Large Language Models with Optimal Planning Proficiency arXiv preprint arXiv:2304.11477 (2023).\\\\n[5] Yao et al. ReAct: Synergizing reasoning and acting in language models. ICLR 2023.\\\\n[6] Google Blog. Announcing ScaNN: Efficient Vector Similarity Search July 28, 2020.\\\\n[7] https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389\\\\n[8] Shinn & Labash. Reflexion: an autonomous agent with dynamic memory and self-reflection arXiv preprint arXiv:2303.11366 (2023).\\\\n[9] Laskin et al. In-context Reinforcement Learning with Algorithm Distillation ICLR 2023.\\\\n[10] Karpas et al. MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning. arXiv preprint arXiv:2205.00445 (2022).', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'})] \\n --- \\n\\n\\nUse the above context and any background question + answer pairs to answer the question: \\n 1. What types of machine learning algorithms does an LLM-powered autonomous agent system typically use for decision-making and control?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [26.31s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Based on the provided context, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms for decision-making and control, including:\\n\\n1. Large Language Models (LLMs): The core component of an LLM-powered autonomous agent system, LLMs are trained on vast amounts of text data to generate responses to prompts. They can be used for decision-making by breaking down complex tasks into smaller subgoals and evaluating possible actions based on their predicted outcomes.\\n2. Planning Algorithms: To plan ahead and handle complex tasks, an LLM-powered autonomous agent system may use planning algorithms such as Graphplan (Yao et al., 2023) or Breadth-First Search (BFS) (Li, 2018). These algorithms allow the agent to decompose tasks into smaller subgoals and generate a sequence of actions to achieve a desired outcome.\\n3. Reinforcement Learning Algorithms: To learn from experience and improve its decision-making abilities, an LLM-powered autonomous agent system may use reinforcement learning algorithms such as Q-learning (Watkins & Dayan, 1992) or Deep Deterministic Policy Gradients (DDPG) (Lillicrap et al., 2016). These algorithms allow the agent to learn from its interactions with the environment and adapt its behavior over time.\\n4. Deliberation Algorithms: To reflect on past actions and improve future decision-making, an LLM-powered autonomous agent system may use deliberation algorithms such as Incremental Logic (Liu et al., 2023) or Hindsight Alignment (Liu et al., 2023). These algorithms allow the agent to evaluate its past actions and adjust its behavior accordingly.\\n5. Optimal Planning Algorithms: To plan and execute complex tasks efficiently, an LLM-powered autonomous agent system may use optimal planning algorithms such as Linear Programming (LP) (Bellman, 1957) or Mixed-Integer Quadratic Programming (MIQP) (Lukasik & Martello, 1983). These algorithms allow the agent to optimize its plan based on constraints and objectives.\\n\\nIn summary, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms, including LLMs, planning algorithms, reinforcement learning algorithms, deliberation algorithms, and optimal planning algorithms, to make decisions and control its behavior.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama2:latest\",\n",
      "          \"created_at\": \"2024-06-18T20:19:04.11462Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 26309727208,\n",
      "          \"load_duration\": 1451875,\n",
      "          \"prompt_eval_count\": 1542,\n",
      "          \"prompt_eval_duration\": 5765699000,\n",
      "          \"eval_count\": 554,\n",
      "          \"eval_duration\": 20533712000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Based on the provided context, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms for decision-making and control, including:\\n\\n1. Large Language Models (LLMs): The core component of an LLM-powered autonomous agent system, LLMs are trained on vast amounts of text data to generate responses to prompts. They can be used for decision-making by breaking down complex tasks into smaller subgoals and evaluating possible actions based on their predicted outcomes.\\n2. Planning Algorithms: To plan ahead and handle complex tasks, an LLM-powered autonomous agent system may use planning algorithms such as Graphplan (Yao et al., 2023) or Breadth-First Search (BFS) (Li, 2018). These algorithms allow the agent to decompose tasks into smaller subgoals and generate a sequence of actions to achieve a desired outcome.\\n3. Reinforcement Learning Algorithms: To learn from experience and improve its decision-making abilities, an LLM-powered autonomous agent system may use reinforcement learning algorithms such as Q-learning (Watkins & Dayan, 1992) or Deep Deterministic Policy Gradients (DDPG) (Lillicrap et al., 2016). These algorithms allow the agent to learn from its interactions with the environment and adapt its behavior over time.\\n4. Deliberation Algorithms: To reflect on past actions and improve future decision-making, an LLM-powered autonomous agent system may use deliberation algorithms such as Incremental Logic (Liu et al., 2023) or Hindsight Alignment (Liu et al., 2023). These algorithms allow the agent to evaluate its past actions and adjust its behavior accordingly.\\n5. Optimal Planning Algorithms: To plan and execute complex tasks efficiently, an LLM-powered autonomous agent system may use optimal planning algorithms such as Linear Programming (LP) (Bellman, 1957) or Mixed-Integer Quadratic Programming (MIQP) (Lukasik & Martello, 1983). These algorithms allow the agent to optimize its plan based on constraints and objectives.\\n\\nIn summary, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms, including LLMs, planning algorithms, reinforcement learning algorithms, deliberation algorithms, and optimal planning algorithms, to make decisions and control its behavior.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama2:latest\",\n",
      "              \"created_at\": \"2024-06-18T20:19:04.11462Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 26309727208,\n",
      "              \"load_duration\": 1451875,\n",
      "              \"prompt_eval_count\": 1542,\n",
      "              \"prompt_eval_duration\": 5765699000,\n",
      "              \"eval_count\": 554,\n",
      "              \"eval_duration\": 20533712000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-0de0f957-e9d3-478d-9561-37559570af8b-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [2ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Based on the provided context, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms for decision-making and control, including:\\n\\n1. Large Language Models (LLMs): The core component of an LLM-powered autonomous agent system, LLMs are trained on vast amounts of text data to generate responses to prompts. They can be used for decision-making by breaking down complex tasks into smaller subgoals and evaluating possible actions based on their predicted outcomes.\\n2. Planning Algorithms: To plan ahead and handle complex tasks, an LLM-powered autonomous agent system may use planning algorithms such as Graphplan (Yao et al., 2023) or Breadth-First Search (BFS) (Li, 2018). These algorithms allow the agent to decompose tasks into smaller subgoals and generate a sequence of actions to achieve a desired outcome.\\n3. Reinforcement Learning Algorithms: To learn from experience and improve its decision-making abilities, an LLM-powered autonomous agent system may use reinforcement learning algorithms such as Q-learning (Watkins & Dayan, 1992) or Deep Deterministic Policy Gradients (DDPG) (Lillicrap et al., 2016). These algorithms allow the agent to learn from its interactions with the environment and adapt its behavior over time.\\n4. Deliberation Algorithms: To reflect on past actions and improve future decision-making, an LLM-powered autonomous agent system may use deliberation algorithms such as Incremental Logic (Liu et al., 2023) or Hindsight Alignment (Liu et al., 2023). These algorithms allow the agent to evaluate its past actions and adjust its behavior accordingly.\\n5. Optimal Planning Algorithms: To plan and execute complex tasks efficiently, an LLM-powered autonomous agent system may use optimal planning algorithms such as Linear Programming (LP) (Bellman, 1957) or Mixed-Integer Quadratic Programming (MIQP) (Lukasik & Martello, 1983). These algorithms allow the agent to optimize its plan based on constraints and objectives.\\n\\nIn summary, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms, including LLMs, planning algorithms, reinforcement learning algorithms, deliberation algorithms, and optimal planning algorithms, to make decisions and control its behavior.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [26.40s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Based on the provided context, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms for decision-making and control, including:\\n\\n1. Large Language Models (LLMs): The core component of an LLM-powered autonomous agent system, LLMs are trained on vast amounts of text data to generate responses to prompts. They can be used for decision-making by breaking down complex tasks into smaller subgoals and evaluating possible actions based on their predicted outcomes.\\n2. Planning Algorithms: To plan ahead and handle complex tasks, an LLM-powered autonomous agent system may use planning algorithms such as Graphplan (Yao et al., 2023) or Breadth-First Search (BFS) (Li, 2018). These algorithms allow the agent to decompose tasks into smaller subgoals and generate a sequence of actions to achieve a desired outcome.\\n3. Reinforcement Learning Algorithms: To learn from experience and improve its decision-making abilities, an LLM-powered autonomous agent system may use reinforcement learning algorithms such as Q-learning (Watkins & Dayan, 1992) or Deep Deterministic Policy Gradients (DDPG) (Lillicrap et al., 2016). These algorithms allow the agent to learn from its interactions with the environment and adapt its behavior over time.\\n4. Deliberation Algorithms: To reflect on past actions and improve future decision-making, an LLM-powered autonomous agent system may use deliberation algorithms such as Incremental Logic (Liu et al., 2023) or Hindsight Alignment (Liu et al., 2023). These algorithms allow the agent to evaluate its past actions and adjust its behavior accordingly.\\n5. Optimal Planning Algorithms: To plan and execute complex tasks efficiently, an LLM-powered autonomous agent system may use optimal planning algorithms such as Linear Programming (LP) (Bellman, 1957) or Mixed-Integer Quadratic Programming (MIQP) (Lukasik & Martello, 1983). These algorithms allow the agent to optimize its plan based on constraints and objectives.\\n\\nIn summary, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms, including LLMs, planning algorithms, reinforcement learning algorithms, deliberation algorithms, and optimal planning algorithms, to make decisions and control its behavior.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"2. How does the LLM integrate with other technologies, such as computer vision or natural language processing, to enable more comprehensive and intelligent behavior?\",\n",
      "  \"q_a_pairs\": \"\\n---\\nQuestion: 1. What types of machine learning algorithms does an LLM-powered autonomous agent system typically use for decision-making and control?\\nAnswer: Based on the provided context, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms for decision-making and control, including:\\n\\n1. Large Language Models (LLMs): The core component of an LLM-powered autonomous agent system, LLMs are trained on vast amounts of text data to generate responses to prompts. They can be used for decision-making by breaking down complex tasks into smaller subgoals and evaluating possible actions based on their predicted outcomes.\\n2. Planning Algorithms: To plan ahead and handle complex tasks, an LLM-powered autonomous agent system may use planning algorithms such as Graphplan (Yao et al., 2023) or Breadth-First Search (BFS) (Li, 2018). These algorithms allow the agent to decompose tasks into smaller subgoals and generate a sequence of actions to achieve a desired outcome.\\n3. Reinforcement Learning Algorithms: To learn from experience and improve its decision-making abilities, an LLM-powered autonomous agent system may use reinforcement learning algorithms such as Q-learning (Watkins & Dayan, 1992) or Deep Deterministic Policy Gradients (DDPG) (Lillicrap et al., 2016). These algorithms allow the agent to learn from its interactions with the environment and adapt its behavior over time.\\n4. Deliberation Algorithms: To reflect on past actions and improve future decision-making, an LLM-powered autonomous agent system may use deliberation algorithms such as Incremental Logic (Liu et al., 2023) or Hindsight Alignment (Liu et al., 2023). These algorithms allow the agent to evaluate its past actions and adjust its behavior accordingly.\\n5. Optimal Planning Algorithms: To plan and execute complex tasks efficiently, an LLM-powered autonomous agent system may use optimal planning algorithms such as Linear Programming (LP) (Bellman, 1957) or Mixed-Integer Quadratic Programming (MIQP) (Lukasik & Martello, 1983). These algorithms allow the agent to optimize its plan based on constraints and objectives.\\n\\nIn summary, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms, including LLMs, planning algorithms, reinforcement learning algorithms, deliberation algorithms, and optimal planning algorithms, to make decisions and control its behavior.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question,q_a_pairs>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"2. How does the LLM integrate with other technologies, such as computer vision or natural language processing, to enable more comprehensive and intelligent behavior?\",\n",
      "  \"q_a_pairs\": \"\\n---\\nQuestion: 1. What types of machine learning algorithms does an LLM-powered autonomous agent system typically use for decision-making and control?\\nAnswer: Based on the provided context, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms for decision-making and control, including:\\n\\n1. Large Language Models (LLMs): The core component of an LLM-powered autonomous agent system, LLMs are trained on vast amounts of text data to generate responses to prompts. They can be used for decision-making by breaking down complex tasks into smaller subgoals and evaluating possible actions based on their predicted outcomes.\\n2. Planning Algorithms: To plan ahead and handle complex tasks, an LLM-powered autonomous agent system may use planning algorithms such as Graphplan (Yao et al., 2023) or Breadth-First Search (BFS) (Li, 2018). These algorithms allow the agent to decompose tasks into smaller subgoals and generate a sequence of actions to achieve a desired outcome.\\n3. Reinforcement Learning Algorithms: To learn from experience and improve its decision-making abilities, an LLM-powered autonomous agent system may use reinforcement learning algorithms such as Q-learning (Watkins & Dayan, 1992) or Deep Deterministic Policy Gradients (DDPG) (Lillicrap et al., 2016). These algorithms allow the agent to learn from its interactions with the environment and adapt its behavior over time.\\n4. Deliberation Algorithms: To reflect on past actions and improve future decision-making, an LLM-powered autonomous agent system may use deliberation algorithms such as Incremental Logic (Liu et al., 2023) or Hindsight Alignment (Liu et al., 2023). These algorithms allow the agent to evaluate its past actions and adjust its behavior accordingly.\\n5. Optimal Planning Algorithms: To plan and execute complex tasks efficiently, an LLM-powered autonomous agent system may use optimal planning algorithms such as Linear Programming (LP) (Bellman, 1957) or Mixed-Integer Quadratic Programming (MIQP) (Lukasik & Martello, 1983). These algorithms allow the agent to optimize its plan based on constraints and objectives.\\n\\nIn summary, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms, including LLMs, planning algorithms, reinforcement learning algorithms, deliberation algorithms, and optimal planning algorithms, to make decisions and control its behavior.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question,q_a_pairs> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"2. How does the LLM integrate with other technologies, such as computer vision or natural language processing, to enable more comprehensive and intelligent behavior?\",\n",
      "  \"q_a_pairs\": \"\\n---\\nQuestion: 1. What types of machine learning algorithms does an LLM-powered autonomous agent system typically use for decision-making and control?\\nAnswer: Based on the provided context, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms for decision-making and control, including:\\n\\n1. Large Language Models (LLMs): The core component of an LLM-powered autonomous agent system, LLMs are trained on vast amounts of text data to generate responses to prompts. They can be used for decision-making by breaking down complex tasks into smaller subgoals and evaluating possible actions based on their predicted outcomes.\\n2. Planning Algorithms: To plan ahead and handle complex tasks, an LLM-powered autonomous agent system may use planning algorithms such as Graphplan (Yao et al., 2023) or Breadth-First Search (BFS) (Li, 2018). These algorithms allow the agent to decompose tasks into smaller subgoals and generate a sequence of actions to achieve a desired outcome.\\n3. Reinforcement Learning Algorithms: To learn from experience and improve its decision-making abilities, an LLM-powered autonomous agent system may use reinforcement learning algorithms such as Q-learning (Watkins & Dayan, 1992) or Deep Deterministic Policy Gradients (DDPG) (Lillicrap et al., 2016). These algorithms allow the agent to learn from its interactions with the environment and adapt its behavior over time.\\n4. Deliberation Algorithms: To reflect on past actions and improve future decision-making, an LLM-powered autonomous agent system may use deliberation algorithms such as Incremental Logic (Liu et al., 2023) or Hindsight Alignment (Liu et al., 2023). These algorithms allow the agent to evaluate its past actions and adjust its behavior accordingly.\\n5. Optimal Planning Algorithms: To plan and execute complex tasks efficiently, an LLM-powered autonomous agent system may use optimal planning algorithms such as Linear Programming (LP) (Bellman, 1957) or Mixed-Integer Quadratic Programming (MIQP) (Lukasik & Martello, 1983). These algorithms allow the agent to optimize its plan based on constraints and objectives.\\n\\nIn summary, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms, including LLMs, planning algorithms, reinforcement learning algorithms, deliberation algorithms, and optimal planning algorithms, to make decisions and control its behavior.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question,q_a_pairs> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"2. How does the LLM integrate with other technologies, such as computer vision or natural language processing, to enable more comprehensive and intelligent behavior?\",\n",
      "  \"q_a_pairs\": \"\\n---\\nQuestion: 1. What types of machine learning algorithms does an LLM-powered autonomous agent system typically use for decision-making and control?\\nAnswer: Based on the provided context, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms for decision-making and control, including:\\n\\n1. Large Language Models (LLMs): The core component of an LLM-powered autonomous agent system, LLMs are trained on vast amounts of text data to generate responses to prompts. They can be used for decision-making by breaking down complex tasks into smaller subgoals and evaluating possible actions based on their predicted outcomes.\\n2. Planning Algorithms: To plan ahead and handle complex tasks, an LLM-powered autonomous agent system may use planning algorithms such as Graphplan (Yao et al., 2023) or Breadth-First Search (BFS) (Li, 2018). These algorithms allow the agent to decompose tasks into smaller subgoals and generate a sequence of actions to achieve a desired outcome.\\n3. Reinforcement Learning Algorithms: To learn from experience and improve its decision-making abilities, an LLM-powered autonomous agent system may use reinforcement learning algorithms such as Q-learning (Watkins & Dayan, 1992) or Deep Deterministic Policy Gradients (DDPG) (Lillicrap et al., 2016). These algorithms allow the agent to learn from its interactions with the environment and adapt its behavior over time.\\n4. Deliberation Algorithms: To reflect on past actions and improve future decision-making, an LLM-powered autonomous agent system may use deliberation algorithms such as Incremental Logic (Liu et al., 2023) or Hindsight Alignment (Liu et al., 2023). These algorithms allow the agent to evaluate its past actions and adjust its behavior accordingly.\\n5. Optimal Planning Algorithms: To plan and execute complex tasks efficiently, an LLM-powered autonomous agent system may use optimal planning algorithms such as Linear Programming (LP) (Bellman, 1957) or Mixed-Integer Quadratic Programming (MIQP) (Lukasik & Martello, 1983). These algorithms allow the agent to optimize its plan based on constraints and objectives.\\n\\nIn summary, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms, including LLMs, planning algorithms, reinforcement learning algorithms, deliberation algorithms, and optimal planning algorithms, to make decisions and control its behavior.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question,q_a_pairs> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"2. How does the LLM integrate with other technologies, such as computer vision or natural language processing, to enable more comprehensive and intelligent behavior?\",\n",
      "  \"q_a_pairs\": \"\\n---\\nQuestion: 1. What types of machine learning algorithms does an LLM-powered autonomous agent system typically use for decision-making and control?\\nAnswer: Based on the provided context, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms for decision-making and control, including:\\n\\n1. Large Language Models (LLMs): The core component of an LLM-powered autonomous agent system, LLMs are trained on vast amounts of text data to generate responses to prompts. They can be used for decision-making by breaking down complex tasks into smaller subgoals and evaluating possible actions based on their predicted outcomes.\\n2. Planning Algorithms: To plan ahead and handle complex tasks, an LLM-powered autonomous agent system may use planning algorithms such as Graphplan (Yao et al., 2023) or Breadth-First Search (BFS) (Li, 2018). These algorithms allow the agent to decompose tasks into smaller subgoals and generate a sequence of actions to achieve a desired outcome.\\n3. Reinforcement Learning Algorithms: To learn from experience and improve its decision-making abilities, an LLM-powered autonomous agent system may use reinforcement learning algorithms such as Q-learning (Watkins & Dayan, 1992) or Deep Deterministic Policy Gradients (DDPG) (Lillicrap et al., 2016). These algorithms allow the agent to learn from its interactions with the environment and adapt its behavior over time.\\n4. Deliberation Algorithms: To reflect on past actions and improve future decision-making, an LLM-powered autonomous agent system may use deliberation algorithms such as Incremental Logic (Liu et al., 2023) or Hindsight Alignment (Liu et al., 2023). These algorithms allow the agent to evaluate its past actions and adjust its behavior accordingly.\\n5. Optimal Planning Algorithms: To plan and execute complex tasks efficiently, an LLM-powered autonomous agent system may use optimal planning algorithms such as Linear Programming (LP) (Bellman, 1957) or Mixed-Integer Quadratic Programming (MIQP) (Lukasik & Martello, 1983). These algorithms allow the agent to optimize its plan based on constraints and objectives.\\n\\nIn summary, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms, including LLMs, planning algorithms, reinforcement learning algorithms, deliberation algorithms, and optimal planning algorithms, to make decisions and control its behavior.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question,q_a_pairs> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"2. How does the LLM integrate with other technologies, such as computer vision or natural language processing, to enable more comprehensive and intelligent behavior?\",\n",
      "  \"q_a_pairs\": \"\\n---\\nQuestion: 1. What types of machine learning algorithms does an LLM-powered autonomous agent system typically use for decision-making and control?\\nAnswer: Based on the provided context, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms for decision-making and control, including:\\n\\n1. Large Language Models (LLMs): The core component of an LLM-powered autonomous agent system, LLMs are trained on vast amounts of text data to generate responses to prompts. They can be used for decision-making by breaking down complex tasks into smaller subgoals and evaluating possible actions based on their predicted outcomes.\\n2. Planning Algorithms: To plan ahead and handle complex tasks, an LLM-powered autonomous agent system may use planning algorithms such as Graphplan (Yao et al., 2023) or Breadth-First Search (BFS) (Li, 2018). These algorithms allow the agent to decompose tasks into smaller subgoals and generate a sequence of actions to achieve a desired outcome.\\n3. Reinforcement Learning Algorithms: To learn from experience and improve its decision-making abilities, an LLM-powered autonomous agent system may use reinforcement learning algorithms such as Q-learning (Watkins & Dayan, 1992) or Deep Deterministic Policy Gradients (DDPG) (Lillicrap et al., 2016). These algorithms allow the agent to learn from its interactions with the environment and adapt its behavior over time.\\n4. Deliberation Algorithms: To reflect on past actions and improve future decision-making, an LLM-powered autonomous agent system may use deliberation algorithms such as Incremental Logic (Liu et al., 2023) or Hindsight Alignment (Liu et al., 2023). These algorithms allow the agent to evaluate its past actions and adjust its behavior accordingly.\\n5. Optimal Planning Algorithms: To plan and execute complex tasks efficiently, an LLM-powered autonomous agent system may use optimal planning algorithms such as Linear Programming (LP) (Bellman, 1957) or Mixed-Integer Quadratic Programming (MIQP) (Lukasik & Martello, 1983). These algorithms allow the agent to optimize its plan based on constraints and objectives.\\n\\nIn summary, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms, including LLMs, planning algorithms, reinforcement learning algorithms, deliberation algorithms, and optimal planning algorithms, to make decisions and control its behavior.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question,q_a_pairs> > chain:RunnableLambda] [3ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"2. How does the LLM integrate with other technologies, such as computer vision or natural language processing, to enable more comprehensive and intelligent behavior?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question,q_a_pairs> > chain:RunnableLambda] [3ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"\\n---\\nQuestion: 1. What types of machine learning algorithms does an LLM-powered autonomous agent system typically use for decision-making and control?\\nAnswer: Based on the provided context, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms for decision-making and control, including:\\n\\n1. Large Language Models (LLMs): The core component of an LLM-powered autonomous agent system, LLMs are trained on vast amounts of text data to generate responses to prompts. They can be used for decision-making by breaking down complex tasks into smaller subgoals and evaluating possible actions based on their predicted outcomes.\\n2. Planning Algorithms: To plan ahead and handle complex tasks, an LLM-powered autonomous agent system may use planning algorithms such as Graphplan (Yao et al., 2023) or Breadth-First Search (BFS) (Li, 2018). These algorithms allow the agent to decompose tasks into smaller subgoals and generate a sequence of actions to achieve a desired outcome.\\n3. Reinforcement Learning Algorithms: To learn from experience and improve its decision-making abilities, an LLM-powered autonomous agent system may use reinforcement learning algorithms such as Q-learning (Watkins & Dayan, 1992) or Deep Deterministic Policy Gradients (DDPG) (Lillicrap et al., 2016). These algorithms allow the agent to learn from its interactions with the environment and adapt its behavior over time.\\n4. Deliberation Algorithms: To reflect on past actions and improve future decision-making, an LLM-powered autonomous agent system may use deliberation algorithms such as Incremental Logic (Liu et al., 2023) or Hindsight Alignment (Liu et al., 2023). These algorithms allow the agent to evaluate its past actions and adjust its behavior accordingly.\\n5. Optimal Planning Algorithms: To plan and execute complex tasks efficiently, an LLM-powered autonomous agent system may use optimal planning algorithms such as Linear Programming (LP) (Bellman, 1957) or Mixed-Integer Quadratic Programming (MIQP) (Lukasik & Martello, 1983). These algorithms allow the agent to optimize its plan based on constraints and objectives.\\n\\nIn summary, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms, including LLMs, planning algorithms, reinforcement learning algorithms, deliberation algorithms, and optimal planning algorithms, to make decisions and control its behavior.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question,q_a_pairs> > chain:RunnableSequence > chain:RunnableLambda] [3ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"2. How does the LLM integrate with other technologies, such as computer vision or natural language processing, to enable more comprehensive and intelligent behavior?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question,q_a_pairs> > chain:RunnableSequence] [78ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question,q_a_pairs>] [79ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Here is the question you need to answer:\\n\\n\\n --- \\n 2. How does the LLM integrate with other technologies, such as computer vision or natural language processing, to enable more comprehensive and intelligent behavior? \\n --- \\n\\n\\nHere is any available background question + answer pairs:\\n\\n\\n --- \\n \\n---\\nQuestion: 1. What types of machine learning algorithms does an LLM-powered autonomous agent system typically use for decision-making and control?\\nAnswer: Based on the provided context, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms for decision-making and control, including:\\n\\n1. Large Language Models (LLMs): The core component of an LLM-powered autonomous agent system, LLMs are trained on vast amounts of text data to generate responses to prompts. They can be used for decision-making by breaking down complex tasks into smaller subgoals and evaluating possible actions based on their predicted outcomes.\\n2. Planning Algorithms: To plan ahead and handle complex tasks, an LLM-powered autonomous agent system may use planning algorithms such as Graphplan (Yao et al., 2023) or Breadth-First Search (BFS) (Li, 2018). These algorithms allow the agent to decompose tasks into smaller subgoals and generate a sequence of actions to achieve a desired outcome.\\n3. Reinforcement Learning Algorithms: To learn from experience and improve its decision-making abilities, an LLM-powered autonomous agent system may use reinforcement learning algorithms such as Q-learning (Watkins & Dayan, 1992) or Deep Deterministic Policy Gradients (DDPG) (Lillicrap et al., 2016). These algorithms allow the agent to learn from its interactions with the environment and adapt its behavior over time.\\n4. Deliberation Algorithms: To reflect on past actions and improve future decision-making, an LLM-powered autonomous agent system may use deliberation algorithms such as Incremental Logic (Liu et al., 2023) or Hindsight Alignment (Liu et al., 2023). These algorithms allow the agent to evaluate its past actions and adjust its behavior accordingly.\\n5. Optimal Planning Algorithms: To plan and execute complex tasks efficiently, an LLM-powered autonomous agent system may use optimal planning algorithms such as Linear Programming (LP) (Bellman, 1957) or Mixed-Integer Quadratic Programming (MIQP) (Lukasik & Martello, 1983). These algorithms allow the agent to optimize its plan based on constraints and objectives.\\n\\nIn summary, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms, including LLMs, planning algorithms, reinforcement learning algorithms, deliberation algorithms, and optimal planning algorithms, to make decisions and control its behavior. \\n --- \\n\\n\\nHere is additional context relevant to the question: \\n\\n\\n --- \\n [Document(page_content='Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\\\nThe system comprises of 4 stages:\\\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\\\nInstruction:', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}), Document(page_content='One interesting observation is that while the LLM-based evaluation concluded that GPT-4 and ChemCrow perform nearly equivalently, human evaluations with experts oriented towards the completion and chemical correctness of the solutions showed that ChemCrow outperforms GPT-4 by a large margin. This indicates a potential problem with using LLM to evaluate its own performance on domains that requires deep expertise. The lack of expertise may cause LLMs not knowing its flaws and thus cannot well judge the correctness of task results.\\\\nBoiko et al. (2023) also looked into LLM-empowered agents for scientific discovery, to handle autonomous design, planning, and performance of complex scientific experiments. This agent can use tools to browse the Internet, read documentation, execute code, call robotics experimentation APIs and leverage other LLMs.\\\\nFor example, when requested to \\\"develop a novel anticancer drug\\\", the model came up with the following reasoning steps:\\\\n\\\\ninquired about current trends in anticancer drug discovery;\\\\nselected a target;\\\\nrequested a scaffold targeting these compounds;\\\\nOnce the compound was identified, the model attempted its synthesis.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}), Document(page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\\\nComponent One: Planning#\\\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\\\nTask Decomposition#\\\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to think step by step to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the models thinking process.\\\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\\\nTask decomposition can be done (1) by LLM with simple prompting like \\\"Steps for XYZ.\\\\\\\\n1.\\\", \\\"What are the subgoals for achieving XYZ?\\\", (2) by using task-specific instructions; e.g. \\\"Write a story outline.\\\" for writing a novel, or (3) with human inputs.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}), Document(page_content='LLM Powered Autonomous Agents\\\\n    \\\\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\\\n\\\\n\\\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview#\\\\nIn a LLM-powered autonomous agent system, LLM functions as the agents brain, complemented by several key components:\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'})] \\n --- \\n\\n\\nUse the above context and any background question + answer pairs to answer the question: \\n 2. How does the LLM integrate with other technologies, such as computer vision or natural language processing, to enable more comprehensive and intelligent behavior?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [26.88s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Based on the provided context, an LLM-powered autonomous agent system typically integrates with other technologies, such as computer vision or natural language processing, through various methods to enable more comprehensive and intelligent behavior. Here are some possible ways:\\n\\n1. Multi-modal input integration: An LLM can integrate with computer vision or natural language processing systems to process multi-modal inputs, such as images and text, simultaneously. For example, an autonomous vehicle equipped with a computer vision system can use the LLM to analyze visual data and make decisions based on both visual and linguistic information.\\n2. Task decomposition: An LLM can break down complex tasks into smaller subgoals using task decomposition techniques, such as chain of thought (CoT) or tree of thoughts (Yao et al., 2023). These techniques allow the LLM to integrate with other technologies, such as natural language processing, to perform more comprehensive and intelligent behavior.\\n3. Hybrid reasoning: An LLM can use hybrid reasoning techniques that combine symbolic and connectionist approaches to integrate with other technologies, such as computer vision or robotics. For example, an autonomous robot can use an LLM to reason about the spatial relationships between objects in its environment and make decisions based on both symbolic and connectionist representations (Wei et al., 2022).\\n4. Transfer learning: An LLM can use transfer learning techniques to leverage knowledge gained from one task or domain to perform another related task or domain. For example, an LLM trained on natural language processing tasks can be fine-tuned for computer vision tasks by adapting the learned representations and weights (Ruder et al., 2019).\\n5. Joint training: An LLM can be jointly trained with other technologies, such as computer vision or natural language processing, to learn shared representations and improve generalization to new tasks or domains. For example, an LLM trained on a combination of natural language processing and computer vision tasks can leverage the shared knowledge and representations to perform more comprehensive and intelligent behavior (Li et al., 2019).\\n\\nIn summary, an LLM-powered autonomous agent system typically integrates with other technologies, such as computer vision or natural language processing, through various methods to enable more comprehensive and intelligent behavior. These methods include multi-modal input integration, task decomposition, hybrid reasoning, transfer learning, and joint training.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama2:latest\",\n",
      "          \"created_at\": \"2024-06-18T20:19:31.101446Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 26878921416,\n",
      "          \"load_duration\": 692291,\n",
      "          \"prompt_eval_count\": 1869,\n",
      "          \"prompt_eval_duration\": 6952397000,\n",
      "          \"eval_count\": 525,\n",
      "          \"eval_duration\": 19920820000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Based on the provided context, an LLM-powered autonomous agent system typically integrates with other technologies, such as computer vision or natural language processing, through various methods to enable more comprehensive and intelligent behavior. Here are some possible ways:\\n\\n1. Multi-modal input integration: An LLM can integrate with computer vision or natural language processing systems to process multi-modal inputs, such as images and text, simultaneously. For example, an autonomous vehicle equipped with a computer vision system can use the LLM to analyze visual data and make decisions based on both visual and linguistic information.\\n2. Task decomposition: An LLM can break down complex tasks into smaller subgoals using task decomposition techniques, such as chain of thought (CoT) or tree of thoughts (Yao et al., 2023). These techniques allow the LLM to integrate with other technologies, such as natural language processing, to perform more comprehensive and intelligent behavior.\\n3. Hybrid reasoning: An LLM can use hybrid reasoning techniques that combine symbolic and connectionist approaches to integrate with other technologies, such as computer vision or robotics. For example, an autonomous robot can use an LLM to reason about the spatial relationships between objects in its environment and make decisions based on both symbolic and connectionist representations (Wei et al., 2022).\\n4. Transfer learning: An LLM can use transfer learning techniques to leverage knowledge gained from one task or domain to perform another related task or domain. For example, an LLM trained on natural language processing tasks can be fine-tuned for computer vision tasks by adapting the learned representations and weights (Ruder et al., 2019).\\n5. Joint training: An LLM can be jointly trained with other technologies, such as computer vision or natural language processing, to learn shared representations and improve generalization to new tasks or domains. For example, an LLM trained on a combination of natural language processing and computer vision tasks can leverage the shared knowledge and representations to perform more comprehensive and intelligent behavior (Li et al., 2019).\\n\\nIn summary, an LLM-powered autonomous agent system typically integrates with other technologies, such as computer vision or natural language processing, through various methods to enable more comprehensive and intelligent behavior. These methods include multi-modal input integration, task decomposition, hybrid reasoning, transfer learning, and joint training.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama2:latest\",\n",
      "              \"created_at\": \"2024-06-18T20:19:31.101446Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 26878921416,\n",
      "              \"load_duration\": 692291,\n",
      "              \"prompt_eval_count\": 1869,\n",
      "              \"prompt_eval_duration\": 6952397000,\n",
      "              \"eval_count\": 525,\n",
      "              \"eval_duration\": 19920820000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-fb4f99d3-5c06-44d0-8879-de98c7fcbbc7-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [2ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Based on the provided context, an LLM-powered autonomous agent system typically integrates with other technologies, such as computer vision or natural language processing, through various methods to enable more comprehensive and intelligent behavior. Here are some possible ways:\\n\\n1. Multi-modal input integration: An LLM can integrate with computer vision or natural language processing systems to process multi-modal inputs, such as images and text, simultaneously. For example, an autonomous vehicle equipped with a computer vision system can use the LLM to analyze visual data and make decisions based on both visual and linguistic information.\\n2. Task decomposition: An LLM can break down complex tasks into smaller subgoals using task decomposition techniques, such as chain of thought (CoT) or tree of thoughts (Yao et al., 2023). These techniques allow the LLM to integrate with other technologies, such as natural language processing, to perform more comprehensive and intelligent behavior.\\n3. Hybrid reasoning: An LLM can use hybrid reasoning techniques that combine symbolic and connectionist approaches to integrate with other technologies, such as computer vision or robotics. For example, an autonomous robot can use an LLM to reason about the spatial relationships between objects in its environment and make decisions based on both symbolic and connectionist representations (Wei et al., 2022).\\n4. Transfer learning: An LLM can use transfer learning techniques to leverage knowledge gained from one task or domain to perform another related task or domain. For example, an LLM trained on natural language processing tasks can be fine-tuned for computer vision tasks by adapting the learned representations and weights (Ruder et al., 2019).\\n5. Joint training: An LLM can be jointly trained with other technologies, such as computer vision or natural language processing, to learn shared representations and improve generalization to new tasks or domains. For example, an LLM trained on a combination of natural language processing and computer vision tasks can leverage the shared knowledge and representations to perform more comprehensive and intelligent behavior (Li et al., 2019).\\n\\nIn summary, an LLM-powered autonomous agent system typically integrates with other technologies, such as computer vision or natural language processing, through various methods to enable more comprehensive and intelligent behavior. These methods include multi-modal input integration, task decomposition, hybrid reasoning, transfer learning, and joint training.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [26.97s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Based on the provided context, an LLM-powered autonomous agent system typically integrates with other technologies, such as computer vision or natural language processing, through various methods to enable more comprehensive and intelligent behavior. Here are some possible ways:\\n\\n1. Multi-modal input integration: An LLM can integrate with computer vision or natural language processing systems to process multi-modal inputs, such as images and text, simultaneously. For example, an autonomous vehicle equipped with a computer vision system can use the LLM to analyze visual data and make decisions based on both visual and linguistic information.\\n2. Task decomposition: An LLM can break down complex tasks into smaller subgoals using task decomposition techniques, such as chain of thought (CoT) or tree of thoughts (Yao et al., 2023). These techniques allow the LLM to integrate with other technologies, such as natural language processing, to perform more comprehensive and intelligent behavior.\\n3. Hybrid reasoning: An LLM can use hybrid reasoning techniques that combine symbolic and connectionist approaches to integrate with other technologies, such as computer vision or robotics. For example, an autonomous robot can use an LLM to reason about the spatial relationships between objects in its environment and make decisions based on both symbolic and connectionist representations (Wei et al., 2022).\\n4. Transfer learning: An LLM can use transfer learning techniques to leverage knowledge gained from one task or domain to perform another related task or domain. For example, an LLM trained on natural language processing tasks can be fine-tuned for computer vision tasks by adapting the learned representations and weights (Ruder et al., 2019).\\n5. Joint training: An LLM can be jointly trained with other technologies, such as computer vision or natural language processing, to learn shared representations and improve generalization to new tasks or domains. For example, an LLM trained on a combination of natural language processing and computer vision tasks can leverage the shared knowledge and representations to perform more comprehensive and intelligent behavior (Li et al., 2019).\\n\\nIn summary, an LLM-powered autonomous agent system typically integrates with other technologies, such as computer vision or natural language processing, through various methods to enable more comprehensive and intelligent behavior. These methods include multi-modal input integration, task decomposition, hybrid reasoning, transfer learning, and joint training.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"3. What are some common applications of LLM-powered autonomous agent systems, such as robotics, self-driving cars, or virtual assistants, and how do they leverage the capabilities of the LLM?\",\n",
      "  \"q_a_pairs\": \"\\n---\\nQuestion: 1. What types of machine learning algorithms does an LLM-powered autonomous agent system typically use for decision-making and control?\\nAnswer: Based on the provided context, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms for decision-making and control, including:\\n\\n1. Large Language Models (LLMs): The core component of an LLM-powered autonomous agent system, LLMs are trained on vast amounts of text data to generate responses to prompts. They can be used for decision-making by breaking down complex tasks into smaller subgoals and evaluating possible actions based on their predicted outcomes.\\n2. Planning Algorithms: To plan ahead and handle complex tasks, an LLM-powered autonomous agent system may use planning algorithms such as Graphplan (Yao et al., 2023) or Breadth-First Search (BFS) (Li, 2018). These algorithms allow the agent to decompose tasks into smaller subgoals and generate a sequence of actions to achieve a desired outcome.\\n3. Reinforcement Learning Algorithms: To learn from experience and improve its decision-making abilities, an LLM-powered autonomous agent system may use reinforcement learning algorithms such as Q-learning (Watkins & Dayan, 1992) or Deep Deterministic Policy Gradients (DDPG) (Lillicrap et al., 2016). These algorithms allow the agent to learn from its interactions with the environment and adapt its behavior over time.\\n4. Deliberation Algorithms: To reflect on past actions and improve future decision-making, an LLM-powered autonomous agent system may use deliberation algorithms such as Incremental Logic (Liu et al., 2023) or Hindsight Alignment (Liu et al., 2023). These algorithms allow the agent to evaluate its past actions and adjust its behavior accordingly.\\n5. Optimal Planning Algorithms: To plan and execute complex tasks efficiently, an LLM-powered autonomous agent system may use optimal planning algorithms such as Linear Programming (LP) (Bellman, 1957) or Mixed-Integer Quadratic Programming (MIQP) (Lukasik & Martello, 1983). These algorithms allow the agent to optimize its plan based on constraints and objectives.\\n\\nIn summary, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms, including LLMs, planning algorithms, reinforcement learning algorithms, deliberation algorithms, and optimal planning algorithms, to make decisions and control its behavior.\\n---\\nQuestion: 2. How does the LLM integrate with other technologies, such as computer vision or natural language processing, to enable more comprehensive and intelligent behavior?\\nAnswer: Based on the provided context, an LLM-powered autonomous agent system typically integrates with other technologies, such as computer vision or natural language processing, through various methods to enable more comprehensive and intelligent behavior. Here are some possible ways:\\n\\n1. Multi-modal input integration: An LLM can integrate with computer vision or natural language processing systems to process multi-modal inputs, such as images and text, simultaneously. For example, an autonomous vehicle equipped with a computer vision system can use the LLM to analyze visual data and make decisions based on both visual and linguistic information.\\n2. Task decomposition: An LLM can break down complex tasks into smaller subgoals using task decomposition techniques, such as chain of thought (CoT) or tree of thoughts (Yao et al., 2023). These techniques allow the LLM to integrate with other technologies, such as natural language processing, to perform more comprehensive and intelligent behavior.\\n3. Hybrid reasoning: An LLM can use hybrid reasoning techniques that combine symbolic and connectionist approaches to integrate with other technologies, such as computer vision or robotics. For example, an autonomous robot can use an LLM to reason about the spatial relationships between objects in its environment and make decisions based on both symbolic and connectionist representations (Wei et al., 2022).\\n4. Transfer learning: An LLM can use transfer learning techniques to leverage knowledge gained from one task or domain to perform another related task or domain. For example, an LLM trained on natural language processing tasks can be fine-tuned for computer vision tasks by adapting the learned representations and weights (Ruder et al., 2019).\\n5. Joint training: An LLM can be jointly trained with other technologies, such as computer vision or natural language processing, to learn shared representations and improve generalization to new tasks or domains. For example, an LLM trained on a combination of natural language processing and computer vision tasks can leverage the shared knowledge and representations to perform more comprehensive and intelligent behavior (Li et al., 2019).\\n\\nIn summary, an LLM-powered autonomous agent system typically integrates with other technologies, such as computer vision or natural language processing, through various methods to enable more comprehensive and intelligent behavior. These methods include multi-modal input integration, task decomposition, hybrid reasoning, transfer learning, and joint training.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question,q_a_pairs>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"3. What are some common applications of LLM-powered autonomous agent systems, such as robotics, self-driving cars, or virtual assistants, and how do they leverage the capabilities of the LLM?\",\n",
      "  \"q_a_pairs\": \"\\n---\\nQuestion: 1. What types of machine learning algorithms does an LLM-powered autonomous agent system typically use for decision-making and control?\\nAnswer: Based on the provided context, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms for decision-making and control, including:\\n\\n1. Large Language Models (LLMs): The core component of an LLM-powered autonomous agent system, LLMs are trained on vast amounts of text data to generate responses to prompts. They can be used for decision-making by breaking down complex tasks into smaller subgoals and evaluating possible actions based on their predicted outcomes.\\n2. Planning Algorithms: To plan ahead and handle complex tasks, an LLM-powered autonomous agent system may use planning algorithms such as Graphplan (Yao et al., 2023) or Breadth-First Search (BFS) (Li, 2018). These algorithms allow the agent to decompose tasks into smaller subgoals and generate a sequence of actions to achieve a desired outcome.\\n3. Reinforcement Learning Algorithms: To learn from experience and improve its decision-making abilities, an LLM-powered autonomous agent system may use reinforcement learning algorithms such as Q-learning (Watkins & Dayan, 1992) or Deep Deterministic Policy Gradients (DDPG) (Lillicrap et al., 2016). These algorithms allow the agent to learn from its interactions with the environment and adapt its behavior over time.\\n4. Deliberation Algorithms: To reflect on past actions and improve future decision-making, an LLM-powered autonomous agent system may use deliberation algorithms such as Incremental Logic (Liu et al., 2023) or Hindsight Alignment (Liu et al., 2023). These algorithms allow the agent to evaluate its past actions and adjust its behavior accordingly.\\n5. Optimal Planning Algorithms: To plan and execute complex tasks efficiently, an LLM-powered autonomous agent system may use optimal planning algorithms such as Linear Programming (LP) (Bellman, 1957) or Mixed-Integer Quadratic Programming (MIQP) (Lukasik & Martello, 1983). These algorithms allow the agent to optimize its plan based on constraints and objectives.\\n\\nIn summary, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms, including LLMs, planning algorithms, reinforcement learning algorithms, deliberation algorithms, and optimal planning algorithms, to make decisions and control its behavior.\\n---\\nQuestion: 2. How does the LLM integrate with other technologies, such as computer vision or natural language processing, to enable more comprehensive and intelligent behavior?\\nAnswer: Based on the provided context, an LLM-powered autonomous agent system typically integrates with other technologies, such as computer vision or natural language processing, through various methods to enable more comprehensive and intelligent behavior. Here are some possible ways:\\n\\n1. Multi-modal input integration: An LLM can integrate with computer vision or natural language processing systems to process multi-modal inputs, such as images and text, simultaneously. For example, an autonomous vehicle equipped with a computer vision system can use the LLM to analyze visual data and make decisions based on both visual and linguistic information.\\n2. Task decomposition: An LLM can break down complex tasks into smaller subgoals using task decomposition techniques, such as chain of thought (CoT) or tree of thoughts (Yao et al., 2023). These techniques allow the LLM to integrate with other technologies, such as natural language processing, to perform more comprehensive and intelligent behavior.\\n3. Hybrid reasoning: An LLM can use hybrid reasoning techniques that combine symbolic and connectionist approaches to integrate with other technologies, such as computer vision or robotics. For example, an autonomous robot can use an LLM to reason about the spatial relationships between objects in its environment and make decisions based on both symbolic and connectionist representations (Wei et al., 2022).\\n4. Transfer learning: An LLM can use transfer learning techniques to leverage knowledge gained from one task or domain to perform another related task or domain. For example, an LLM trained on natural language processing tasks can be fine-tuned for computer vision tasks by adapting the learned representations and weights (Ruder et al., 2019).\\n5. Joint training: An LLM can be jointly trained with other technologies, such as computer vision or natural language processing, to learn shared representations and improve generalization to new tasks or domains. For example, an LLM trained on a combination of natural language processing and computer vision tasks can leverage the shared knowledge and representations to perform more comprehensive and intelligent behavior (Li et al., 2019).\\n\\nIn summary, an LLM-powered autonomous agent system typically integrates with other technologies, such as computer vision or natural language processing, through various methods to enable more comprehensive and intelligent behavior. These methods include multi-modal input integration, task decomposition, hybrid reasoning, transfer learning, and joint training.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question,q_a_pairs> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"3. What are some common applications of LLM-powered autonomous agent systems, such as robotics, self-driving cars, or virtual assistants, and how do they leverage the capabilities of the LLM?\",\n",
      "  \"q_a_pairs\": \"\\n---\\nQuestion: 1. What types of machine learning algorithms does an LLM-powered autonomous agent system typically use for decision-making and control?\\nAnswer: Based on the provided context, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms for decision-making and control, including:\\n\\n1. Large Language Models (LLMs): The core component of an LLM-powered autonomous agent system, LLMs are trained on vast amounts of text data to generate responses to prompts. They can be used for decision-making by breaking down complex tasks into smaller subgoals and evaluating possible actions based on their predicted outcomes.\\n2. Planning Algorithms: To plan ahead and handle complex tasks, an LLM-powered autonomous agent system may use planning algorithms such as Graphplan (Yao et al., 2023) or Breadth-First Search (BFS) (Li, 2018). These algorithms allow the agent to decompose tasks into smaller subgoals and generate a sequence of actions to achieve a desired outcome.\\n3. Reinforcement Learning Algorithms: To learn from experience and improve its decision-making abilities, an LLM-powered autonomous agent system may use reinforcement learning algorithms such as Q-learning (Watkins & Dayan, 1992) or Deep Deterministic Policy Gradients (DDPG) (Lillicrap et al., 2016). These algorithms allow the agent to learn from its interactions with the environment and adapt its behavior over time.\\n4. Deliberation Algorithms: To reflect on past actions and improve future decision-making, an LLM-powered autonomous agent system may use deliberation algorithms such as Incremental Logic (Liu et al., 2023) or Hindsight Alignment (Liu et al., 2023). These algorithms allow the agent to evaluate its past actions and adjust its behavior accordingly.\\n5. Optimal Planning Algorithms: To plan and execute complex tasks efficiently, an LLM-powered autonomous agent system may use optimal planning algorithms such as Linear Programming (LP) (Bellman, 1957) or Mixed-Integer Quadratic Programming (MIQP) (Lukasik & Martello, 1983). These algorithms allow the agent to optimize its plan based on constraints and objectives.\\n\\nIn summary, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms, including LLMs, planning algorithms, reinforcement learning algorithms, deliberation algorithms, and optimal planning algorithms, to make decisions and control its behavior.\\n---\\nQuestion: 2. How does the LLM integrate with other technologies, such as computer vision or natural language processing, to enable more comprehensive and intelligent behavior?\\nAnswer: Based on the provided context, an LLM-powered autonomous agent system typically integrates with other technologies, such as computer vision or natural language processing, through various methods to enable more comprehensive and intelligent behavior. Here are some possible ways:\\n\\n1. Multi-modal input integration: An LLM can integrate with computer vision or natural language processing systems to process multi-modal inputs, such as images and text, simultaneously. For example, an autonomous vehicle equipped with a computer vision system can use the LLM to analyze visual data and make decisions based on both visual and linguistic information.\\n2. Task decomposition: An LLM can break down complex tasks into smaller subgoals using task decomposition techniques, such as chain of thought (CoT) or tree of thoughts (Yao et al., 2023). These techniques allow the LLM to integrate with other technologies, such as natural language processing, to perform more comprehensive and intelligent behavior.\\n3. Hybrid reasoning: An LLM can use hybrid reasoning techniques that combine symbolic and connectionist approaches to integrate with other technologies, such as computer vision or robotics. For example, an autonomous robot can use an LLM to reason about the spatial relationships between objects in its environment and make decisions based on both symbolic and connectionist representations (Wei et al., 2022).\\n4. Transfer learning: An LLM can use transfer learning techniques to leverage knowledge gained from one task or domain to perform another related task or domain. For example, an LLM trained on natural language processing tasks can be fine-tuned for computer vision tasks by adapting the learned representations and weights (Ruder et al., 2019).\\n5. Joint training: An LLM can be jointly trained with other technologies, such as computer vision or natural language processing, to learn shared representations and improve generalization to new tasks or domains. For example, an LLM trained on a combination of natural language processing and computer vision tasks can leverage the shared knowledge and representations to perform more comprehensive and intelligent behavior (Li et al., 2019).\\n\\nIn summary, an LLM-powered autonomous agent system typically integrates with other technologies, such as computer vision or natural language processing, through various methods to enable more comprehensive and intelligent behavior. These methods include multi-modal input integration, task decomposition, hybrid reasoning, transfer learning, and joint training.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question,q_a_pairs> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"3. What are some common applications of LLM-powered autonomous agent systems, such as robotics, self-driving cars, or virtual assistants, and how do they leverage the capabilities of the LLM?\",\n",
      "  \"q_a_pairs\": \"\\n---\\nQuestion: 1. What types of machine learning algorithms does an LLM-powered autonomous agent system typically use for decision-making and control?\\nAnswer: Based on the provided context, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms for decision-making and control, including:\\n\\n1. Large Language Models (LLMs): The core component of an LLM-powered autonomous agent system, LLMs are trained on vast amounts of text data to generate responses to prompts. They can be used for decision-making by breaking down complex tasks into smaller subgoals and evaluating possible actions based on their predicted outcomes.\\n2. Planning Algorithms: To plan ahead and handle complex tasks, an LLM-powered autonomous agent system may use planning algorithms such as Graphplan (Yao et al., 2023) or Breadth-First Search (BFS) (Li, 2018). These algorithms allow the agent to decompose tasks into smaller subgoals and generate a sequence of actions to achieve a desired outcome.\\n3. Reinforcement Learning Algorithms: To learn from experience and improve its decision-making abilities, an LLM-powered autonomous agent system may use reinforcement learning algorithms such as Q-learning (Watkins & Dayan, 1992) or Deep Deterministic Policy Gradients (DDPG) (Lillicrap et al., 2016). These algorithms allow the agent to learn from its interactions with the environment and adapt its behavior over time.\\n4. Deliberation Algorithms: To reflect on past actions and improve future decision-making, an LLM-powered autonomous agent system may use deliberation algorithms such as Incremental Logic (Liu et al., 2023) or Hindsight Alignment (Liu et al., 2023). These algorithms allow the agent to evaluate its past actions and adjust its behavior accordingly.\\n5. Optimal Planning Algorithms: To plan and execute complex tasks efficiently, an LLM-powered autonomous agent system may use optimal planning algorithms such as Linear Programming (LP) (Bellman, 1957) or Mixed-Integer Quadratic Programming (MIQP) (Lukasik & Martello, 1983). These algorithms allow the agent to optimize its plan based on constraints and objectives.\\n\\nIn summary, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms, including LLMs, planning algorithms, reinforcement learning algorithms, deliberation algorithms, and optimal planning algorithms, to make decisions and control its behavior.\\n---\\nQuestion: 2. How does the LLM integrate with other technologies, such as computer vision or natural language processing, to enable more comprehensive and intelligent behavior?\\nAnswer: Based on the provided context, an LLM-powered autonomous agent system typically integrates with other technologies, such as computer vision or natural language processing, through various methods to enable more comprehensive and intelligent behavior. Here are some possible ways:\\n\\n1. Multi-modal input integration: An LLM can integrate with computer vision or natural language processing systems to process multi-modal inputs, such as images and text, simultaneously. For example, an autonomous vehicle equipped with a computer vision system can use the LLM to analyze visual data and make decisions based on both visual and linguistic information.\\n2. Task decomposition: An LLM can break down complex tasks into smaller subgoals using task decomposition techniques, such as chain of thought (CoT) or tree of thoughts (Yao et al., 2023). These techniques allow the LLM to integrate with other technologies, such as natural language processing, to perform more comprehensive and intelligent behavior.\\n3. Hybrid reasoning: An LLM can use hybrid reasoning techniques that combine symbolic and connectionist approaches to integrate with other technologies, such as computer vision or robotics. For example, an autonomous robot can use an LLM to reason about the spatial relationships between objects in its environment and make decisions based on both symbolic and connectionist representations (Wei et al., 2022).\\n4. Transfer learning: An LLM can use transfer learning techniques to leverage knowledge gained from one task or domain to perform another related task or domain. For example, an LLM trained on natural language processing tasks can be fine-tuned for computer vision tasks by adapting the learned representations and weights (Ruder et al., 2019).\\n5. Joint training: An LLM can be jointly trained with other technologies, such as computer vision or natural language processing, to learn shared representations and improve generalization to new tasks or domains. For example, an LLM trained on a combination of natural language processing and computer vision tasks can leverage the shared knowledge and representations to perform more comprehensive and intelligent behavior (Li et al., 2019).\\n\\nIn summary, an LLM-powered autonomous agent system typically integrates with other technologies, such as computer vision or natural language processing, through various methods to enable more comprehensive and intelligent behavior. These methods include multi-modal input integration, task decomposition, hybrid reasoning, transfer learning, and joint training.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question,q_a_pairs> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"3. What are some common applications of LLM-powered autonomous agent systems, such as robotics, self-driving cars, or virtual assistants, and how do they leverage the capabilities of the LLM?\",\n",
      "  \"q_a_pairs\": \"\\n---\\nQuestion: 1. What types of machine learning algorithms does an LLM-powered autonomous agent system typically use for decision-making and control?\\nAnswer: Based on the provided context, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms for decision-making and control, including:\\n\\n1. Large Language Models (LLMs): The core component of an LLM-powered autonomous agent system, LLMs are trained on vast amounts of text data to generate responses to prompts. They can be used for decision-making by breaking down complex tasks into smaller subgoals and evaluating possible actions based on their predicted outcomes.\\n2. Planning Algorithms: To plan ahead and handle complex tasks, an LLM-powered autonomous agent system may use planning algorithms such as Graphplan (Yao et al., 2023) or Breadth-First Search (BFS) (Li, 2018). These algorithms allow the agent to decompose tasks into smaller subgoals and generate a sequence of actions to achieve a desired outcome.\\n3. Reinforcement Learning Algorithms: To learn from experience and improve its decision-making abilities, an LLM-powered autonomous agent system may use reinforcement learning algorithms such as Q-learning (Watkins & Dayan, 1992) or Deep Deterministic Policy Gradients (DDPG) (Lillicrap et al., 2016). These algorithms allow the agent to learn from its interactions with the environment and adapt its behavior over time.\\n4. Deliberation Algorithms: To reflect on past actions and improve future decision-making, an LLM-powered autonomous agent system may use deliberation algorithms such as Incremental Logic (Liu et al., 2023) or Hindsight Alignment (Liu et al., 2023). These algorithms allow the agent to evaluate its past actions and adjust its behavior accordingly.\\n5. Optimal Planning Algorithms: To plan and execute complex tasks efficiently, an LLM-powered autonomous agent system may use optimal planning algorithms such as Linear Programming (LP) (Bellman, 1957) or Mixed-Integer Quadratic Programming (MIQP) (Lukasik & Martello, 1983). These algorithms allow the agent to optimize its plan based on constraints and objectives.\\n\\nIn summary, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms, including LLMs, planning algorithms, reinforcement learning algorithms, deliberation algorithms, and optimal planning algorithms, to make decisions and control its behavior.\\n---\\nQuestion: 2. How does the LLM integrate with other technologies, such as computer vision or natural language processing, to enable more comprehensive and intelligent behavior?\\nAnswer: Based on the provided context, an LLM-powered autonomous agent system typically integrates with other technologies, such as computer vision or natural language processing, through various methods to enable more comprehensive and intelligent behavior. Here are some possible ways:\\n\\n1. Multi-modal input integration: An LLM can integrate with computer vision or natural language processing systems to process multi-modal inputs, such as images and text, simultaneously. For example, an autonomous vehicle equipped with a computer vision system can use the LLM to analyze visual data and make decisions based on both visual and linguistic information.\\n2. Task decomposition: An LLM can break down complex tasks into smaller subgoals using task decomposition techniques, such as chain of thought (CoT) or tree of thoughts (Yao et al., 2023). These techniques allow the LLM to integrate with other technologies, such as natural language processing, to perform more comprehensive and intelligent behavior.\\n3. Hybrid reasoning: An LLM can use hybrid reasoning techniques that combine symbolic and connectionist approaches to integrate with other technologies, such as computer vision or robotics. For example, an autonomous robot can use an LLM to reason about the spatial relationships between objects in its environment and make decisions based on both symbolic and connectionist representations (Wei et al., 2022).\\n4. Transfer learning: An LLM can use transfer learning techniques to leverage knowledge gained from one task or domain to perform another related task or domain. For example, an LLM trained on natural language processing tasks can be fine-tuned for computer vision tasks by adapting the learned representations and weights (Ruder et al., 2019).\\n5. Joint training: An LLM can be jointly trained with other technologies, such as computer vision or natural language processing, to learn shared representations and improve generalization to new tasks or domains. For example, an LLM trained on a combination of natural language processing and computer vision tasks can leverage the shared knowledge and representations to perform more comprehensive and intelligent behavior (Li et al., 2019).\\n\\nIn summary, an LLM-powered autonomous agent system typically integrates with other technologies, such as computer vision or natural language processing, through various methods to enable more comprehensive and intelligent behavior. These methods include multi-modal input integration, task decomposition, hybrid reasoning, transfer learning, and joint training.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question,q_a_pairs> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"3. What are some common applications of LLM-powered autonomous agent systems, such as robotics, self-driving cars, or virtual assistants, and how do they leverage the capabilities of the LLM?\",\n",
      "  \"q_a_pairs\": \"\\n---\\nQuestion: 1. What types of machine learning algorithms does an LLM-powered autonomous agent system typically use for decision-making and control?\\nAnswer: Based on the provided context, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms for decision-making and control, including:\\n\\n1. Large Language Models (LLMs): The core component of an LLM-powered autonomous agent system, LLMs are trained on vast amounts of text data to generate responses to prompts. They can be used for decision-making by breaking down complex tasks into smaller subgoals and evaluating possible actions based on their predicted outcomes.\\n2. Planning Algorithms: To plan ahead and handle complex tasks, an LLM-powered autonomous agent system may use planning algorithms such as Graphplan (Yao et al., 2023) or Breadth-First Search (BFS) (Li, 2018). These algorithms allow the agent to decompose tasks into smaller subgoals and generate a sequence of actions to achieve a desired outcome.\\n3. Reinforcement Learning Algorithms: To learn from experience and improve its decision-making abilities, an LLM-powered autonomous agent system may use reinforcement learning algorithms such as Q-learning (Watkins & Dayan, 1992) or Deep Deterministic Policy Gradients (DDPG) (Lillicrap et al., 2016). These algorithms allow the agent to learn from its interactions with the environment and adapt its behavior over time.\\n4. Deliberation Algorithms: To reflect on past actions and improve future decision-making, an LLM-powered autonomous agent system may use deliberation algorithms such as Incremental Logic (Liu et al., 2023) or Hindsight Alignment (Liu et al., 2023). These algorithms allow the agent to evaluate its past actions and adjust its behavior accordingly.\\n5. Optimal Planning Algorithms: To plan and execute complex tasks efficiently, an LLM-powered autonomous agent system may use optimal planning algorithms such as Linear Programming (LP) (Bellman, 1957) or Mixed-Integer Quadratic Programming (MIQP) (Lukasik & Martello, 1983). These algorithms allow the agent to optimize its plan based on constraints and objectives.\\n\\nIn summary, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms, including LLMs, planning algorithms, reinforcement learning algorithms, deliberation algorithms, and optimal planning algorithms, to make decisions and control its behavior.\\n---\\nQuestion: 2. How does the LLM integrate with other technologies, such as computer vision or natural language processing, to enable more comprehensive and intelligent behavior?\\nAnswer: Based on the provided context, an LLM-powered autonomous agent system typically integrates with other technologies, such as computer vision or natural language processing, through various methods to enable more comprehensive and intelligent behavior. Here are some possible ways:\\n\\n1. Multi-modal input integration: An LLM can integrate with computer vision or natural language processing systems to process multi-modal inputs, such as images and text, simultaneously. For example, an autonomous vehicle equipped with a computer vision system can use the LLM to analyze visual data and make decisions based on both visual and linguistic information.\\n2. Task decomposition: An LLM can break down complex tasks into smaller subgoals using task decomposition techniques, such as chain of thought (CoT) or tree of thoughts (Yao et al., 2023). These techniques allow the LLM to integrate with other technologies, such as natural language processing, to perform more comprehensive and intelligent behavior.\\n3. Hybrid reasoning: An LLM can use hybrid reasoning techniques that combine symbolic and connectionist approaches to integrate with other technologies, such as computer vision or robotics. For example, an autonomous robot can use an LLM to reason about the spatial relationships between objects in its environment and make decisions based on both symbolic and connectionist representations (Wei et al., 2022).\\n4. Transfer learning: An LLM can use transfer learning techniques to leverage knowledge gained from one task or domain to perform another related task or domain. For example, an LLM trained on natural language processing tasks can be fine-tuned for computer vision tasks by adapting the learned representations and weights (Ruder et al., 2019).\\n5. Joint training: An LLM can be jointly trained with other technologies, such as computer vision or natural language processing, to learn shared representations and improve generalization to new tasks or domains. For example, an LLM trained on a combination of natural language processing and computer vision tasks can leverage the shared knowledge and representations to perform more comprehensive and intelligent behavior (Li et al., 2019).\\n\\nIn summary, an LLM-powered autonomous agent system typically integrates with other technologies, such as computer vision or natural language processing, through various methods to enable more comprehensive and intelligent behavior. These methods include multi-modal input integration, task decomposition, hybrid reasoning, transfer learning, and joint training.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question,q_a_pairs> > chain:RunnableLambda] [4ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"3. What are some common applications of LLM-powered autonomous agent systems, such as robotics, self-driving cars, or virtual assistants, and how do they leverage the capabilities of the LLM?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question,q_a_pairs> > chain:RunnableLambda] [4ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"\\n---\\nQuestion: 1. What types of machine learning algorithms does an LLM-powered autonomous agent system typically use for decision-making and control?\\nAnswer: Based on the provided context, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms for decision-making and control, including:\\n\\n1. Large Language Models (LLMs): The core component of an LLM-powered autonomous agent system, LLMs are trained on vast amounts of text data to generate responses to prompts. They can be used for decision-making by breaking down complex tasks into smaller subgoals and evaluating possible actions based on their predicted outcomes.\\n2. Planning Algorithms: To plan ahead and handle complex tasks, an LLM-powered autonomous agent system may use planning algorithms such as Graphplan (Yao et al., 2023) or Breadth-First Search (BFS) (Li, 2018). These algorithms allow the agent to decompose tasks into smaller subgoals and generate a sequence of actions to achieve a desired outcome.\\n3. Reinforcement Learning Algorithms: To learn from experience and improve its decision-making abilities, an LLM-powered autonomous agent system may use reinforcement learning algorithms such as Q-learning (Watkins & Dayan, 1992) or Deep Deterministic Policy Gradients (DDPG) (Lillicrap et al., 2016). These algorithms allow the agent to learn from its interactions with the environment and adapt its behavior over time.\\n4. Deliberation Algorithms: To reflect on past actions and improve future decision-making, an LLM-powered autonomous agent system may use deliberation algorithms such as Incremental Logic (Liu et al., 2023) or Hindsight Alignment (Liu et al., 2023). These algorithms allow the agent to evaluate its past actions and adjust its behavior accordingly.\\n5. Optimal Planning Algorithms: To plan and execute complex tasks efficiently, an LLM-powered autonomous agent system may use optimal planning algorithms such as Linear Programming (LP) (Bellman, 1957) or Mixed-Integer Quadratic Programming (MIQP) (Lukasik & Martello, 1983). These algorithms allow the agent to optimize its plan based on constraints and objectives.\\n\\nIn summary, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms, including LLMs, planning algorithms, reinforcement learning algorithms, deliberation algorithms, and optimal planning algorithms, to make decisions and control its behavior.\\n---\\nQuestion: 2. How does the LLM integrate with other technologies, such as computer vision or natural language processing, to enable more comprehensive and intelligent behavior?\\nAnswer: Based on the provided context, an LLM-powered autonomous agent system typically integrates with other technologies, such as computer vision or natural language processing, through various methods to enable more comprehensive and intelligent behavior. Here are some possible ways:\\n\\n1. Multi-modal input integration: An LLM can integrate with computer vision or natural language processing systems to process multi-modal inputs, such as images and text, simultaneously. For example, an autonomous vehicle equipped with a computer vision system can use the LLM to analyze visual data and make decisions based on both visual and linguistic information.\\n2. Task decomposition: An LLM can break down complex tasks into smaller subgoals using task decomposition techniques, such as chain of thought (CoT) or tree of thoughts (Yao et al., 2023). These techniques allow the LLM to integrate with other technologies, such as natural language processing, to perform more comprehensive and intelligent behavior.\\n3. Hybrid reasoning: An LLM can use hybrid reasoning techniques that combine symbolic and connectionist approaches to integrate with other technologies, such as computer vision or robotics. For example, an autonomous robot can use an LLM to reason about the spatial relationships between objects in its environment and make decisions based on both symbolic and connectionist representations (Wei et al., 2022).\\n4. Transfer learning: An LLM can use transfer learning techniques to leverage knowledge gained from one task or domain to perform another related task or domain. For example, an LLM trained on natural language processing tasks can be fine-tuned for computer vision tasks by adapting the learned representations and weights (Ruder et al., 2019).\\n5. Joint training: An LLM can be jointly trained with other technologies, such as computer vision or natural language processing, to learn shared representations and improve generalization to new tasks or domains. For example, an LLM trained on a combination of natural language processing and computer vision tasks can leverage the shared knowledge and representations to perform more comprehensive and intelligent behavior (Li et al., 2019).\\n\\nIn summary, an LLM-powered autonomous agent system typically integrates with other technologies, such as computer vision or natural language processing, through various methods to enable more comprehensive and intelligent behavior. These methods include multi-modal input integration, task decomposition, hybrid reasoning, transfer learning, and joint training.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question,q_a_pairs> > chain:RunnableSequence > chain:RunnableLambda] [3ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"3. What are some common applications of LLM-powered autonomous agent systems, such as robotics, self-driving cars, or virtual assistants, and how do they leverage the capabilities of the LLM?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question,q_a_pairs> > chain:RunnableSequence] [85ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question,q_a_pairs>] [86ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Here is the question you need to answer:\\n\\n\\n --- \\n 3. What are some common applications of LLM-powered autonomous agent systems, such as robotics, self-driving cars, or virtual assistants, and how do they leverage the capabilities of the LLM? \\n --- \\n\\n\\nHere is any available background question + answer pairs:\\n\\n\\n --- \\n \\n---\\nQuestion: 1. What types of machine learning algorithms does an LLM-powered autonomous agent system typically use for decision-making and control?\\nAnswer: Based on the provided context, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms for decision-making and control, including:\\n\\n1. Large Language Models (LLMs): The core component of an LLM-powered autonomous agent system, LLMs are trained on vast amounts of text data to generate responses to prompts. They can be used for decision-making by breaking down complex tasks into smaller subgoals and evaluating possible actions based on their predicted outcomes.\\n2. Planning Algorithms: To plan ahead and handle complex tasks, an LLM-powered autonomous agent system may use planning algorithms such as Graphplan (Yao et al., 2023) or Breadth-First Search (BFS) (Li, 2018). These algorithms allow the agent to decompose tasks into smaller subgoals and generate a sequence of actions to achieve a desired outcome.\\n3. Reinforcement Learning Algorithms: To learn from experience and improve its decision-making abilities, an LLM-powered autonomous agent system may use reinforcement learning algorithms such as Q-learning (Watkins & Dayan, 1992) or Deep Deterministic Policy Gradients (DDPG) (Lillicrap et al., 2016). These algorithms allow the agent to learn from its interactions with the environment and adapt its behavior over time.\\n4. Deliberation Algorithms: To reflect on past actions and improve future decision-making, an LLM-powered autonomous agent system may use deliberation algorithms such as Incremental Logic (Liu et al., 2023) or Hindsight Alignment (Liu et al., 2023). These algorithms allow the agent to evaluate its past actions and adjust its behavior accordingly.\\n5. Optimal Planning Algorithms: To plan and execute complex tasks efficiently, an LLM-powered autonomous agent system may use optimal planning algorithms such as Linear Programming (LP) (Bellman, 1957) or Mixed-Integer Quadratic Programming (MIQP) (Lukasik & Martello, 1983). These algorithms allow the agent to optimize its plan based on constraints and objectives.\\n\\nIn summary, an LLM-powered autonomous agent system typically uses a combination of machine learning algorithms, including LLMs, planning algorithms, reinforcement learning algorithms, deliberation algorithms, and optimal planning algorithms, to make decisions and control its behavior.\\n---\\nQuestion: 2. How does the LLM integrate with other technologies, such as computer vision or natural language processing, to enable more comprehensive and intelligent behavior?\\nAnswer: Based on the provided context, an LLM-powered autonomous agent system typically integrates with other technologies, such as computer vision or natural language processing, through various methods to enable more comprehensive and intelligent behavior. Here are some possible ways:\\n\\n1. Multi-modal input integration: An LLM can integrate with computer vision or natural language processing systems to process multi-modal inputs, such as images and text, simultaneously. For example, an autonomous vehicle equipped with a computer vision system can use the LLM to analyze visual data and make decisions based on both visual and linguistic information.\\n2. Task decomposition: An LLM can break down complex tasks into smaller subgoals using task decomposition techniques, such as chain of thought (CoT) or tree of thoughts (Yao et al., 2023). These techniques allow the LLM to integrate with other technologies, such as natural language processing, to perform more comprehensive and intelligent behavior.\\n3. Hybrid reasoning: An LLM can use hybrid reasoning techniques that combine symbolic and connectionist approaches to integrate with other technologies, such as computer vision or robotics. For example, an autonomous robot can use an LLM to reason about the spatial relationships between objects in its environment and make decisions based on both symbolic and connectionist representations (Wei et al., 2022).\\n4. Transfer learning: An LLM can use transfer learning techniques to leverage knowledge gained from one task or domain to perform another related task or domain. For example, an LLM trained on natural language processing tasks can be fine-tuned for computer vision tasks by adapting the learned representations and weights (Ruder et al., 2019).\\n5. Joint training: An LLM can be jointly trained with other technologies, such as computer vision or natural language processing, to learn shared representations and improve generalization to new tasks or domains. For example, an LLM trained on a combination of natural language processing and computer vision tasks can leverage the shared knowledge and representations to perform more comprehensive and intelligent behavior (Li et al., 2019).\\n\\nIn summary, an LLM-powered autonomous agent system typically integrates with other technologies, such as computer vision or natural language processing, through various methods to enable more comprehensive and intelligent behavior. These methods include multi-modal input integration, task decomposition, hybrid reasoning, transfer learning, and joint training. \\n --- \\n\\n\\nHere is additional context relevant to the question: \\n\\n\\n --- \\n [Document(page_content='LLM Powered Autonomous Agents\\\\n    \\\\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\\\n\\\\n\\\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview#\\\\nIn a LLM-powered autonomous agent system, LLM functions as the agents brain, complemented by several key components:\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}), Document(page_content='Or\\\\n@article{weng2023agent,\\\\n  title   = \\\"LLM-powered Autonomous Agents\\\",\\\\n  author  = \\\"Weng, Lilian\\\",\\\\n  journal = \\\"lilianweng.github.io\\\",\\\\n  year    = \\\"2023\\\",\\\\n  month   = \\\"Jun\\\",\\\\n  url     = \\\"https://lilianweng.github.io/posts/2023-06-23-agent/\\\"\\\\n}\\\\nReferences#\\\\n[1] Wei et al. Chain of thought prompting elicits reasoning in large language models. NeurIPS 2022\\\\n[2] Yao et al. Tree of Thoughts: Dliberate Problem Solving with Large Language Models. arXiv preprint arXiv:2305.10601 (2023).\\\\n[3] Liu et al. Chain of Hindsight Aligns Language Models with Feedback\\\\n arXiv preprint arXiv:2302.02676 (2023).\\\\n[4] Liu et al. LLM+P: Empowering Large Language Models with Optimal Planning Proficiency arXiv preprint arXiv:2304.11477 (2023).', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}), Document(page_content='One interesting observation is that while the LLM-based evaluation concluded that GPT-4 and ChemCrow perform nearly equivalently, human evaluations with experts oriented towards the completion and chemical correctness of the solutions showed that ChemCrow outperforms GPT-4 by a large margin. This indicates a potential problem with using LLM to evaluate its own performance on domains that requires deep expertise. The lack of expertise may cause LLMs not knowing its flaws and thus cannot well judge the correctness of task results.\\\\nBoiko et al. (2023) also looked into LLM-empowered agents for scientific discovery, to handle autonomous design, planning, and performance of complex scientific experiments. This agent can use tools to browse the Internet, read documentation, execute code, call robotics experimentation APIs and leverage other LLMs.\\\\nFor example, when requested to \\\"develop a novel anticancer drug\\\", the model came up with the following reasoning steps:\\\\n\\\\ninquired about current trends in anticancer drug discovery;\\\\nselected a target;\\\\nrequested a scaffold targeting these compounds;\\\\nOnce the compound was identified, the model attempted its synthesis.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}), Document(page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\\\nComponent One: Planning#\\\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\\\nTask Decomposition#\\\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to think step by step to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the models thinking process.\\\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\\\nTask decomposition can be done (1) by LLM with simple prompting like \\\"Steps for XYZ.\\\\\\\\n1.\\\", \\\"What are the subgoals for achieving XYZ?\\\", (2) by using task-specific instructions; e.g. \\\"Write a story outline.\\\" for writing a novel, or (3) with human inputs.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'})] \\n --- \\n\\n\\nUse the above context and any background question + answer pairs to answer the question: \\n 3. What are some common applications of LLM-powered autonomous agent systems, such as robotics, self-driving cars, or virtual assistants, and how do they leverage the capabilities of the LLM?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [25.40s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Based on the provided context, some common applications of LLM-powered autonomous agent systems include:\\n\\n1. Scientific discovery: LLMs can be empowered to conduct complex scientific experiments by leveraging their ability to reason and make decisions based on large amounts of data (Boiko et al., 2023).\\n2. Robotics: LLM-powered autonomous agents can control robots and perform tasks such as object manipulation, navigation, and decision-making (Weng, 2023).\\n3. Self-driving cars: LLMs can be used to improve the performance of self-driving cars by enhancing their ability to understand and respond to their environment (Liu et al., 2023).\\n4. Virtual assistants: LLM-powered virtual assistants can provide more comprehensive and intelligent responses to user queries by leveraging their ability to reason and learn from large amounts of data (Weng, 2023).\\n\\nIn these applications, the LLM is used to power the autonomous agent system, which integrates with other technologies such as computer vision or natural language processing. The LLM is trained on a specific task or domain, and then fine-tuned for the target application through techniques such as transfer learning or joint training (Ruder et al., 2019).\\n\\nThe capabilities of the LLM are leveraged in various ways in these applications, including:\\n\\n1. Reasoning and decision-making: The LLM can reason and make decisions based on large amounts of data, allowing it to handle complex tasks such as scientific discovery or robotics control.\\n2. Language understanding: The LLM can understand natural language inputs and generate responses, enabling applications such as virtual assistants.\\n3. Knowledge representation: The LLM can represent and manipulate knowledge in a structured way, which is useful for tasks such as planning and decision-making (Boiko et al., 2023).\\n4. Learning and adaptation: The LLM can learn from experience and adapt to new situations, allowing it to improve its performance over time (Liu et al., 2023).\\n\\nOverall, the applications of LLM-powered autonomous agent systems are diverse and have the potential to revolutionize various industries by providing more comprehensive and intelligent solutions.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama2:latest\",\n",
      "          \"created_at\": \"2024-06-18T20:19:56.612943Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 25396312500,\n",
      "          \"load_duration\": 909458,\n",
      "          \"prompt_eval_count\": 1660,\n",
      "          \"prompt_eval_duration\": 6150485000,\n",
      "          \"eval_count\": 513,\n",
      "          \"eval_duration\": 19237319000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Based on the provided context, some common applications of LLM-powered autonomous agent systems include:\\n\\n1. Scientific discovery: LLMs can be empowered to conduct complex scientific experiments by leveraging their ability to reason and make decisions based on large amounts of data (Boiko et al., 2023).\\n2. Robotics: LLM-powered autonomous agents can control robots and perform tasks such as object manipulation, navigation, and decision-making (Weng, 2023).\\n3. Self-driving cars: LLMs can be used to improve the performance of self-driving cars by enhancing their ability to understand and respond to their environment (Liu et al., 2023).\\n4. Virtual assistants: LLM-powered virtual assistants can provide more comprehensive and intelligent responses to user queries by leveraging their ability to reason and learn from large amounts of data (Weng, 2023).\\n\\nIn these applications, the LLM is used to power the autonomous agent system, which integrates with other technologies such as computer vision or natural language processing. The LLM is trained on a specific task or domain, and then fine-tuned for the target application through techniques such as transfer learning or joint training (Ruder et al., 2019).\\n\\nThe capabilities of the LLM are leveraged in various ways in these applications, including:\\n\\n1. Reasoning and decision-making: The LLM can reason and make decisions based on large amounts of data, allowing it to handle complex tasks such as scientific discovery or robotics control.\\n2. Language understanding: The LLM can understand natural language inputs and generate responses, enabling applications such as virtual assistants.\\n3. Knowledge representation: The LLM can represent and manipulate knowledge in a structured way, which is useful for tasks such as planning and decision-making (Boiko et al., 2023).\\n4. Learning and adaptation: The LLM can learn from experience and adapt to new situations, allowing it to improve its performance over time (Liu et al., 2023).\\n\\nOverall, the applications of LLM-powered autonomous agent systems are diverse and have the potential to revolutionize various industries by providing more comprehensive and intelligent solutions.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama2:latest\",\n",
      "              \"created_at\": \"2024-06-18T20:19:56.612943Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 25396312500,\n",
      "              \"load_duration\": 909458,\n",
      "              \"prompt_eval_count\": 1660,\n",
      "              \"prompt_eval_duration\": 6150485000,\n",
      "              \"eval_count\": 513,\n",
      "              \"eval_duration\": 19237319000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-9f8f97f9-1d3c-4d45-89c1-d1bc878f8be3-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [2ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Based on the provided context, some common applications of LLM-powered autonomous agent systems include:\\n\\n1. Scientific discovery: LLMs can be empowered to conduct complex scientific experiments by leveraging their ability to reason and make decisions based on large amounts of data (Boiko et al., 2023).\\n2. Robotics: LLM-powered autonomous agents can control robots and perform tasks such as object manipulation, navigation, and decision-making (Weng, 2023).\\n3. Self-driving cars: LLMs can be used to improve the performance of self-driving cars by enhancing their ability to understand and respond to their environment (Liu et al., 2023).\\n4. Virtual assistants: LLM-powered virtual assistants can provide more comprehensive and intelligent responses to user queries by leveraging their ability to reason and learn from large amounts of data (Weng, 2023).\\n\\nIn these applications, the LLM is used to power the autonomous agent system, which integrates with other technologies such as computer vision or natural language processing. The LLM is trained on a specific task or domain, and then fine-tuned for the target application through techniques such as transfer learning or joint training (Ruder et al., 2019).\\n\\nThe capabilities of the LLM are leveraged in various ways in these applications, including:\\n\\n1. Reasoning and decision-making: The LLM can reason and make decisions based on large amounts of data, allowing it to handle complex tasks such as scientific discovery or robotics control.\\n2. Language understanding: The LLM can understand natural language inputs and generate responses, enabling applications such as virtual assistants.\\n3. Knowledge representation: The LLM can represent and manipulate knowledge in a structured way, which is useful for tasks such as planning and decision-making (Boiko et al., 2023).\\n4. Learning and adaptation: The LLM can learn from experience and adapt to new situations, allowing it to improve its performance over time (Liu et al., 2023).\\n\\nOverall, the applications of LLM-powered autonomous agent systems are diverse and have the potential to revolutionize various industries by providing more comprehensive and intelligent solutions.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [25.50s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Based on the provided context, some common applications of LLM-powered autonomous agent systems include:\\n\\n1. Scientific discovery: LLMs can be empowered to conduct complex scientific experiments by leveraging their ability to reason and make decisions based on large amounts of data (Boiko et al., 2023).\\n2. Robotics: LLM-powered autonomous agents can control robots and perform tasks such as object manipulation, navigation, and decision-making (Weng, 2023).\\n3. Self-driving cars: LLMs can be used to improve the performance of self-driving cars by enhancing their ability to understand and respond to their environment (Liu et al., 2023).\\n4. Virtual assistants: LLM-powered virtual assistants can provide more comprehensive and intelligent responses to user queries by leveraging their ability to reason and learn from large amounts of data (Weng, 2023).\\n\\nIn these applications, the LLM is used to power the autonomous agent system, which integrates with other technologies such as computer vision or natural language processing. The LLM is trained on a specific task or domain, and then fine-tuned for the target application through techniques such as transfer learning or joint training (Ruder et al., 2019).\\n\\nThe capabilities of the LLM are leveraged in various ways in these applications, including:\\n\\n1. Reasoning and decision-making: The LLM can reason and make decisions based on large amounts of data, allowing it to handle complex tasks such as scientific discovery or robotics control.\\n2. Language understanding: The LLM can understand natural language inputs and generate responses, enabling applications such as virtual assistants.\\n3. Knowledge representation: The LLM can represent and manipulate knowledge in a structured way, which is useful for tasks such as planning and decision-making (Boiko et al., 2023).\\n4. Learning and adaptation: The LLM can learn from experience and adapt to new situations, allowing it to improve its performance over time (Liu et al., 2023).\\n\\nOverall, the applications of LLM-powered autonomous agent systems are diverse and have the potential to revolutionize various industries by providing more comprehensive and intelligent solutions.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "q_a_pairs = \"\"\n",
    "for question in decomposed_questions:\n",
    "    ## Retreive docs relevant to question (context) + all previously answered questions (q_a_pairs) and answer current question\n",
    "    rag_chain = {\"context\": itemgetter(\"question\") | retreiver, \"question\": itemgetter(\"question\"), \"q_a_pairs\": itemgetter(\"q_a_pairs\")} | prompt_ir_cot | local_llm | StrOutputParser()\n",
    "\n",
    "    answer = await rag_chain.ainvoke({\"question\": question, \"q_a_pairs\": q_a_pairs})\n",
    "    q_a_pair = format_qa_pair(question, answer)\n",
    "    q_a_pairs = q_a_pairs + \"\\n---\\n\" + q_a_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dfa5ff70-9dd2-417c-9505-db288007b467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, some common applications of LLM-powered autonomous agent systems include:\n",
      "\n",
      "1. Scientific discovery: LLMs can be empowered to conduct complex scientific experiments by leveraging their ability to reason and make decisions based on large amounts of data (Boiko et al., 2023).\n",
      "2. Robotics: LLM-powered autonomous agents can control robots and perform tasks such as object manipulation, navigation, and decision-making (Weng, 2023).\n",
      "3. Self-driving cars: LLMs can be used to improve the performance of self-driving cars by enhancing their ability to understand and respond to their environment (Liu et al., 2023).\n",
      "4. Virtual assistants: LLM-powered virtual assistants can provide more comprehensive and intelligent responses to user queries by leveraging their ability to reason and learn from large amounts of data (Weng, 2023).\n",
      "\n",
      "In these applications, the LLM is used to power the autonomous agent system, which integrates with other technologies such as computer vision or natural language processing. The LLM is trained on a specific task or domain, and then fine-tuned for the target application through techniques such as transfer learning or joint training (Ruder et al., 2019).\n",
      "\n",
      "The capabilities of the LLM are leveraged in various ways in these applications, including:\n",
      "\n",
      "1. Reasoning and decision-making: The LLM can reason and make decisions based on large amounts of data, allowing it to handle complex tasks such as scientific discovery or robotics control.\n",
      "2. Language understanding: The LLM can understand natural language inputs and generate responses, enabling applications such as virtual assistants.\n",
      "3. Knowledge representation: The LLM can represent and manipulate knowledge in a structured way, which is useful for tasks such as planning and decision-making (Boiko et al., 2023).\n",
      "4. Learning and adaptation: The LLM can learn from experience and adapt to new situations, allowing it to improve its performance over time (Liu et al., 2023).\n",
      "\n",
      "Overall, the applications of LLM-powered autonomous agent systems are diverse and have the potential to revolutionize various industries by providing more comprehensive and intelligent solutions.\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51d3165-24bb-4164-8b7a-e80c03c6ffec",
   "metadata": {},
   "source": [
    "### Way 4: Step back prompting: Useful for knowledge intensive tasks where it will benifit from thinking from first principles/ overall level/ step back to get broader picture.\n",
    "- Step back question: derived from original question at a higher level of abstraction (This step back question should be much easier to answer)\n",
    "\n",
    "2 steps:\n",
    "1. Abstraction: Get step back question and retreive relevant concepts for it.. This step back question is task dependent.\n",
    "2. Reasoning (Abstraction grounded reasoning): Answer original question but stay grounded on facts obtained from Abstraction phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "35f63553-7077-4bb7-83f7-82339f2bed48",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2 shot examples\n",
    "## input: query, output: step back version of query\n",
    "examples = [{\"input\": \"Could the members of The Police perform lawful arrests?\", \"output\": \"what can the members of The Police do?\"}, {\"input\": \"Jan Sindels was born in what country?\", \"output\": \"what is Jan Sindels personal history?\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a52a945e-7d39-4f58-a7f6-7ba71dbc420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = ChatPromptTemplate.from_messages([(\"human\", \"{input}\"), (\"ai\", \"{output}\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8a590510-57b0-41f5-b2f7-6c9c77697524",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = FewShotChatMessagePromptTemplate(example_prompt=example_prompt, examples=examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "253bba5e-4744-442a-b86c-56d1893bb1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_back_prompt = ChatPromptTemplate.from_messages([(\"system\", \"\"\"You are an expert at world knowledge. Your task is to step back and paraphrase a question to a more generic step-back question, which is easier to answer. Here are a few examples:\"\"\"), few_shot_prompt, (\"user\", \"{question}\")]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9e27dc0d-c789-483e-9f61-cc9e491b05fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are an expert at world knowledge. Your task is to step back and paraphrase a question to a more generic step-back question, which is easier to answer. Here are a few examples:'), HumanMessage(content='Could the members of The Police perform lawful arrests?'), AIMessage(content='what can the members of The Police do?'), HumanMessage(content='Jan Sindels was born in what country?'), AIMessage(content='what is Jan Sindels personal history?'), HumanMessage(content='What is task decomposition for LLM agents?')])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_back_prompt.invoke({\"question\": \"What is task decomposition for LLM agents?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "72314412-066a-4021-a45a-0396d64e41f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are an expert at world knowledge. Your task is to step back and paraphrase a question to a more generic step-back question, which is easier to answer. Here are a few examples:\\nHuman: Could the members of The Police perform lawful arrests?\\nAI: what can the members of The Police do?\\nHuman: Jan Sindels was born in what country?\\nAI: what is Jan Sindels personal history?\\nHuman: What is task decomposition for LLM agents?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [972ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"can you explain a key concept related to artificial intelligence?\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama2:latest\",\n",
      "          \"created_at\": \"2024-06-18T20:19:57.633429Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 967505666,\n",
      "          \"load_duration\": 1985333,\n",
      "          \"prompt_eval_count\": 149,\n",
      "          \"prompt_eval_duration\": 652766000,\n",
      "          \"eval_count\": 12,\n",
      "          \"eval_duration\": 310086000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"can you explain a key concept related to artificial intelligence?\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama2:latest\",\n",
      "              \"created_at\": \"2024-06-18T20:19:57.633429Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 967505666,\n",
      "              \"load_duration\": 1985333,\n",
      "              \"prompt_eval_count\": 149,\n",
      "              \"prompt_eval_duration\": 652766000,\n",
      "              \"eval_count\": 12,\n",
      "              \"eval_duration\": 310086000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-bdc25236-b0dd-41c7-85a1-53d28e0486fa-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [2ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"can you explain a key concept related to artificial intelligence?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [980ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"can you explain a key concept related to artificial intelligence?\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "generate_step_back_queries_chain = step_back_prompt | local_llm | StrOutputParser()\n",
    "step_back_query = await generate_step_back_queries_chain.ainvoke({\"question\": \"What is task decomposition for LLM agents?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cfe368b2-5df0-4c4d-92e0-7aeb4956820e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can you explain a key concept related to artificial intelligence?\n"
     ]
    }
   ],
   "source": [
    "print(step_back_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2b935875-d004-4b35-aa3c-8ae432b930b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_back_response_template = \"\"\"You are an expert of world knowledge. I am going to ask you a question. Your response should be comprehensive and not contradicted with the following context if they are relevant. Otherwise, ignore them if they are not relevant.\n",
    "\n",
    "{normal_context}\n",
    "{step_back_context}\n",
    "\n",
    "Original Question: {question}\n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "42189447-899c-4dda-a79b-e8378298d9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_back_response_prompt = ChatPromptTemplate.from_template(step_back_response_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a47d503a-f731-4542-9547-e9ef582d3d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['normal_context', 'question', 'step_back_context'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['normal_context', 'question', 'step_back_context'], template='You are an expert of world knowledge. I am going to ask you a question. Your response should be comprehensive and not contradicted with the following context if they are relevant. Otherwise, ignore them if they are not relevant.\\n\\n{normal_context}\\n{step_back_context}\\n\\nOriginal Question: {question}\\nAnswer:'))])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_back_response_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3b22127b-f0f2-4aec-b120-ffbfb6b2f974",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_back_chain = {\"question\": itemgetter(\"question\"), \"normal_context\": itemgetter(\"question\") | retreiver, \"step_back_context\": generate_step_back_queries_chain | retreiver } | step_back_response_prompt | local_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8fb98f19-383b-48cf-95e6-8c200cb392f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question,normal_context,step_back_context>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question,normal_context,step_back_context> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question,normal_context,step_back_context> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question,normal_context,step_back_context> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question,normal_context,step_back_context> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question,normal_context,step_back_context> > chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question,normal_context,step_back_context> > chain:RunnableLambda] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question,normal_context,step_back_context> > chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question,normal_context,step_back_context> > chain:RunnableSequence > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question,normal_context,step_back_context> > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are an expert at world knowledge. Your task is to step back and paraphrase a question to a more generic step-back question, which is easier to answer. Here are a few examples:\\nHuman: Could the members of The Police perform lawful arrests?\\nAI: what can the members of The Police do?\\nHuman: Jan Sindels was born in what country?\\nAI: what is Jan Sindels personal history?\\nHuman: What is task decomposition for LLM agents?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question,normal_context,step_back_context> > chain:RunnableSequence] [72ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question,normal_context,step_back_context> > chain:RunnableSequence > llm:ChatOllama] [394ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"what are the subtasks involved in LLM agent tasks?\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama2:latest\",\n",
      "          \"created_at\": \"2024-06-18T20:19:58.086124Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 389012667,\n",
      "          \"load_duration\": 917625,\n",
      "          \"prompt_eval_duration\": 29792000,\n",
      "          \"eval_count\": 13,\n",
      "          \"eval_duration\": 355291000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"what are the subtasks involved in LLM agent tasks?\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama2:latest\",\n",
      "              \"created_at\": \"2024-06-18T20:19:58.086124Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 389012667,\n",
      "              \"load_duration\": 917625,\n",
      "              \"prompt_eval_duration\": 29792000,\n",
      "              \"eval_count\": 13,\n",
      "              \"eval_duration\": 355291000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-bf5d5f78-b7f5-4444-9964-71d0b4513c6e-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question,normal_context,step_back_context> > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question,normal_context,step_back_context> > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"what are the subtasks involved in LLM agent tasks?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question,normal_context,step_back_context> > chain:RunnableSequence] [459ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question,normal_context,step_back_context>] [462ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an expert of world knowledge. I am going to ask you a question. Your response should be comprehensive and not contradicted with the following context if they are relevant. Otherwise, ignore them if they are not relevant.\\n\\n[Document(page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\\\nComponent One: Planning#\\\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\\\nTask Decomposition#\\\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to think step by step to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the models thinking process.\\\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\\\nTask decomposition can be done (1) by LLM with simple prompting like \\\"Steps for XYZ.\\\\\\\\n1.\\\", \\\"What are the subgoals for achieving XYZ?\\\", (2) by using task-specific instructions; e.g. \\\"Write a story outline.\\\" for writing a novel, or (3) with human inputs.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}), Document(page_content='LLM Powered Autonomous Agents\\\\n    \\\\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\\\n\\\\n\\\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview#\\\\nIn a LLM-powered autonomous agent system, LLM functions as the agents brain, complemented by several key components:\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}), Document(page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\\\n\\\\n\\\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\\\n\\\\n\\\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\\\n\\\\n\\\\nCitation#\\\\nCited as:\\\\n\\\\nWeng, Lilian. (Jun 2023). LLM-powered Autonomous Agents. LilLog. https://lilianweng.github.io/posts/2023-06-23-agent/.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}), Document(page_content='The AI assistant can parse user input to several tasks: [{\\\"task\\\": task, \\\"id\\\", task_id, \\\"dep\\\": dependency_task_ids, \\\"args\\\": {\\\"text\\\": text, \\\"image\\\": URL, \\\"audio\\\": URL, \\\"video\\\": URL}}]. The \\\"dep\\\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \\\"-task_id\\\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\\\\n\\\\n(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\\\nInstruction:', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'})]\\n[Document(page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\\\nComponent One: Planning#\\\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\\\nTask Decomposition#\\\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to think step by step to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the models thinking process.\\\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\\\nTask decomposition can be done (1) by LLM with simple prompting like \\\"Steps for XYZ.\\\\\\\\n1.\\\", \\\"What are the subgoals for achieving XYZ?\\\", (2) by using task-specific instructions; e.g. \\\"Write a story outline.\\\" for writing a novel, or (3) with human inputs.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}), Document(page_content='LLM Powered Autonomous Agents\\\\n    \\\\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\\\n\\\\n\\\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview#\\\\nIn a LLM-powered autonomous agent system, LLM functions as the agents brain, complemented by several key components:\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}), Document(page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\\\n\\\\n\\\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\\\n\\\\n\\\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\\\n\\\\n\\\\nCitation#\\\\nCited as:\\\\n\\\\nWeng, Lilian. (Jun 2023). LLM-powered Autonomous Agents. LilLog. https://lilianweng.github.io/posts/2023-06-23-agent/.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}), Document(page_content='Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\\\nThe system comprises of 4 stages:\\\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\\\nInstruction:', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'})]\\n\\nOriginal Question: What is task decomposition for LLM agents?\\nAnswer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [17.13s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down a complex task into smaller, manageable subtasks or steps. This is typically done to improve the efficiency and quality of the agent's performance on the task. The goal of task decomposition is to enable the agent to handle complex tasks by breaking them down into simpler ones that can be tackled one at a time.\\n\\nThere are several approaches to task decomposition for LLM agents, including:\\n\\n1. Chain of thought (CoT): This involves instructing the LLM to \\\"think step by step\\\" to utilize more test-time computation to decompose hard tasks into smaller and simpler steps.\\n2. Tree of thoughts (ToT): This extends CoT by exploring multiple reasoning possibilities at each step, creating a tree structure. The search process can be BFS or DFS with each state evaluated by a classifier (via a prompt) or majority vote.\\n3. Human inputs: Task decomposition can also be done using human inputs, such as providing a list of subtasks for the agent to execute.\\n4. LLM-based instructions: The agent can be instructed to perform tasks in a specific order or with specific dependencies, such as \\\"Write a story outline.\\\" for writing a novel.\\n\\nThe benefits of task decomposition for LLM agents include improved efficiency and quality of performance, as well as the ability to handle complex tasks that would otherwise be difficult to manage.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama2:latest\",\n",
      "          \"created_at\": \"2024-06-18T20:20:15.276275Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 17124958500,\n",
      "          \"load_duration\": 828042,\n",
      "          \"prompt_eval_count\": 1572,\n",
      "          \"prompt_eval_duration\": 5873737000,\n",
      "          \"eval_count\": 308,\n",
      "          \"eval_duration\": 11244547000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down a complex task into smaller, manageable subtasks or steps. This is typically done to improve the efficiency and quality of the agent's performance on the task. The goal of task decomposition is to enable the agent to handle complex tasks by breaking them down into simpler ones that can be tackled one at a time.\\n\\nThere are several approaches to task decomposition for LLM agents, including:\\n\\n1. Chain of thought (CoT): This involves instructing the LLM to \\\"think step by step\\\" to utilize more test-time computation to decompose hard tasks into smaller and simpler steps.\\n2. Tree of thoughts (ToT): This extends CoT by exploring multiple reasoning possibilities at each step, creating a tree structure. The search process can be BFS or DFS with each state evaluated by a classifier (via a prompt) or majority vote.\\n3. Human inputs: Task decomposition can also be done using human inputs, such as providing a list of subtasks for the agent to execute.\\n4. LLM-based instructions: The agent can be instructed to perform tasks in a specific order or with specific dependencies, such as \\\"Write a story outline.\\\" for writing a novel.\\n\\nThe benefits of task decomposition for LLM agents include improved efficiency and quality of performance, as well as the ability to handle complex tasks that would otherwise be difficult to manage.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama2:latest\",\n",
      "              \"created_at\": \"2024-06-18T20:20:15.276275Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 17124958500,\n",
      "              \"load_duration\": 828042,\n",
      "              \"prompt_eval_count\": 1572,\n",
      "              \"prompt_eval_duration\": 5873737000,\n",
      "              \"eval_count\": 308,\n",
      "              \"eval_duration\": 11244547000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-af5d1e68-7d66-47f2-a499-9b3657d68e16-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down a complex task into smaller, manageable subtasks or steps. This is typically done to improve the efficiency and quality of the agent's performance on the task. The goal of task decomposition is to enable the agent to handle complex tasks by breaking them down into simpler ones that can be tackled one at a time.\\n\\nThere are several approaches to task decomposition for LLM agents, including:\\n\\n1. Chain of thought (CoT): This involves instructing the LLM to \\\"think step by step\\\" to utilize more test-time computation to decompose hard tasks into smaller and simpler steps.\\n2. Tree of thoughts (ToT): This extends CoT by exploring multiple reasoning possibilities at each step, creating a tree structure. The search process can be BFS or DFS with each state evaluated by a classifier (via a prompt) or majority vote.\\n3. Human inputs: Task decomposition can also be done using human inputs, such as providing a list of subtasks for the agent to execute.\\n4. LLM-based instructions: The agent can be instructed to perform tasks in a specific order or with specific dependencies, such as \\\"Write a story outline.\\\" for writing a novel.\\n\\nThe benefits of task decomposition for LLM agents include improved efficiency and quality of performance, as well as the ability to handle complex tasks that would otherwise be difficult to manage.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [17.60s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down a complex task into smaller, manageable subtasks or steps. This is typically done to improve the efficiency and quality of the agent's performance on the task. The goal of task decomposition is to enable the agent to handle complex tasks by breaking them down into simpler ones that can be tackled one at a time.\\n\\nThere are several approaches to task decomposition for LLM agents, including:\\n\\n1. Chain of thought (CoT): This involves instructing the LLM to \\\"think step by step\\\" to utilize more test-time computation to decompose hard tasks into smaller and simpler steps.\\n2. Tree of thoughts (ToT): This extends CoT by exploring multiple reasoning possibilities at each step, creating a tree structure. The search process can be BFS or DFS with each state evaluated by a classifier (via a prompt) or majority vote.\\n3. Human inputs: Task decomposition can also be done using human inputs, such as providing a list of subtasks for the agent to execute.\\n4. LLM-based instructions: The agent can be instructed to perform tasks in a specific order or with specific dependencies, such as \\\"Write a story outline.\\\" for writing a novel.\\n\\nThe benefits of task decomposition for LLM agents include improved efficiency and quality of performance, as well as the ability to handle complex tasks that would otherwise be difficult to manage.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "step_back_answer = await step_back_chain.ainvoke({\"question\": \"What is task decomposition for LLM agents?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9c7e4033-bc06-45ee-8dea-c91263acaa44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down a complex task into smaller, manageable subtasks or steps. This is typically done to improve the efficiency and quality of the agent's performance on the task. The goal of task decomposition is to enable the agent to handle complex tasks by breaking them down into simpler ones that can be tackled one at a time.\n",
      "\n",
      "There are several approaches to task decomposition for LLM agents, including:\n",
      "\n",
      "1. Chain of thought (CoT): This involves instructing the LLM to \"think step by step\" to utilize more test-time computation to decompose hard tasks into smaller and simpler steps.\n",
      "2. Tree of thoughts (ToT): This extends CoT by exploring multiple reasoning possibilities at each step, creating a tree structure. The search process can be BFS or DFS with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "3. Human inputs: Task decomposition can also be done using human inputs, such as providing a list of subtasks for the agent to execute.\n",
      "4. LLM-based instructions: The agent can be instructed to perform tasks in a specific order or with specific dependencies, such as \"Write a story outline.\" for writing a novel.\n",
      "\n",
      "The benefits of task decomposition for LLM agents include improved efficiency and quality of performance, as well as the ability to handle complex tasks that would otherwise be difficult to manage.\n"
     ]
    }
   ],
   "source": [
    "print(step_back_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffa6c1b-1c31-4677-b8e4-8e0ef70aa5d8",
   "metadata": {},
   "source": [
    "### Way 5: HyDE (Hypothetical Document Embedding) => https://docs.haystack.deepset.ai/docs/hypothetical-document-embeddings-hyde\n",
    "1. Given a query, the Hypothetical Document Embeddings (HyDE) first zero-shot prompts an instruction-following language model to generate a fake hypothetical document that captures relevant textual patterns from the initial query - in practice, this is done five times. (basically ask Instruction following LLM to generate paragraphs to answer user query 5 times)\n",
    "2. Embed the 5 results from Step 1 using the same embedder as the one used to embed docs and save in Chroma DB\n",
    "3. Average the embeddings (for 5 documents) to get a single Hypothetical Document embedding\n",
    "4. Now, search top_k documents with embedding similar to the hypothetical document created in previous step. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d335599-a777-4f9d-99cb-f629427f18fa",
   "metadata": {},
   "source": [
    "When to use?\n",
    "The HyDE method is highly useful when:\n",
    "\n",
    "1. The performance of the retrieval step in your pipeline is not good enough (for example, low Recall metric).\n",
    "2. Your retrieval step has a query as input and returns documents from a larger document base.\n",
    "3. Particularly worth a try if your data (documents or queries) come from a special domain that is very different from the typical datasets that Retrievers are trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2170fe09-48a2-402e-b8d1-19c6f3da864c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyde_prompt_template = \"\"\"Given a question, generate a paragraph of text that answers the question\n",
    "Question: {question}\n",
    "Passage:\"\"\"\n",
    "hyde_prompt = ChatPromptTemplate.from_template(hyde_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2ef07de7-318c-47c6-9b49-681a9042a1e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question> > chain:RunnableLambda] [12ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question>] [33ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Given a question, generate a paragraph of text that answers the question\\nQuestion: What is task decomposition for LLM agents?\\nPassage:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [4.63s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex tasks into smaller, more manageable sub-tasks. This technique allows LLM agents to tackle challenging tasks by dividing them into simpler ones, which can be completed with greater accuracy and efficiency. By decomposing a task into smaller parts, the LLM agent can focus on each component separately, using its language understanding capabilities to execute each part successfully. This approach enables LLM agents to handle complex tasks that would otherwise be beyond their capabilities, making them more versatile and effective in various applications. Task decomposition is an essential technique for LLM agents to improve their performance and enhance their ability to handle diverse linguistic inputs.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama2:latest\",\n",
      "          \"created_at\": \"2024-06-18T20:24:45.889581Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 4629461333,\n",
      "          \"load_duration\": 1511625,\n",
      "          \"prompt_eval_count\": 46,\n",
      "          \"prompt_eval_duration\": 457430000,\n",
      "          \"eval_count\": 149,\n",
      "          \"eval_duration\": 4168577000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex tasks into smaller, more manageable sub-tasks. This technique allows LLM agents to tackle challenging tasks by dividing them into simpler ones, which can be completed with greater accuracy and efficiency. By decomposing a task into smaller parts, the LLM agent can focus on each component separately, using its language understanding capabilities to execute each part successfully. This approach enables LLM agents to handle complex tasks that would otherwise be beyond their capabilities, making them more versatile and effective in various applications. Task decomposition is an essential technique for LLM agents to improve their performance and enhance their ability to handle diverse linguistic inputs.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama2:latest\",\n",
      "              \"created_at\": \"2024-06-18T20:24:45.889581Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 4629461333,\n",
      "              \"load_duration\": 1511625,\n",
      "              \"prompt_eval_count\": 46,\n",
      "              \"prompt_eval_duration\": 457430000,\n",
      "              \"eval_count\": 149,\n",
      "              \"eval_duration\": 4168577000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-8e44485d-c8d6-4a02-abcd-6a9f556e227f-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [2ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex tasks into smaller, more manageable sub-tasks. This technique allows LLM agents to tackle challenging tasks by dividing them into simpler ones, which can be completed with greater accuracy and efficiency. By decomposing a task into smaller parts, the LLM agent can focus on each component separately, using its language understanding capabilities to execute each part successfully. This approach enables LLM agents to handle complex tasks that would otherwise be beyond their capabilities, making them more versatile and effective in various applications. Task decomposition is an essential technique for LLM agents to improve their performance and enhance their ability to handle diverse linguistic inputs.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [4.68s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex tasks into smaller, more manageable sub-tasks. This technique allows LLM agents to tackle challenging tasks by dividing them into simpler ones, which can be completed with greater accuracy and efficiency. By decomposing a task into smaller parts, the LLM agent can focus on each component separately, using its language understanding capabilities to execute each part successfully. This approach enables LLM agents to handle complex tasks that would otherwise be beyond their capabilities, making them more versatile and effective in various applications. Task decomposition is an essential technique for LLM agents to improve their performance and enhance their ability to handle diverse linguistic inputs.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question> > chain:RunnableLambda] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question>] [3ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Given a question, generate a paragraph of text that answers the question\\nQuestion: What is task decomposition for LLM agents?\\nPassage:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [6.92s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Task decomposition for LLM (Language Model) agents refers to the process of breaking down complex tasks into smaller, more manageable sub-tasks or steps. This technique is essential for LLM agents to effectively handle diverse and dynamic tasks, as it enables them to focus on specific aspects of the task at hand and apply their language understanding capabilities in a structured manner. By decomposing a task into smaller components, LLM agents can better understand their goals, identify relevant information, and generate appropriate responses. This process also helps to reduce cognitive overload and improve overall task performance by allowing agents to tackle tasks in a more systematic and efficient way.\\n\\nTask decomposition can involve various techniques, such as identifying key phrases or keywords within a task description, breaking down complex actions into smaller steps, or categorizing tasks based on their underlying goals or objectives. LLM agents can also use various strategies to manage and prioritize tasks, such as using mental maps or graphs to organize information, or employing different levels of abstraction to represent tasks at different stages of completion. By leveraging these techniques, LLM agents can better navigate complex task environments and provide more accurate and effective responses.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama2:latest\",\n",
      "          \"created_at\": \"2024-06-18T20:24:52.838356Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 6916018000,\n",
      "          \"load_duration\": 1509417,\n",
      "          \"prompt_eval_duration\": 29389000,\n",
      "          \"eval_count\": 246,\n",
      "          \"eval_duration\": 6883102000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Task decomposition for LLM (Language Model) agents refers to the process of breaking down complex tasks into smaller, more manageable sub-tasks or steps. This technique is essential for LLM agents to effectively handle diverse and dynamic tasks, as it enables them to focus on specific aspects of the task at hand and apply their language understanding capabilities in a structured manner. By decomposing a task into smaller components, LLM agents can better understand their goals, identify relevant information, and generate appropriate responses. This process also helps to reduce cognitive overload and improve overall task performance by allowing agents to tackle tasks in a more systematic and efficient way.\\n\\nTask decomposition can involve various techniques, such as identifying key phrases or keywords within a task description, breaking down complex actions into smaller steps, or categorizing tasks based on their underlying goals or objectives. LLM agents can also use various strategies to manage and prioritize tasks, such as using mental maps or graphs to organize information, or employing different levels of abstraction to represent tasks at different stages of completion. By leveraging these techniques, LLM agents can better navigate complex task environments and provide more accurate and effective responses.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama2:latest\",\n",
      "              \"created_at\": \"2024-06-18T20:24:52.838356Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 6916018000,\n",
      "              \"load_duration\": 1509417,\n",
      "              \"prompt_eval_duration\": 29389000,\n",
      "              \"eval_count\": 246,\n",
      "              \"eval_duration\": 6883102000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-17ba44d8-da40-4254-a738-4cb10f90c1fd-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Task decomposition for LLM (Language Model) agents refers to the process of breaking down complex tasks into smaller, more manageable sub-tasks or steps. This technique is essential for LLM agents to effectively handle diverse and dynamic tasks, as it enables them to focus on specific aspects of the task at hand and apply their language understanding capabilities in a structured manner. By decomposing a task into smaller components, LLM agents can better understand their goals, identify relevant information, and generate appropriate responses. This process also helps to reduce cognitive overload and improve overall task performance by allowing agents to tackle tasks in a more systematic and efficient way.\\n\\nTask decomposition can involve various techniques, such as identifying key phrases or keywords within a task description, breaking down complex actions into smaller steps, or categorizing tasks based on their underlying goals or objectives. LLM agents can also use various strategies to manage and prioritize tasks, such as using mental maps or graphs to organize information, or employing different levels of abstraction to represent tasks at different stages of completion. By leveraging these techniques, LLM agents can better navigate complex task environments and provide more accurate and effective responses.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [6.94s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Task decomposition for LLM (Language Model) agents refers to the process of breaking down complex tasks into smaller, more manageable sub-tasks or steps. This technique is essential for LLM agents to effectively handle diverse and dynamic tasks, as it enables them to focus on specific aspects of the task at hand and apply their language understanding capabilities in a structured manner. By decomposing a task into smaller components, LLM agents can better understand their goals, identify relevant information, and generate appropriate responses. This process also helps to reduce cognitive overload and improve overall task performance by allowing agents to tackle tasks in a more systematic and efficient way.\\n\\nTask decomposition can involve various techniques, such as identifying key phrases or keywords within a task description, breaking down complex actions into smaller steps, or categorizing tasks based on their underlying goals or objectives. LLM agents can also use various strategies to manage and prioritize tasks, such as using mental maps or graphs to organize information, or employing different levels of abstraction to represent tasks at different stages of completion. By leveraging these techniques, LLM agents can better navigate complex task environments and provide more accurate and effective responses.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question> > chain:RunnableLambda] [3ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question>] [4ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Given a question, generate a paragraph of text that answers the question\\nQuestion: What is task decomposition for LLM agents?\\nPassage:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [5.78s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex tasks into smaller, more manageable sub-tasks. This allows the agent to focus on each sub-task individually, rather than trying to tackle the entire task all at once. By decomposing a task into smaller parts, the agent can use its language understanding capabilities more effectively, as it can concentrate on one aspect of the task at a time. For example, if an LLM agent is given the task of writing a news article, it may first break down the task into smaller sub-tasks such as researching the topic, identifying relevant sources, and organizing the information into an outline. Once the agent has completed these sub-tasks, it can then focus on writing the article itself, using the information gathered during the previous stages. Task decomposition allows LLM agents to tackle complex tasks by breaking them down into manageable parts, enabling them to complete the task more efficiently and effectively.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama2:latest\",\n",
      "          \"created_at\": \"2024-06-18T20:24:58.639627Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 5769132250,\n",
      "          \"load_duration\": 1055458,\n",
      "          \"prompt_eval_duration\": 28666000,\n",
      "          \"eval_count\": 206,\n",
      "          \"eval_duration\": 5738015000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex tasks into smaller, more manageable sub-tasks. This allows the agent to focus on each sub-task individually, rather than trying to tackle the entire task all at once. By decomposing a task into smaller parts, the agent can use its language understanding capabilities more effectively, as it can concentrate on one aspect of the task at a time. For example, if an LLM agent is given the task of writing a news article, it may first break down the task into smaller sub-tasks such as researching the topic, identifying relevant sources, and organizing the information into an outline. Once the agent has completed these sub-tasks, it can then focus on writing the article itself, using the information gathered during the previous stages. Task decomposition allows LLM agents to tackle complex tasks by breaking them down into manageable parts, enabling them to complete the task more efficiently and effectively.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama2:latest\",\n",
      "              \"created_at\": \"2024-06-18T20:24:58.639627Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 5769132250,\n",
      "              \"load_duration\": 1055458,\n",
      "              \"prompt_eval_duration\": 28666000,\n",
      "              \"eval_count\": 206,\n",
      "              \"eval_duration\": 5738015000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-c8bd7783-85ff-472d-9043-5ea0841e30cb-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [2ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex tasks into smaller, more manageable sub-tasks. This allows the agent to focus on each sub-task individually, rather than trying to tackle the entire task all at once. By decomposing a task into smaller parts, the agent can use its language understanding capabilities more effectively, as it can concentrate on one aspect of the task at a time. For example, if an LLM agent is given the task of writing a news article, it may first break down the task into smaller sub-tasks such as researching the topic, identifying relevant sources, and organizing the information into an outline. Once the agent has completed these sub-tasks, it can then focus on writing the article itself, using the information gathered during the previous stages. Task decomposition allows LLM agents to tackle complex tasks by breaking them down into manageable parts, enabling them to complete the task more efficiently and effectively.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [5.80s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex tasks into smaller, more manageable sub-tasks. This allows the agent to focus on each sub-task individually, rather than trying to tackle the entire task all at once. By decomposing a task into smaller parts, the agent can use its language understanding capabilities more effectively, as it can concentrate on one aspect of the task at a time. For example, if an LLM agent is given the task of writing a news article, it may first break down the task into smaller sub-tasks such as researching the topic, identifying relevant sources, and organizing the information into an outline. Once the agent has completed these sub-tasks, it can then focus on writing the article itself, using the information gathered during the previous stages. Task decomposition allows LLM agents to tackle complex tasks by breaking them down into manageable parts, enabling them to complete the task more efficiently and effectively.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question> > chain:RunnableLambda] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question>] [4ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Given a question, generate a paragraph of text that answers the question\\nQuestion: What is task decomposition for LLM agents?\\nPassage:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [5.30s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex tasks into smaller, more manageable sub-tasks. This allows the agent to focus on each sub-task individually, rather than trying to tackle the entire task all at once. By decomposing a task into smaller parts, the LLM agent can leverage its capabilities more efficiently and effectively, leading to better performance and accuracy. Task decomposition is particularly useful for tasks that involve multiple steps or require the agent to process and analyze large amounts of data. By breaking down these tasks into smaller, more manageable pieces, the LLM agent can more easily identify patterns and relationships within the data, making it easier to make predictions or take actions based on that data. In addition, task decomposition can help to reduce the cognitive overload associated with complex tasks, allowing the LLM agent to perform at its best and achieve better results.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama2:latest\",\n",
      "          \"created_at\": \"2024-06-18T20:25:03.959392Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 5290704667,\n",
      "          \"load_duration\": 1385250,\n",
      "          \"prompt_eval_duration\": 28791000,\n",
      "          \"eval_count\": 189,\n",
      "          \"eval_duration\": 5258894000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex tasks into smaller, more manageable sub-tasks. This allows the agent to focus on each sub-task individually, rather than trying to tackle the entire task all at once. By decomposing a task into smaller parts, the LLM agent can leverage its capabilities more efficiently and effectively, leading to better performance and accuracy. Task decomposition is particularly useful for tasks that involve multiple steps or require the agent to process and analyze large amounts of data. By breaking down these tasks into smaller, more manageable pieces, the LLM agent can more easily identify patterns and relationships within the data, making it easier to make predictions or take actions based on that data. In addition, task decomposition can help to reduce the cognitive overload associated with complex tasks, allowing the LLM agent to perform at its best and achieve better results.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama2:latest\",\n",
      "              \"created_at\": \"2024-06-18T20:25:03.959392Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 5290704667,\n",
      "              \"load_duration\": 1385250,\n",
      "              \"prompt_eval_duration\": 28791000,\n",
      "              \"eval_count\": 189,\n",
      "              \"eval_duration\": 5258894000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-5b9d9d7e-556c-4a14-975d-8a35881d952e-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [2ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex tasks into smaller, more manageable sub-tasks. This allows the agent to focus on each sub-task individually, rather than trying to tackle the entire task all at once. By decomposing a task into smaller parts, the LLM agent can leverage its capabilities more efficiently and effectively, leading to better performance and accuracy. Task decomposition is particularly useful for tasks that involve multiple steps or require the agent to process and analyze large amounts of data. By breaking down these tasks into smaller, more manageable pieces, the LLM agent can more easily identify patterns and relationships within the data, making it easier to make predictions or take actions based on that data. In addition, task decomposition can help to reduce the cognitive overload associated with complex tasks, allowing the LLM agent to perform at its best and achieve better results.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [5.31s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex tasks into smaller, more manageable sub-tasks. This allows the agent to focus on each sub-task individually, rather than trying to tackle the entire task all at once. By decomposing a task into smaller parts, the LLM agent can leverage its capabilities more efficiently and effectively, leading to better performance and accuracy. Task decomposition is particularly useful for tasks that involve multiple steps or require the agent to process and analyze large amounts of data. By breaking down these tasks into smaller, more manageable pieces, the LLM agent can more easily identify patterns and relationships within the data, making it easier to make predictions or take actions based on that data. In addition, task decomposition can help to reduce the cognitive overload associated with complex tasks, allowing the LLM agent to perform at its best and achieve better results.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question> > chain:RunnableLambda] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<question>] [4ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Given a question, generate a paragraph of text that answers the question\\nQuestion: What is task decomposition for LLM agents?\\nPassage:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [5.04s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Task decomposition is a process of breaking down complex tasks into smaller, more manageable subtasks for an LLM (Large Language Model) agent. This allows the agent to focus on each subtask individually and complete them efficiently, rather than trying to tackle the entire task at once. By decomposing a task into smaller parts, the agent can better understand the task requirements, identify potential obstacles, and develop strategies for overcoming them. Additionally, task decomposition enables the agent to divide its attention between different subtasks, allowing it to process information more quickly and make decisions more accurately. This approach is particularly useful in situations where time is of the essence, such as in high-stakes decision-making or complex problem-solving tasks. By using task decomposition, LLM agents can improve their performance and achieve better outcomes in a wide range of applications.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama2:latest\",\n",
      "          \"created_at\": \"2024-06-18T20:25:09.026284Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 5038353458,\n",
      "          \"load_duration\": 1516208,\n",
      "          \"prompt_eval_duration\": 28663000,\n",
      "          \"eval_count\": 180,\n",
      "          \"eval_duration\": 5005699000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Task decomposition is a process of breaking down complex tasks into smaller, more manageable subtasks for an LLM (Large Language Model) agent. This allows the agent to focus on each subtask individually and complete them efficiently, rather than trying to tackle the entire task at once. By decomposing a task into smaller parts, the agent can better understand the task requirements, identify potential obstacles, and develop strategies for overcoming them. Additionally, task decomposition enables the agent to divide its attention between different subtasks, allowing it to process information more quickly and make decisions more accurately. This approach is particularly useful in situations where time is of the essence, such as in high-stakes decision-making or complex problem-solving tasks. By using task decomposition, LLM agents can improve their performance and achieve better outcomes in a wide range of applications.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama2:latest\",\n",
      "              \"created_at\": \"2024-06-18T20:25:09.026284Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 5038353458,\n",
      "              \"load_duration\": 1516208,\n",
      "              \"prompt_eval_duration\": 28663000,\n",
      "              \"eval_count\": 180,\n",
      "              \"eval_duration\": 5005699000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-4b9cfe7a-e111-4050-986a-0e3e8fac00c5-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Task decomposition is a process of breaking down complex tasks into smaller, more manageable subtasks for an LLM (Large Language Model) agent. This allows the agent to focus on each subtask individually and complete them efficiently, rather than trying to tackle the entire task at once. By decomposing a task into smaller parts, the agent can better understand the task requirements, identify potential obstacles, and develop strategies for overcoming them. Additionally, task decomposition enables the agent to divide its attention between different subtasks, allowing it to process information more quickly and make decisions more accurately. This approach is particularly useful in situations where time is of the essence, such as in high-stakes decision-making or complex problem-solving tasks. By using task decomposition, LLM agents can improve their performance and achieve better outcomes in a wide range of applications.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [5.06s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Task decomposition is a process of breaking down complex tasks into smaller, more manageable subtasks for an LLM (Large Language Model) agent. This allows the agent to focus on each subtask individually and complete them efficiently, rather than trying to tackle the entire task at once. By decomposing a task into smaller parts, the agent can better understand the task requirements, identify potential obstacles, and develop strategies for overcoming them. Additionally, task decomposition enables the agent to divide its attention between different subtasks, allowing it to process information more quickly and make decisions more accurately. This approach is particularly useful in situations where time is of the essence, such as in high-stakes decision-making or complex problem-solving tasks. By using task decomposition, LLM agents can improve their performance and achieve better outcomes in a wide range of applications.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "count_hypothetical_docs = 5\n",
    "hypothetical_doc_list = []\n",
    "for c in range(count_hypothetical_docs):\n",
    "    hyde_chain = {\"question\": itemgetter(\"question\")} | hyde_prompt | local_llm | StrOutputParser()\n",
    "    hyp_doc = await hyde_chain.ainvoke({\"question\": \"What is task decomposition for LLM agents?\"})\n",
    "    hypothetical_doc_list.append(hyp_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "196374c0-71c1-4c48-81bd-b4dcdb68c42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothetical_document_embedding_list = await embeddings.aembed_documents(hypothetical_doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "82501451-bd0b-40d1-89ae-7c2a7757bcd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hypothetical_embedding_matrix = np.array(hypothetical_document_embedding_list)\n",
    "average_hypothetical_document_embedding = np.mean(hypothetical_embedding_matrix, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8aca7c07-906c-423d-a49a-0a0f744533e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_hypothetical_document_embedding_list = average_hypothetical_document_embedding.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f96c712b-51e3-446e-b337-f075e5fd3d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now find tok_k relvant docs for this query\n",
    "## https://api.python.langchain.com/en/v0.1/vectorstores/langchain_community.vectorstores.chroma.Chroma.html#langchain_community.vectorstores.chroma.Chroma.asimilarity_search_by_vector\n",
    "hyde_relevant_documents = await vectorstore.asimilarity_search_by_vector(average_hypothetical_document_embedding_list, k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6f82b31a-506f-4055-abfd-e025281e5ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_hyde_generation_template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\"\"\"\n",
    "final_hyde_generation_prompt = ChatPromptTemplate.from_template(final_hyde_generation_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "448736ef-a109-4cec-9ae6-372ff6f467d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_hyde_generation_chain = {\"context\": itemgetter(\"context\"), \"question\": itemgetter(\"question\")} | final_hyde_generation_prompt | local_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0c740e9a-5f5e-43c5-b58a-d10d600e0215",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableLambda] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableLambda] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"What is task decomposition for LLM agents?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question>] [3ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Answer the following question based on this context:\\n\\n[Document(page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\\\nComponent One: Planning#\\\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\\\nTask Decomposition#\\\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to think step by step to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the models thinking process.\\\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\\\nTask decomposition can be done (1) by LLM with simple prompting like \\\"Steps for XYZ.\\\\\\\\n1.\\\", \\\"What are the subgoals for achieving XYZ?\\\", (2) by using task-specific instructions; e.g. \\\"Write a story outline.\\\" for writing a novel, or (3) with human inputs.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}), Document(page_content='LLM Powered Autonomous Agents\\\\n    \\\\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\\\n\\\\n\\\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview#\\\\nIn a LLM-powered autonomous agent system, LLM functions as the agents brain, complemented by several key components:\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}), Document(page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\\\n\\\\n\\\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\\\n\\\\n\\\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\\\n\\\\n\\\\nCitation#\\\\nCited as:\\\\n\\\\nWeng, Lilian. (Jun 2023). LLM-powered Autonomous Agents. LilLog. https://lilianweng.github.io/posts/2023-06-23-agent/.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}), Document(page_content='Or\\\\n@article{weng2023agent,\\\\n  title   = \\\"LLM-powered Autonomous Agents\\\",\\\\n  author  = \\\"Weng, Lilian\\\",\\\\n  journal = \\\"lilianweng.github.io\\\",\\\\n  year    = \\\"2023\\\",\\\\n  month   = \\\"Jun\\\",\\\\n  url     = \\\"https://lilianweng.github.io/posts/2023-06-23-agent/\\\"\\\\n}\\\\nReferences#\\\\n[1] Wei et al. Chain of thought prompting elicits reasoning in large language models. NeurIPS 2022\\\\n[2] Yao et al. Tree of Thoughts: Dliberate Problem Solving with Large Language Models. arXiv preprint arXiv:2305.10601 (2023).\\\\n[3] Liu et al. Chain of Hindsight Aligns Language Models with Feedback\\\\n arXiv preprint arXiv:2302.02676 (2023).\\\\n[4] Liu et al. LLM+P: Empowering Large Language Models with Optimal Planning Proficiency arXiv preprint arXiv:2304.11477 (2023).', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'})]\\n\\nQuestion: What is task decomposition for LLM agents?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [18.83s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\\nTask decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex tasks into smaller, manageable subtasks or steps. This process is essential for LLMs to handle complex tasks efficiently and effectively. Task decomposition can be done in various ways, including:\\n\\n1. Simple prompting: Providing simple instructions or prompts to the LLM to break down a task into smaller subtasks. For example, \\\"Steps for XYZ\\\" or \\\"What are the subgoals for achieving XYZ?\\\"\\n2. Using task-specific instructions: Providing specific instructions or templates for each task to help the LLM understand what is required. For example, \\\"Write a story outline\\\" for writing a novel.\\n3. Human inputs: Allowing humans to provide input or guidance during the task decomposition process. This can be useful when dealing with tasks that require creativity or nuanced decision-making.\\n\\nTask decomposition helps LLMs in several ways:\\n\\n1. Improved efficiency: By breaking down complex tasks into smaller subtasks, the LLM can handle them more efficiently and quickly.\\n2. Better handling of unexpected errors: When faced with unexpected errors, LLMs can adjust their plans more effectively when they have a clear understanding of the task decomposition.\\n3. Enhanced reliability: With a clear understanding of the task decomposition, the LLM can provide more accurate and reliable outputs.\\n4. Improved learning: By breaking down tasks into smaller subtasks, the LLM can learn from each step of the process, leading to improved performance over time.\\n\\nIn summary, task decomposition is an essential aspect of LLM agents' functionality, allowing them to handle complex tasks efficiently and effectively by breaking them down into manageable subtasks or steps.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama2:latest\",\n",
      "          \"created_at\": \"2024-06-18T20:25:28.486488Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 18825741333,\n",
      "          \"load_duration\": 1610208,\n",
      "          \"prompt_eval_count\": 1417,\n",
      "          \"prompt_eval_duration\": 5306431000,\n",
      "          \"eval_count\": 376,\n",
      "          \"eval_duration\": 13508894000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\\nTask decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex tasks into smaller, manageable subtasks or steps. This process is essential for LLMs to handle complex tasks efficiently and effectively. Task decomposition can be done in various ways, including:\\n\\n1. Simple prompting: Providing simple instructions or prompts to the LLM to break down a task into smaller subtasks. For example, \\\"Steps for XYZ\\\" or \\\"What are the subgoals for achieving XYZ?\\\"\\n2. Using task-specific instructions: Providing specific instructions or templates for each task to help the LLM understand what is required. For example, \\\"Write a story outline\\\" for writing a novel.\\n3. Human inputs: Allowing humans to provide input or guidance during the task decomposition process. This can be useful when dealing with tasks that require creativity or nuanced decision-making.\\n\\nTask decomposition helps LLMs in several ways:\\n\\n1. Improved efficiency: By breaking down complex tasks into smaller subtasks, the LLM can handle them more efficiently and quickly.\\n2. Better handling of unexpected errors: When faced with unexpected errors, LLMs can adjust their plans more effectively when they have a clear understanding of the task decomposition.\\n3. Enhanced reliability: With a clear understanding of the task decomposition, the LLM can provide more accurate and reliable outputs.\\n4. Improved learning: By breaking down tasks into smaller subtasks, the LLM can learn from each step of the process, leading to improved performance over time.\\n\\nIn summary, task decomposition is an essential aspect of LLM agents' functionality, allowing them to handle complex tasks efficiently and effectively by breaking them down into manageable subtasks or steps.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama2:latest\",\n",
      "              \"created_at\": \"2024-06-18T20:25:28.486488Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 18825741333,\n",
      "              \"load_duration\": 1610208,\n",
      "              \"prompt_eval_count\": 1417,\n",
      "              \"prompt_eval_duration\": 5306431000,\n",
      "              \"eval_count\": 376,\n",
      "              \"eval_duration\": 13508894000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-2fbb52bd-059f-47e0-bb2e-976683b402f7-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [2ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"\\nTask decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex tasks into smaller, manageable subtasks or steps. This process is essential for LLMs to handle complex tasks efficiently and effectively. Task decomposition can be done in various ways, including:\\n\\n1. Simple prompting: Providing simple instructions or prompts to the LLM to break down a task into smaller subtasks. For example, \\\"Steps for XYZ\\\" or \\\"What are the subgoals for achieving XYZ?\\\"\\n2. Using task-specific instructions: Providing specific instructions or templates for each task to help the LLM understand what is required. For example, \\\"Write a story outline\\\" for writing a novel.\\n3. Human inputs: Allowing humans to provide input or guidance during the task decomposition process. This can be useful when dealing with tasks that require creativity or nuanced decision-making.\\n\\nTask decomposition helps LLMs in several ways:\\n\\n1. Improved efficiency: By breaking down complex tasks into smaller subtasks, the LLM can handle them more efficiently and quickly.\\n2. Better handling of unexpected errors: When faced with unexpected errors, LLMs can adjust their plans more effectively when they have a clear understanding of the task decomposition.\\n3. Enhanced reliability: With a clear understanding of the task decomposition, the LLM can provide more accurate and reliable outputs.\\n4. Improved learning: By breaking down tasks into smaller subtasks, the LLM can learn from each step of the process, leading to improved performance over time.\\n\\nIn summary, task decomposition is an essential aspect of LLM agents' functionality, allowing them to handle complex tasks efficiently and effectively by breaking them down into manageable subtasks or steps.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [18.84s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"\\nTask decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex tasks into smaller, manageable subtasks or steps. This process is essential for LLMs to handle complex tasks efficiently and effectively. Task decomposition can be done in various ways, including:\\n\\n1. Simple prompting: Providing simple instructions or prompts to the LLM to break down a task into smaller subtasks. For example, \\\"Steps for XYZ\\\" or \\\"What are the subgoals for achieving XYZ?\\\"\\n2. Using task-specific instructions: Providing specific instructions or templates for each task to help the LLM understand what is required. For example, \\\"Write a story outline\\\" for writing a novel.\\n3. Human inputs: Allowing humans to provide input or guidance during the task decomposition process. This can be useful when dealing with tasks that require creativity or nuanced decision-making.\\n\\nTask decomposition helps LLMs in several ways:\\n\\n1. Improved efficiency: By breaking down complex tasks into smaller subtasks, the LLM can handle them more efficiently and quickly.\\n2. Better handling of unexpected errors: When faced with unexpected errors, LLMs can adjust their plans more effectively when they have a clear understanding of the task decomposition.\\n3. Enhanced reliability: With a clear understanding of the task decomposition, the LLM can provide more accurate and reliable outputs.\\n4. Improved learning: By breaking down tasks into smaller subtasks, the LLM can learn from each step of the process, leading to improved performance over time.\\n\\nIn summary, task decomposition is an essential aspect of LLM agents' functionality, allowing them to handle complex tasks efficiently and effectively by breaking them down into manageable subtasks or steps.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "hyde_generated_response = await final_hyde_generation_chain.ainvoke({\"context\": hyde_relevant_documents, \"question\": \"What is task decomposition for LLM agents?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6be10907-3d71-4dc4-9889-4c1ef899a467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex tasks into smaller, manageable subtasks or steps. This process is essential for LLMs to handle complex tasks efficiently and effectively. Task decomposition can be done in various ways, including:\n",
      "\n",
      "1. Simple prompting: Providing simple instructions or prompts to the LLM to break down a task into smaller subtasks. For example, \"Steps for XYZ\" or \"What are the subgoals for achieving XYZ?\"\n",
      "2. Using task-specific instructions: Providing specific instructions or templates for each task to help the LLM understand what is required. For example, \"Write a story outline\" for writing a novel.\n",
      "3. Human inputs: Allowing humans to provide input or guidance during the task decomposition process. This can be useful when dealing with tasks that require creativity or nuanced decision-making.\n",
      "\n",
      "Task decomposition helps LLMs in several ways:\n",
      "\n",
      "1. Improved efficiency: By breaking down complex tasks into smaller subtasks, the LLM can handle them more efficiently and quickly.\n",
      "2. Better handling of unexpected errors: When faced with unexpected errors, LLMs can adjust their plans more effectively when they have a clear understanding of the task decomposition.\n",
      "3. Enhanced reliability: With a clear understanding of the task decomposition, the LLM can provide more accurate and reliable outputs.\n",
      "4. Improved learning: By breaking down tasks into smaller subtasks, the LLM can learn from each step of the process, leading to improved performance over time.\n",
      "\n",
      "In summary, task decomposition is an essential aspect of LLM agents' functionality, allowing them to handle complex tasks efficiently and effectively by breaking them down into manageable subtasks or steps.\n"
     ]
    }
   ],
   "source": [
    "print(hyde_generated_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e065d82b-9291-4216-ad09-6f52423e5b65",
   "metadata": {},
   "source": [
    "# Part3: https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_10_and_11.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29864f96-fb78-4149-873c-3ac873f149e1",
   "metadata": {},
   "source": [
    "## ROUTING: Get query to the correct source. 2 types:\n",
    "1. Logical routing: Route query to correct retreiver/ database e.g. vecotr db, graph db etc (via structured functions as LLM output). Consider it as a classification system that given the query, returns the db system to be used for query answering\n",
    "2. Semantic routing: Embed multiple prompts and query using same embedder and choose the prompt that has highest similarity with query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fef34e-a562-4c53-8c3d-ef25ba73763e",
   "metadata": {},
   "source": [
    "## 1. Logical routing: Use function-calling for classification (LLM for classification with structured output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1501cf-3612-4d5c-b20d-4d59ab426c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Create a class/ data model that will be the output of LLM\n",
    "\n",
    "# class RouteQuery(BaseModel):\n",
    "#     datasource: Literal[\"python_docs\", \"js_docs\", \"golang_docs\"] = Field(description=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "3102eac2-81cb-4d16-8d6b-87650d6b9109",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Understandinfg use of pydantic to create Data model to which the output of LLM should confootm to\n",
    "## https://python.langchain.com/v0.1/docs/modules/model_io/output_parsers/types/pydantic/\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to setup a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "joke_query = \"Tell me a joke\"\n",
    "joke_parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "joke_prompt = PromptTemplate(template = \"Answer the user query. \\n{format_instructions}\\n{query}\\n\", input_variables=[\"query\"], partial_variables={\"format_instructions\": joke_parser.get_format_instructions()})\n",
    "#structured_local_llm = local_llm.with_structured_output(BaseModel)\n",
    "joke_chain = joke_prompt | local_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "d00ded02-e4da-40c8-9dca-b0b366cc39fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#joke_prompt.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "9e46a934-e29f-4b75-ad26-511d4df332bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joke_template = \"\"\"You are a great comedian who makes scientific jokes. You tell jokes according to the question asked below.\\n\n",
    "# question: {question}\n",
    "# Answer:\"\"\"\n",
    "\n",
    "# simple_joke_chain = {\"question\": RunnablePassthrough()} | ChatPromptTemplate.from_template(joke_template) | local_llm |StrOutputParser()\n",
    "\n",
    "# simple_joke = simple_joke_chain.invoke(\"Tell me a joke related to plants\")\n",
    "\n",
    "# print(simple_joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "07d5b910-de7f-4cdd-9ab3-f6e64ef45152",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"Tell me a joke\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"Tell me a joke\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Answer the user query. \\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\\\"properties\\\": {\\\"foo\\\": {\\\"title\\\": \\\"Foo\\\", \\\"description\\\": \\\"a list of strings\\\", \\\"type\\\": \\\"array\\\", \\\"items\\\": {\\\"type\\\": \\\"string\\\"}}}, \\\"required\\\": [\\\"foo\\\"]}\\nthe object {\\\"foo\\\": [\\\"bar\\\", \\\"baz\\\"]} is a well-formatted instance of the schema. The object {\\\"properties\\\": {\\\"foo\\\": [\\\"bar\\\", \\\"baz\\\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\\\"properties\\\": {\\\"setup\\\": {\\\"title\\\": \\\"Setup\\\", \\\"description\\\": \\\"question to setup a joke\\\", \\\"type\\\": \\\"string\\\"}, \\\"punchline\\\": {\\\"title\\\": \\\"Punchline\\\", \\\"description\\\": \\\"answer to resolve the joke\\\", \\\"type\\\": \\\"string\\\"}}, \\\"required\\\": [\\\"setup\\\", \\\"punchline\\\"]}\\n```\\nTell me a joke\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [4.16s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \" Sure, here is a well-formatted JSON instance that conforms to the schema you provided:\\n\\n{\\n\\\"properties\\\": {\\n\\\"setup\\\": {\\\"title\\\": \\\"Setup\\\", \\\"description\\\": \\\"question to setup a joke\\\", \\\"type\\\": \\\"string\\\"},\\n\\\"punchline\\\": {\\\"title\\\": \\\"Punchline\\\", \\\"description\\\": \\\"answer to resolve the joke\\\", \\\"type\\\": \\\"string\\\"}\\n},\\n\\\"required\\\": [\\\"setup\\\", \\\"punchline\\\"]\\n}\\n\\nAs for the joke, here is one:\\n\\nWhy was the math book sad?\\n\\nBecause it had too many problems!\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama2:latest\",\n",
      "          \"created_at\": \"2024-06-20T21:08:25.926807Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 4154331917,\n",
      "          \"load_duration\": 3832708,\n",
      "          \"prompt_eval_duration\": 354321000,\n",
      "          \"eval_count\": 134,\n",
      "          \"eval_duration\": 3792161000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \" Sure, here is a well-formatted JSON instance that conforms to the schema you provided:\\n\\n{\\n\\\"properties\\\": {\\n\\\"setup\\\": {\\\"title\\\": \\\"Setup\\\", \\\"description\\\": \\\"question to setup a joke\\\", \\\"type\\\": \\\"string\\\"},\\n\\\"punchline\\\": {\\\"title\\\": \\\"Punchline\\\", \\\"description\\\": \\\"answer to resolve the joke\\\", \\\"type\\\": \\\"string\\\"}\\n},\\n\\\"required\\\": [\\\"setup\\\", \\\"punchline\\\"]\\n}\\n\\nAs for the joke, here is one:\\n\\nWhy was the math book sad?\\n\\nBecause it had too many problems!\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama2:latest\",\n",
      "              \"created_at\": \"2024-06-20T21:08:25.926807Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 4154331917,\n",
      "              \"load_duration\": 3832708,\n",
      "              \"prompt_eval_duration\": 354321000,\n",
      "              \"eval_count\": 134,\n",
      "              \"eval_duration\": 3792161000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-dc28df34-54db-4f68-a394-8dce4c91b48e-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \" Sure, here is a well-formatted JSON instance that conforms to the schema you provided:\\n\\n{\\n\\\"properties\\\": {\\n\\\"setup\\\": {\\\"title\\\": \\\"Setup\\\", \\\"description\\\": \\\"question to setup a joke\\\", \\\"type\\\": \\\"string\\\"},\\n\\\"punchline\\\": {\\\"title\\\": \\\"Punchline\\\", \\\"description\\\": \\\"answer to resolve the joke\\\", \\\"type\\\": \\\"string\\\"}\\n},\\n\\\"required\\\": [\\\"setup\\\", \\\"punchline\\\"]\\n}\\n\\nAs for the joke, here is one:\\n\\nWhy was the math book sad?\\n\\nBecause it had too many problems!\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [4.17s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \" Sure, here is a well-formatted JSON instance that conforms to the schema you provided:\\n\\n{\\n\\\"properties\\\": {\\n\\\"setup\\\": {\\\"title\\\": \\\"Setup\\\", \\\"description\\\": \\\"question to setup a joke\\\", \\\"type\\\": \\\"string\\\"},\\n\\\"punchline\\\": {\\\"title\\\": \\\"Punchline\\\", \\\"description\\\": \\\"answer to resolve the joke\\\", \\\"type\\\": \\\"string\\\"}\\n},\\n\\\"required\\\": [\\\"setup\\\", \\\"punchline\\\"]\\n}\\n\\nAs for the joke, here is one:\\n\\nWhy was the math book sad?\\n\\nBecause it had too many problems!\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "res = joke_chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "719d6a62-39db-43aa-a250-e0be1f83cab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sure, here is a well-formatted JSON instance that conforms to the schema you provided:\n",
      "\n",
      "{\n",
      "\"properties\": {\n",
      "\"setup\": {\"title\": \"Setup\", \"description\": \"question to setup a joke\", \"type\": \"string\"},\n",
      "\"punchline\": {\"title\": \"Punchline\", \"description\": \"answer to resolve the joke\", \"type\": \"string\"}\n",
      "},\n",
      "\"required\": [\"setup\", \"punchline\"]\n",
      "}\n",
      "\n",
      "As for the joke, here is one:\n",
      "\n",
      "Why was the math book sad?\n",
      "\n",
      "Because it had too many problems!\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05111181-ab4b-4ada-ad73-84403a33b45a",
   "metadata": {},
   "source": [
    "## LLama 2 model is not able to follow the datamodel. Atleast that is what I could understand. This might work with ChatGPT based LLMs.\n",
    "## Check https://python.langchain.com/v0.1/docs/modules/model_io/chat/structured_output/#groq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1346e7a-eda7-4e49-85a0-df30f94cea80",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Doing function calling with open source local models like llama are experimental in langchain till now.\n",
    "## https://api.python.langchain.com/en/latest/llms/langchain_experimental.llms.ollama_functions.OllamaFunctions.html#langchain_experimental.llms.ollama_functions.OllamaFunctions\n",
    "## Video to explain function calling in LLama models: https://www.youtube.com/watch?v=Ss_GdU0KqE0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9effad5-7d64-457b-a75b-4369c5f73347",
   "metadata": {},
   "source": [
    "## Experiment with Llama and Phi3 models for function calling: https://export.arxiv.org/pdf/2404.14219 in FunctionCallingWithLocalModels notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d9d934-a26e-4210-87b7-254baaf88e62",
   "metadata": {},
   "source": [
    "## Implement logical routing using langchain_experimental.llms.ollama_functions.OllamaFunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "783072f2-3357-4b8a-8ccb-25877c60ffeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RouteQuery(BaseModel):\n",
    "    datasource: Literal[\"python_docs\", \"js_docs\", \"golang_docs\"] = Field(description=\"Given a user question choose which datasource would be most relevant for answering their question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "02792fb7-c6e8-4092-81e3-7b20412234d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "experimental_local_llm = OllamaFunctions(model=\"llama2:latest\", format=\"json\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "d787452a-915e-4301-ac68-6928ce915678",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_experimental_local_llm = experimental_local_llm.with_structured_output(RouteQuery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "b69c7576-26bc-42ec-bd0f-aa2371d5368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "routing_messages = [\n",
    "    SystemMessage(content=\"You are an expert at routing a user question to the appropriate data source. Based on the programming language the question is referring to, route it to the relevant data source.\"),\n",
    "    HumanMessage(content=\"{query}\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "89fc01fc-80a4-4a92-b411-5c79b15f0bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=[] messages=[SystemMessage(content='You are an expert at routing a user question to the appropriate data source. Based on the programming language the question is referring to, route it to the relevant data source.'), HumanMessage(content='{query}')]\n"
     ]
    }
   ],
   "source": [
    "routing_prompt = ChatPromptTemplate.from_messages(routing_messages)\n",
    "print(routing_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "1a0cc91f-f30d-4054-8383-b083c774f158",
   "metadata": {},
   "outputs": [],
   "source": [
    "router = routing_prompt | structured_experimental_local_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "99a9c0c5-8d07-46c8-bb20-6fe0d9cd1cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"Why doesn't the following code work:\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\"human\", \"speak in {language}\"])\n",
    "prompt.invoke(\"french\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "4586260b-d606-4946-a2f3-6e9fc04030d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"Why doesn't the following code work:\\n\\nfrom langchain_core.prompts import ChatPromptTemplate\\n\\nprompt = ChatPromptTemplate.from_messages([\\\"human\\\", \\\"speak in {language}\\\"])\\nprompt.invoke(\\\"french\\\")\\n\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"Why doesn't the following code work:\\n\\nfrom langchain_core.prompts import ChatPromptTemplate\\n\\nprompt = ChatPromptTemplate.from_messages([\\\"human\\\", \\\"speak in {language}\\\"])\\nprompt.invoke(\\\"french\\\")\\n\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:OllamaFunctions] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are an expert at routing a user question to the appropriate data source. Based on the programming language the question is referring to, route it to the relevant data source.\\nHuman: {query}\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:OllamaFunctions] [2.59s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-a81ed14f-18e9-4de0-a60f-043725d60c7d-0\",\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"name\": \"RouteQuery\",\n",
      "                \"args\": {\n",
      "                  \"datasource\": \"python_docs\"\n",
      "                },\n",
      "                \"id\": \"call_c9d2d2b9c4244729b8e8b0a6f05866e8\"\n",
      "              }\n",
      "            ],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:parse_response] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:parse_response] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"{\\\"datasource\\\": \\\"python_docs\\\"}\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:PydanticOutputParser] Entering Parser run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"{\\\"datasource\\\": \\\"python_docs\\\"}\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:PydanticOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [2.60s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n"
     ]
    }
   ],
   "source": [
    "router_result = router.invoke({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "ecf88a34-8823-4dac-83a6-0bd5e72146ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RouteQuery(datasource='python_docs')"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RouteQuery.parse_obj(router_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6049cc44-54df-47e6-837d-09f0bd00c77d",
   "metadata": {},
   "source": [
    "## It appears as if Llama 2 model is not able to distinguish between coding languages. It is possible that it is not trained on code. But the concept of making LLM output confirm to a json/ data model is very critical concept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2372db-efd9-4c78-b638-78b2137324a7",
   "metadata": {},
   "source": [
    "## 2. Semantic routing: Choosing between multiple prompts based on similarity with the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "cbf5f747-4c36-4c59-bb55-fc4bb8966291",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{query}\"\"\"\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. You are great at answering math questions. \\\n",
    "You are so good because you are able to break down hard problems into their component parts, \\\n",
    "answer the component parts, and then put them together to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{query}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "60ea5f68-5595-44f6-bca2-1a4d44b16219",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_prompt_templates = [physics_template, math_template]\n",
    "multiple_prompt_embeddings = await embeddings.aembed_documents(multiple_prompt_templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e8f2c3cb-9292-48a7-b7ec-29b93b527235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_router(input_dict):\n",
    "    query_embedding = embeddings.embed_query(input_dict[\"query\"])\n",
    "    similarity = cosine_similarity([query_embedding], multiple_prompt_embeddings)[0]\n",
    "    most_similar = multiple_prompt_templates[similarity.argmax()]\n",
    "    print(f\"Using Math termplate\" if most_similar == math_template else \"Using Physics template\")\n",
    "    return ChatPromptTemplate.from_template(most_similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "29d5526b-4a50-4381-b66c-93447fdc4c8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Explain to me special theory of relativity\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<query>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Explain to me special theory of relativity\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<query> > chain:RunnablePassthrough] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Explain to me special theory of relativity\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<query> > chain:RunnablePassthrough] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Explain to me special theory of relativity\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<query>] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"query\": \"Explain to me special theory of relativity\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:prompt_router] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"Explain to me special theory of relativity\"\n",
      "}\n",
      "Using Physics template\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:prompt_router > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"Explain to me special theory of relativity\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:prompt_router > prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:prompt_router] [124ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a very smart physics professor. You are great at answering questions about physics in a concise and easy to understand manner. When you don't know the answer to a question you admit that you don't know.\\n\\nHere is a question:\\nExplain to me special theory of relativity\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [13.00s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Of course! The special theory of relativity, introduced by Albert Einstein in 1905, is a fundamental concept in modern physics that challenges our traditional understanding of space and time. Here's a brief explanation:\\n\\n1. Time dilation: According to the special theory of relativity, the passage of time is relative and can vary depending on the observer's frame of reference. The faster an object moves, the slower time passes for that object relative to a stationary observer. This means that time can appear to slow down or speed up depending on the observer's motion.\\n2. Length contraction: Einstein showed that objects appear shorter to an observer when they are moving at high speeds relative to the observer. The faster the object moves, the more it contracts in length. This means that the length of an object is not absolute, but rather depends on the observer's motion.\\n3. Relativity of simultaneity: Einstein demonstrated that the concept of \\\"now\\\" is relative and can vary depending on the observer's frame of reference. Two events that are simultaneous for one observer may not be simultaneous for another observer moving at a different speed. This challenges our intuitive understanding of time and space.\\n4. Equivalence of mass and energy: Einstein showed that mass and energy are interchangeable, and that the energy of an object is proportional to its mass. This idea has far-reaching implications in fields such as nuclear physics and astrophysics.\\n5. Lorentz transformations: Einstein developed a set of mathematical equations known as the Lorentz transformations, which describe how space and time are transformed for an observer moving at high speeds relative to a stationary observer. These transformations form the basis of modern relativity and are used to calculate the motion of objects in different reference frames.\\n\\nWhile I'm happy to help you understand the special theory of relativity, please keep in mind that it's a complex and abstract concept. If you have any specific questions or areas of confusion, feel free to ask!\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama2:latest\",\n",
      "          \"created_at\": \"2024-06-18T22:18:52.782874Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 12994213750,\n",
      "          \"load_duration\": 2665750,\n",
      "          \"prompt_eval_count\": 14,\n",
      "          \"prompt_eval_duration\": 463103000,\n",
      "          \"eval_count\": 435,\n",
      "          \"eval_duration\": 12526326000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Of course! The special theory of relativity, introduced by Albert Einstein in 1905, is a fundamental concept in modern physics that challenges our traditional understanding of space and time. Here's a brief explanation:\\n\\n1. Time dilation: According to the special theory of relativity, the passage of time is relative and can vary depending on the observer's frame of reference. The faster an object moves, the slower time passes for that object relative to a stationary observer. This means that time can appear to slow down or speed up depending on the observer's motion.\\n2. Length contraction: Einstein showed that objects appear shorter to an observer when they are moving at high speeds relative to the observer. The faster the object moves, the more it contracts in length. This means that the length of an object is not absolute, but rather depends on the observer's motion.\\n3. Relativity of simultaneity: Einstein demonstrated that the concept of \\\"now\\\" is relative and can vary depending on the observer's frame of reference. Two events that are simultaneous for one observer may not be simultaneous for another observer moving at a different speed. This challenges our intuitive understanding of time and space.\\n4. Equivalence of mass and energy: Einstein showed that mass and energy are interchangeable, and that the energy of an object is proportional to its mass. This idea has far-reaching implications in fields such as nuclear physics and astrophysics.\\n5. Lorentz transformations: Einstein developed a set of mathematical equations known as the Lorentz transformations, which describe how space and time are transformed for an observer moving at high speeds relative to a stationary observer. These transformations form the basis of modern relativity and are used to calculate the motion of objects in different reference frames.\\n\\nWhile I'm happy to help you understand the special theory of relativity, please keep in mind that it's a complex and abstract concept. If you have any specific questions or areas of confusion, feel free to ask!\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama2:latest\",\n",
      "              \"created_at\": \"2024-06-18T22:18:52.782874Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 12994213750,\n",
      "              \"load_duration\": 2665750,\n",
      "              \"prompt_eval_count\": 14,\n",
      "              \"prompt_eval_duration\": 463103000,\n",
      "              \"eval_count\": 435,\n",
      "              \"eval_duration\": 12526326000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-27119203-5007-4b2a-823d-e2bcaf604530-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Of course! The special theory of relativity, introduced by Albert Einstein in 1905, is a fundamental concept in modern physics that challenges our traditional understanding of space and time. Here's a brief explanation:\\n\\n1. Time dilation: According to the special theory of relativity, the passage of time is relative and can vary depending on the observer's frame of reference. The faster an object moves, the slower time passes for that object relative to a stationary observer. This means that time can appear to slow down or speed up depending on the observer's motion.\\n2. Length contraction: Einstein showed that objects appear shorter to an observer when they are moving at high speeds relative to the observer. The faster the object moves, the more it contracts in length. This means that the length of an object is not absolute, but rather depends on the observer's motion.\\n3. Relativity of simultaneity: Einstein demonstrated that the concept of \\\"now\\\" is relative and can vary depending on the observer's frame of reference. Two events that are simultaneous for one observer may not be simultaneous for another observer moving at a different speed. This challenges our intuitive understanding of time and space.\\n4. Equivalence of mass and energy: Einstein showed that mass and energy are interchangeable, and that the energy of an object is proportional to its mass. This idea has far-reaching implications in fields such as nuclear physics and astrophysics.\\n5. Lorentz transformations: Einstein developed a set of mathematical equations known as the Lorentz transformations, which describe how space and time are transformed for an observer moving at high speeds relative to a stationary observer. These transformations form the basis of modern relativity and are used to calculate the motion of objects in different reference frames.\\n\\nWhile I'm happy to help you understand the special theory of relativity, please keep in mind that it's a complex and abstract concept. If you have any specific questions or areas of confusion, feel free to ask!\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [13.13s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Of course! The special theory of relativity, introduced by Albert Einstein in 1905, is a fundamental concept in modern physics that challenges our traditional understanding of space and time. Here's a brief explanation:\\n\\n1. Time dilation: According to the special theory of relativity, the passage of time is relative and can vary depending on the observer's frame of reference. The faster an object moves, the slower time passes for that object relative to a stationary observer. This means that time can appear to slow down or speed up depending on the observer's motion.\\n2. Length contraction: Einstein showed that objects appear shorter to an observer when they are moving at high speeds relative to the observer. The faster the object moves, the more it contracts in length. This means that the length of an object is not absolute, but rather depends on the observer's motion.\\n3. Relativity of simultaneity: Einstein demonstrated that the concept of \\\"now\\\" is relative and can vary depending on the observer's frame of reference. Two events that are simultaneous for one observer may not be simultaneous for another observer moving at a different speed. This challenges our intuitive understanding of time and space.\\n4. Equivalence of mass and energy: Einstein showed that mass and energy are interchangeable, and that the energy of an object is proportional to its mass. This idea has far-reaching implications in fields such as nuclear physics and astrophysics.\\n5. Lorentz transformations: Einstein developed a set of mathematical equations known as the Lorentz transformations, which describe how space and time are transformed for an observer moving at high speeds relative to a stationary observer. These transformations form the basis of modern relativity and are used to calculate the motion of objects in different reference frames.\\n\\nWhile I'm happy to help you understand the special theory of relativity, please keep in mind that it's a complex and abstract concept. If you have any specific questions or areas of confusion, feel free to ask!\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "semantic_router_chain = {\"query\": RunnablePassthrough()} | RunnableLambda(prompt_router) | local_llm | StrOutputParser()\n",
    "semantic_router_result = semantic_router_chain.invoke(\"Explain to me special theory of relativity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "65f6d47a-b665-40f6-aa69-6339bdab705c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! The special theory of relativity, introduced by Albert Einstein in 1905, is a fundamental concept in modern physics that challenges our traditional understanding of space and time. Here's a brief explanation:\n",
      "\n",
      "1. Time dilation: According to the special theory of relativity, the passage of time is relative and can vary depending on the observer's frame of reference. The faster an object moves, the slower time passes for that object relative to a stationary observer. This means that time can appear to slow down or speed up depending on the observer's motion.\n",
      "2. Length contraction: Einstein showed that objects appear shorter to an observer when they are moving at high speeds relative to the observer. The faster the object moves, the more it contracts in length. This means that the length of an object is not absolute, but rather depends on the observer's motion.\n",
      "3. Relativity of simultaneity: Einstein demonstrated that the concept of \"now\" is relative and can vary depending on the observer's frame of reference. Two events that are simultaneous for one observer may not be simultaneous for another observer moving at a different speed. This challenges our intuitive understanding of time and space.\n",
      "4. Equivalence of mass and energy: Einstein showed that mass and energy are interchangeable, and that the energy of an object is proportional to its mass. This idea has far-reaching implications in fields such as nuclear physics and astrophysics.\n",
      "5. Lorentz transformations: Einstein developed a set of mathematical equations known as the Lorentz transformations, which describe how space and time are transformed for an observer moving at high speeds relative to a stationary observer. These transformations form the basis of modern relativity and are used to calculate the motion of objects in different reference frames.\n",
      "\n",
      "While I'm happy to help you understand the special theory of relativity, please keep in mind that it's a complex and abstract concept. If you have any specific questions or areas of confusion, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "print(semantic_router_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "52147fb3-16fd-42e2-a4fe-a2a3ed621ee3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Explain me the concept of imaginary numbers\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<query>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Explain me the concept of imaginary numbers\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<query> > chain:RunnablePassthrough] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Explain me the concept of imaginary numbers\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<query> > chain:RunnablePassthrough] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Explain me the concept of imaginary numbers\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<query>] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"query\": \"Explain me the concept of imaginary numbers\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:prompt_router] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"Explain me the concept of imaginary numbers\"\n",
      "}\n",
      "Using Math termplate\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:prompt_router > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"Explain me the concept of imaginary numbers\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:prompt_router > prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:prompt_router] [71ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a very good mathematician. You are great at answering math questions. You are so good because you are able to break down hard problems into their component parts, answer the component parts, and then put them together to answer the broader question.\\n\\nHere is a question:\\nExplain me the concept of imaginary numbers\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [16.22s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\\nThank you for your kind words! I'm glad to help you understand the concept of imaginary numbers. Imaginary numbers are a mathematical concept that extends the real number system to include numbers that can be expressed as a multiple of the imaginary unit, i.e., $i = \\\\sqrt{-1}$. In other words, imaginary numbers are numbers that have an imaginary part, which is denoted by the letter $i$.\\n\\nThe concept of imaginary numbers was first introduced by Italian mathematician Girolamo Cardano in the 16th century, and it has since become a fundamental aspect of mathematics, particularly in the fields of algebra, calculus, and quantum mechanics.\\n\\nTo understand the concept of imaginary numbers, let's consider a simple example. Suppose you have a real number, $x$, and you want to find its square. You can do this by using the usual squaring operation, which gives you $x^2$. However, if you try to square an imaginary number, such as $i$, you will get an answer that is also imaginary. This is because the squaring operation for complex numbers is defined as $(a + bi)^2 = a^2 - b^2 + 2ab \\\\cdot i$, where $a$ and $b$ are the real and imaginary parts of the complex number, respectively.\\n\\nAs you can see, the imaginary part of the complex number, $i$, plays a crucial role in this operation. It allows us to square complex numbers and obtain an imaginary result, which is essential in many mathematical applications.\\n\\nNow, you might be wondering why we need imaginary numbers in mathematics. The answer is that they provide us with a way to represent certain quantities that cannot be expressed using real numbers alone. For example, in electrical circuits, we often encounter AC (alternating current) waves, which have an imaginary component in addition to the real component. Imaginary numbers allow us to analyze and solve problems involving AC waves in a more straightforward manner.\\n\\nSimilarly, in quantum mechanics, particles can have both real and imaginary energies, which are essential for understanding their behavior and properties. Without imaginary numbers, we would not be able to describe these phenomena accurately.\\n\\nIn conclusion, the concept of imaginary numbers is a fundamental aspect of mathematics that allows us to represent quantities that cannot be expressed using real numbers alone. They provide us with a way to solve complex problems in various fields, including algebra, calculus, and quantum mechanics.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama2:latest\",\n",
      "          \"created_at\": \"2024-06-18T22:20:37.097591Z\",\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\"\n",
      "          },\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"done\": true,\n",
      "          \"total_duration\": 16212833583,\n",
      "          \"load_duration\": 3656958,\n",
      "          \"prompt_eval_count\": 70,\n",
      "          \"prompt_eval_duration\": 557632000,\n",
      "          \"eval_count\": 536,\n",
      "          \"eval_duration\": 15647874000\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\\nThank you for your kind words! I'm glad to help you understand the concept of imaginary numbers. Imaginary numbers are a mathematical concept that extends the real number system to include numbers that can be expressed as a multiple of the imaginary unit, i.e., $i = \\\\sqrt{-1}$. In other words, imaginary numbers are numbers that have an imaginary part, which is denoted by the letter $i$.\\n\\nThe concept of imaginary numbers was first introduced by Italian mathematician Girolamo Cardano in the 16th century, and it has since become a fundamental aspect of mathematics, particularly in the fields of algebra, calculus, and quantum mechanics.\\n\\nTo understand the concept of imaginary numbers, let's consider a simple example. Suppose you have a real number, $x$, and you want to find its square. You can do this by using the usual squaring operation, which gives you $x^2$. However, if you try to square an imaginary number, such as $i$, you will get an answer that is also imaginary. This is because the squaring operation for complex numbers is defined as $(a + bi)^2 = a^2 - b^2 + 2ab \\\\cdot i$, where $a$ and $b$ are the real and imaginary parts of the complex number, respectively.\\n\\nAs you can see, the imaginary part of the complex number, $i$, plays a crucial role in this operation. It allows us to square complex numbers and obtain an imaginary result, which is essential in many mathematical applications.\\n\\nNow, you might be wondering why we need imaginary numbers in mathematics. The answer is that they provide us with a way to represent certain quantities that cannot be expressed using real numbers alone. For example, in electrical circuits, we often encounter AC (alternating current) waves, which have an imaginary component in addition to the real component. Imaginary numbers allow us to analyze and solve problems involving AC waves in a more straightforward manner.\\n\\nSimilarly, in quantum mechanics, particles can have both real and imaginary energies, which are essential for understanding their behavior and properties. Without imaginary numbers, we would not be able to describe these phenomena accurately.\\n\\nIn conclusion, the concept of imaginary numbers is a fundamental aspect of mathematics that allows us to represent quantities that cannot be expressed using real numbers alone. They provide us with a way to solve complex problems in various fields, including algebra, calculus, and quantum mechanics.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama2:latest\",\n",
      "              \"created_at\": \"2024-06-18T22:20:37.097591Z\",\n",
      "              \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\"\n",
      "              },\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"done\": true,\n",
      "              \"total_duration\": 16212833583,\n",
      "              \"load_duration\": 3656958,\n",
      "              \"prompt_eval_count\": 70,\n",
      "              \"prompt_eval_duration\": 557632000,\n",
      "              \"eval_count\": 536,\n",
      "              \"eval_duration\": 15647874000\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-aada6a50-5390-44b1-a2b0-0ba881ddfcfd-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"\\nThank you for your kind words! I'm glad to help you understand the concept of imaginary numbers. Imaginary numbers are a mathematical concept that extends the real number system to include numbers that can be expressed as a multiple of the imaginary unit, i.e., $i = \\\\sqrt{-1}$. In other words, imaginary numbers are numbers that have an imaginary part, which is denoted by the letter $i$.\\n\\nThe concept of imaginary numbers was first introduced by Italian mathematician Girolamo Cardano in the 16th century, and it has since become a fundamental aspect of mathematics, particularly in the fields of algebra, calculus, and quantum mechanics.\\n\\nTo understand the concept of imaginary numbers, let's consider a simple example. Suppose you have a real number, $x$, and you want to find its square. You can do this by using the usual squaring operation, which gives you $x^2$. However, if you try to square an imaginary number, such as $i$, you will get an answer that is also imaginary. This is because the squaring operation for complex numbers is defined as $(a + bi)^2 = a^2 - b^2 + 2ab \\\\cdot i$, where $a$ and $b$ are the real and imaginary parts of the complex number, respectively.\\n\\nAs you can see, the imaginary part of the complex number, $i$, plays a crucial role in this operation. It allows us to square complex numbers and obtain an imaginary result, which is essential in many mathematical applications.\\n\\nNow, you might be wondering why we need imaginary numbers in mathematics. The answer is that they provide us with a way to represent certain quantities that cannot be expressed using real numbers alone. For example, in electrical circuits, we often encounter AC (alternating current) waves, which have an imaginary component in addition to the real component. Imaginary numbers allow us to analyze and solve problems involving AC waves in a more straightforward manner.\\n\\nSimilarly, in quantum mechanics, particles can have both real and imaginary energies, which are essential for understanding their behavior and properties. Without imaginary numbers, we would not be able to describe these phenomena accurately.\\n\\nIn conclusion, the concept of imaginary numbers is a fundamental aspect of mathematics that allows us to represent quantities that cannot be expressed using real numbers alone. They provide us with a way to solve complex problems in various fields, including algebra, calculus, and quantum mechanics.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [16.30s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"\\nThank you for your kind words! I'm glad to help you understand the concept of imaginary numbers. Imaginary numbers are a mathematical concept that extends the real number system to include numbers that can be expressed as a multiple of the imaginary unit, i.e., $i = \\\\sqrt{-1}$. In other words, imaginary numbers are numbers that have an imaginary part, which is denoted by the letter $i$.\\n\\nThe concept of imaginary numbers was first introduced by Italian mathematician Girolamo Cardano in the 16th century, and it has since become a fundamental aspect of mathematics, particularly in the fields of algebra, calculus, and quantum mechanics.\\n\\nTo understand the concept of imaginary numbers, let's consider a simple example. Suppose you have a real number, $x$, and you want to find its square. You can do this by using the usual squaring operation, which gives you $x^2$. However, if you try to square an imaginary number, such as $i$, you will get an answer that is also imaginary. This is because the squaring operation for complex numbers is defined as $(a + bi)^2 = a^2 - b^2 + 2ab \\\\cdot i$, where $a$ and $b$ are the real and imaginary parts of the complex number, respectively.\\n\\nAs you can see, the imaginary part of the complex number, $i$, plays a crucial role in this operation. It allows us to square complex numbers and obtain an imaginary result, which is essential in many mathematical applications.\\n\\nNow, you might be wondering why we need imaginary numbers in mathematics. The answer is that they provide us with a way to represent certain quantities that cannot be expressed using real numbers alone. For example, in electrical circuits, we often encounter AC (alternating current) waves, which have an imaginary component in addition to the real component. Imaginary numbers allow us to analyze and solve problems involving AC waves in a more straightforward manner.\\n\\nSimilarly, in quantum mechanics, particles can have both real and imaginary energies, which are essential for understanding their behavior and properties. Without imaginary numbers, we would not be able to describe these phenomena accurately.\\n\\nIn conclusion, the concept of imaginary numbers is a fundamental aspect of mathematics that allows us to represent quantities that cannot be expressed using real numbers alone. They provide us with a way to solve complex problems in various fields, including algebra, calculus, and quantum mechanics.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "maths_router_result = semantic_router_chain.invoke(\"Explain me the concept of imaginary numbers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d6c6eecd-b1db-4343-9508-02d59ef73b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thank you for your kind words! I'm glad to help you understand the concept of imaginary numbers. Imaginary numbers are a mathematical concept that extends the real number system to include numbers that can be expressed as a multiple of the imaginary unit, i.e., $i = \\sqrt{-1}$. In other words, imaginary numbers are numbers that have an imaginary part, which is denoted by the letter $i$.\n",
      "\n",
      "The concept of imaginary numbers was first introduced by Italian mathematician Girolamo Cardano in the 16th century, and it has since become a fundamental aspect of mathematics, particularly in the fields of algebra, calculus, and quantum mechanics.\n",
      "\n",
      "To understand the concept of imaginary numbers, let's consider a simple example. Suppose you have a real number, $x$, and you want to find its square. You can do this by using the usual squaring operation, which gives you $x^2$. However, if you try to square an imaginary number, such as $i$, you will get an answer that is also imaginary. This is because the squaring operation for complex numbers is defined as $(a + bi)^2 = a^2 - b^2 + 2ab \\cdot i$, where $a$ and $b$ are the real and imaginary parts of the complex number, respectively.\n",
      "\n",
      "As you can see, the imaginary part of the complex number, $i$, plays a crucial role in this operation. It allows us to square complex numbers and obtain an imaginary result, which is essential in many mathematical applications.\n",
      "\n",
      "Now, you might be wondering why we need imaginary numbers in mathematics. The answer is that they provide us with a way to represent certain quantities that cannot be expressed using real numbers alone. For example, in electrical circuits, we often encounter AC (alternating current) waves, which have an imaginary component in addition to the real component. Imaginary numbers allow us to analyze and solve problems involving AC waves in a more straightforward manner.\n",
      "\n",
      "Similarly, in quantum mechanics, particles can have both real and imaginary energies, which are essential for understanding their behavior and properties. Without imaginary numbers, we would not be able to describe these phenomena accurately.\n",
      "\n",
      "In conclusion, the concept of imaginary numbers is a fundamental aspect of mathematics that allows us to represent quantities that cannot be expressed using real numbers alone. They provide us with a way to solve complex problems in various fields, including algebra, calculus, and quantum mechanics.\n"
     ]
    }
   ],
   "source": [
    "print(maths_router_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6a915b-15e3-4621-9972-0c30d7d921f1",
   "metadata": {},
   "source": [
    "## QUERY CONSTRUCTION: Based on the database used (vectorDb/ GraphDb etc), translate human language query into form suitable to be run on dbase.\n",
    "## e.g. If dbase used is Vector DB, extract metadata filter information from the input query and run them against the vector dbase like Chroma\n",
    "## https://python.langchain.com/v0.2/docs/tutorials/query_analysis/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111f2180-8dd1-4f60-9ed2-50b0906a9a5d",
   "metadata": {},
   "source": [
    "## In this example we will use youtube video transcripts etc as document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "e0dfbd45-de69-436d-a17f-5019bb583ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_urls = [\n",
    "    \"https://www.youtube.com/watch?v=HAn9vnJy6S4\",\n",
    "    \"https://www.youtube.com/watch?v=dA1cHGACXCo\",\n",
    "    \"https://www.youtube.com/watch?v=ZcEMLz27sL4\",\n",
    "    \"https://www.youtube.com/watch?v=hvAPnpSfSGo\",\n",
    "    \"https://www.youtube.com/watch?v=EhlPDL4QrWY\",\n",
    "    \"https://www.youtube.com/watch?v=mmBo8nlu2j0\",\n",
    "    \"https://www.youtube.com/watch?v=rQdibOsL1ps\",\n",
    "    \"https://www.youtube.com/watch?v=28lC4fqukoc\",\n",
    "    \"https://www.youtube.com/watch?v=es-9MgxB-uc\",\n",
    "    \"https://www.youtube.com/watch?v=wLRHwKuKvOE\",\n",
    "    \"https://www.youtube.com/watch?v=ObIltMaRJvY\",\n",
    "    \"https://www.youtube.com/watch?v=DjuXACWYkkU\",\n",
    "    \"https://www.youtube.com/watch?v=o7C9ld6Ln-M\",\n",
    "]\n",
    "youtube_docs = []\n",
    "for url in youtube_urls:\n",
    "    youtube_docs.extend(YoutubeLoader.from_youtube_url(url, add_video_info=True).load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "c725159e-1e6d-44db-8e36-31375dd95235",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for doc in youtube_docs:\n",
    "    doc.metadata[\"publish_year\"] = int(datetime.datetime.strptime(doc.metadata[\"publish_date\"], \"%Y-%m-%d %H:%M:%S\").strftime(\"%Y\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "d4d6a04f-b8cf-45d6-9781-5e35d5afec5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OpenGPTs',\n",
       " 'Building a web RAG chatbot: using LangChain, Exa (prev. Metaphor), LangSmith, and Hosted Langserve',\n",
       " 'Streaming Events: Introducing a new `stream_events` method',\n",
       " 'LangGraph: Multi-Agent Workflows',\n",
       " 'Build and Deploy a RAG app with Pinecone Serverless',\n",
       " 'Auto-Prompt Builder (with Hosted LangServe)',\n",
       " 'Build a Full Stack RAG App With TypeScript',\n",
       " 'Getting Started with Multi-Modal LLMs',\n",
       " 'SQL Research Assistant',\n",
       " 'Skeleton-of-Thought: Building a New Template from Scratch',\n",
       " 'Benchmarking RAG over LangChain Docs',\n",
       " 'Building a Research Assistant from Scratch',\n",
       " 'LangServe and LangChain Templates Webinar']"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[doc.metadata[\"title\"] for doc in youtube_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "af54ed93-ddb7-4a46-8a71-855b95797df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8912,\n",
       " 7402,\n",
       " 2556,\n",
       " 46801,\n",
       " 8514,\n",
       " 11818,\n",
       " 16115,\n",
       " 4028,\n",
       " 11732,\n",
       " 6724,\n",
       " 3337,\n",
       " 22273,\n",
       " 5426]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[doc.metadata[\"view_count\"] for doc in youtube_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "7644480c-1a46-4f4f-b76d-f4dbe20eb64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'HAn9vnJy6S4',\n",
       " 'title': 'OpenGPTs',\n",
       " 'description': 'Unknown',\n",
       " 'view_count': 8912,\n",
       " 'thumbnail_url': 'https://i.ytimg.com/vi/HAn9vnJy6S4/hq720.jpg',\n",
       " 'publish_date': '2024-01-31 00:00:00',\n",
       " 'length': 1530,\n",
       " 'author': 'LangChain',\n",
       " 'publish_year': 2024}"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "youtube_docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "24950ad1-e4b8-4ee7-bbdb-80d866b0ccc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chunk youtube docs using RecursiveCharacterTextSplitter, use nomic embedder to get embeddings and store it into a vector database (Chroma)\n",
    "youtube_splits = splitter.split_documents(youtube_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "f511f235-9f9b-41f8-a1d6-104e9fa19fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_vectorstore = Chroma.from_documents(collection_name=\"youtube_store_nomic\", documents=youtube_splits, embedding=embeddings, persist_directory=\"./chroma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d141bd8-7e4f-4bd2-af56-cf582cdf8d65",
   "metadata": {},
   "source": [
    "## Now create a BaseModel that helps extract relevant metadata from input query that can then be applied on top on chroma db (youtube_vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "d8c3e24d-bd09-46bf-aca8-693596f272dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TutorialSearch(BaseModel):\n",
    "    content_search: str = Field(description=\"Similarity search queries that can be applied to video transcripts\")\n",
    "    title_Search: str = Field(description=\"Succinct title with only the keywords\")\n",
    "    min_view_count: Optional[int] = Field(description=\"Minimum view count, inclusive. Use only if explicitly specified\")\n",
    "    max_view_count: Optional[int] = Field(description=\"Maximum view count, inclusive. Use only if explicitly specified\")\n",
    "    publish_year: Optional[int] = Field(description=\"Year when the video was published. Use only if explicitly specified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "38ee70b1-c130-4720-a865-12f3847dbe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_experimental_youtube_local_llm = experimental_local_llm.with_structured_output(TutorialSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "a2402966-3030-4b45-b6cb-4849877ba511",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_messages = [\n",
    "    SystemMessage(content=\"\"\"You are an expert at converting user questions into database queries.\n",
    "    You have access to a database of tutorial videos about a software library for building LLM-powered applications.\n",
    "    Given a question, return a database query optimized to retrieve the most relevant results.\n",
    "    If there are acronyms or words you are not familiar with, do not try to rephrase them.\"\"\"),\n",
    "    HumanMessage(content=\"{question}\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "21193e0b-5477-43fc-8cee-67b439dde0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_prompt = ChatPromptTemplate.from_messages(youtube_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "617a5907-167d-4d3e-911a-692630dee0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_constructor_chain = youtube_prompt | structured_experimental_youtube_local_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "3f4d294d-4698-4c76-ad58-4b80adcc9eb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"videos on chat langchain published in 2023\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"videos on chat langchain published in 2023\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:OllamaFunctions] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are an expert at converting user questions into database queries.\\n    You have access to a database of tutorial videos about a software library for building LLM-powered applications.\\n    Given a question, return a database query optimized to retrieve the most relevant results.\\n    If there are acronyms or words you are not familiar with, do not try to rephrase them.\\nHuman: {question}\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:OllamaFunctions] [4.23s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-d359e880-b9b0-4b65-9322-0ec7c61463b0-0\",\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"name\": \"TutorialSearch\",\n",
      "                \"args\": {\n",
      "                  \"content_search\": \"LLM-powered applications\",\n",
      "                  \"title_Search\": \"Use cases\"\n",
      "                },\n",
      "                \"id\": \"call_a7d4def3a2564a06a461217a28208226\"\n",
      "              }\n",
      "            ],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:parse_response] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:parse_response] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"{\\\"content_search\\\": \\\"LLM-powered applications\\\", \\\"title_Search\\\": \\\"Use cases\\\"}\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:PydanticOutputParser] Entering Parser run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"{\\\"content_search\\\": \\\"LLM-powered applications\\\", \\\"title_Search\\\": \\\"Use cases\\\"}\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:PydanticOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [4.24s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n"
     ]
    }
   ],
   "source": [
    "youtube_resp = query_constructor_chain.invoke({\"question\": \"videos on chat langchain published in 2023\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636785d1-0740-4413-92cf-1531d3e772e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24597f0a-bec1-41b0-b687-ec2b24abfbc6",
   "metadata": {},
   "source": [
    "## LLama 2 does not appear to have the capability to extract elevant information from the query in the above case. It is worth experimenting with other LLMs that are trained specifically for function calling. For example:\n",
    "1. Phi models\n",
    "2. Nexusravn: https://ollama.com/library/nexusraven/blobs/cf200ab0155f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a9e980-78d8-4fba-8048-2b4050c5e6cb",
   "metadata": {},
   "source": [
    "## https://api.python.langchain.com/en/latest/vectorstores/langchain_community.vectorstores.chroma.Chroma.html#langchain_community.vectorstores.chroma.Chroma.as_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f97c851-77c7-49f0-8dcc-8ba862d3d8be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "rag_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
